{
    "docs": [
        {
            "location": "/", 
            "text": "The Lurch Deductive Engine (LDE)\n\n\nThis documentation site contains the design of the LDE.\n\n\nWe will implement that design, and as we do so, the various phases of\ndevelopment (accessible from the navigation menu above) will be converted\nfrom pages describing the plan into pages describing the completed API.\n\n\nUse the menu at the top of this site to find content.\n\n\nSee the source code repository here.", 
            "title": "Home"
        }, 
        {
            "location": "/#the-lurch-deductive-engine-lde", 
            "text": "This documentation site contains the design of the LDE.  We will implement that design, and as we do so, the various phases of\ndevelopment (accessible from the navigation menu above) will be converted\nfrom pages describing the plan into pages describing the completed API.  Use the menu at the top of this site to find content.  See the source code repository here.", 
            "title": "The Lurch Deductive Engine (LDE)"
        }, 
        {
            "location": "/design-overview/", 
            "text": "LDE Design Overview\n\n\nThis page lists the design principles adopted by the Lurch team to date\nregarding the LDE, with reasons and explanations for each.  This document\ncan be used as reference, and to guide development, but it may also be\nchanged as better ideas come along.\n\n\nTo see the specific phases of development planned for the LDE, and what's\ncompleted, use the \"Phases\" menu above.\n\n\nElegance and Simplicity\n\n\nThese are of utmost importance, because\n\n\n\n\nthey make Lurch easier to explain to students or in an Advanced User's\n   Guide (AUG),\n\n\nthey make Lurch easier to test because it has fewer unusual corner cases\n   or special handling of odd circumstances,\n\n\nthey make Lurch easier to implement for the same reason, and\n\n\nthey make it easier for us to be confident that our designs are good,\n   because they're easier to hold in your head and grok all at once.\n\n\n\n\nFeedback and Validation\n\n\n\n\nThe primary purpose of the Lurch application is to give feedback to the\n   user about the work they type into their document.\n\n\nBecause this will often involve validating steps of work in a proof, we\n   may use the terms \"feedback\" and \"validation\" interchangeably, even\n   though technically validation is just a particular type of feedback\n   (though the most common type in our case).\n\n\nOne-Pass Validation (OPV)\n is a paradigm in which, whenever the app\n   needs to update feedback in response to changes made by the user, it\n   does so by reprocessing every bit of meaningful content from scratch, in\n   one (large, possibly time-consuming) pass over the whole document.\n\n\nReal-Time Validation (RTV)\n is a paradigm in which, whenever the app\n   needs to update feedback in response to changes made by the user, it\n   attempts to re-use as much information from previous validation as\n   possible, only updating those portions of it that need updating in\n   response to the specific change the user just made.  Thus RTV is\n   trickier to design and implement than OPV, but more efficient at\n   run-time.\n\n\nAn important concept for our test suite is that any RTV design can be\n   converted to an OPV design trivially, and then used for comparison\n   testing.  Simply replace all sophisticated RTV-style change event\n   handlers with OPV-style ones, that mark the entire document as needing\n   reprocessing.  Then any potential change that can be made to the user's\n   document can be run through each of these engines in parallel, and the\n   results compared for equivalence.\n\n\nNote that the choice of OPV vs. RTV is independent of the choice of\n   manual validation vs. automatic validation.  RTV certainly makes\n   automatic validation nicer, and thus makes manual validation less\n   appealing, but you could choose anything from among\n   \n\\{\\text{OPV},\\text{RTV}\\}\\times\\{\\text{auto},\\text{manual}\\}\n.\n\n\n\n\nLDE and UI\n\n\n\n\nWe have a paradigm in which the UI is exactly that (user interface) and\n   the LDE (Lurch Deductive Engine) is the brain that operates in one or\n   more background threads, processing what the user has given the app\n   through the UI.\n\n\nWe aim to implement every feature in the LDE if possible, but implement\n   in the UI only those features that can't be implemented in the LDE.\n   Here, \"if possible\" means that it would not break the model-view\n   paradigm to implement it in the LDE (i.e., the LDE wouldn't need to\n   speak HTML).  Reasons for this:\n\n\nThe LDE will be implemented in pure JS, no DOM, so that it can be\n  used in a WebWorker and in the unit testing suite.\n\n\nTherefore the bigger the LDE is, the more of our code has been\n  subject to rigorous unit tests.\n\n\nAnd the bigger the LDE is, the more of our code is run out of the UX\n  thread, and thus the more responsive our app is.\n\n\n\n\n\n\nThe decisions recorded here are almost entirely about the design of the\n   LDE, not the UI.\n\n\n\n\nStructures\n\n\n\n\nDefine a \nstructure\n to be the basic unit of meaning in the LDE.\n\n\nThis includes document-level structures such as a section,\n  subsection, proof, subproof, etc., which are analogous to block-level\n  items like DIV or P in HTML, and \n\\begin{X}...\\end{X}\n in LaTeX.\n\n\nBut it also includes inline structures (SPANs in HTML, \n\\foo{...}\n or\n  \n$...$\n in LaTeX).\n\n\nStructures can be nested acyclically.\n\n\n\n\n\n\nExamples of types of structures that we may choose to define later:\n\n\nProofs/Subproofs, with one specific flavor of it being the kind that\n  declares a variable first\n\n\nDefinitions of rules, axioms, language rules\n\n\nFormal systems (or \"mathematical topics\")\n\n\nTheorems and pairing of them with proofs\n\n\nExpressions\n\n\nMaybe variables will be declared by based on placing a variable\n  inside an expression by itself, at the head of a variable declaration\n  subproof, or maybe by creating a new structure type for variable\n  declarations, or maybe something else\n\n\nHomework problems\n\n\nExamples (an environment in which anything you declare ends its scope\n  at the end of the example, no matter what it was)\n\n\n\n\n\n\nThe set of structure types should equal the set of common mathematical\n   structures that mathematics students should be learning anyway, and they\n   should behave the same in Lurch as in mathematics.  This ensures that\n   Lurch doesn't add to the mathematics learning curve in this sense.\n\n\nNot every structure is permitted to contain every other type of\n   structure.  But such rules are enforced through validation, which we\n   will not be defining for some time yet, so this comment is just a\n   preview of what's to come.  For instance, expressions can contain only\n   other expressions.\n\n\nAt some later point, we may care about the meanings of structures, so\n   that they can be used as premises in proofs.  At such a time, we will\n   ensure that a structure's meaning includes the unjustified steps in the\n   structure (which function as premises), the final step in the structure\n   (which functions as its conclusion), any variables declared within it\n   (which are bound in it), and so on, but it is not necessary to define\n   those details yet.  I mention them here merely so that the idea is not\n   lost.\n\n\n\n\nAccessibility\n\n\n\n\nA structure A is accessible to a structure B if some ancestor structure\n   of B (possibly B itself) is a sibling of A, but A is the (strictly)\n   earlier of the two siblings within their parent structure.\n\n\nEquivalently, we can speak of \"scope\" rather than accessibility.  The\n   scope of a structure A is all later siblings of A in the same parent,\n   along with all their descendants.  Thus B is in the scope of A iff A is\n   accessible to B.\n\n\n\n\nAttributes\n\n\n\n\nEvery structure contains a key-value dictionary called \nattributes,\n\n   which are read-only from the point of view of the LDE, and are\n   read-write from the point of view of the UI.  From the LDE's point of\n   view, they come from elsewhere (the UI).\n\n\n\n\nDocument\n\n\n\n\nThe entire document will be represented to the LDE as a single\n   structure, usually with a nonzero number of inner structures.\n\n\nWe call the representation of the entire document as a structure the LDE\n   Document, a phrase chosen to connote \"the LDE's view of the document,\n   not the one the user sees in the UI.\"\n\n\nOne main job of the UI is to convert from what the user sees into the\n   LDE Document.\n\n\nSo to the list of structure types above, add \"Document.\"\n\n\nThe entire LDE Document data structure will live inside the LDE module.\n   In the main Lurch app, this implies that the LDE Document will be stored\n   in the background thread where the LDE runs, not in the UI.  Thus the UI\n   will communicate across threads to create the LDE Document.  Details on\n   this later.\n\n\n\n\nSome brief UI comments\n\n\n\n\nMost of the purpose of the UI will be to convert the HTML document the\n   user sees into the LDE Document the LDE processes, then to show the user\n   in the HTML document and feedback the LDE sends back.\n\n\nIn service to that purpose, the UI contains many (largely independent\n  and usually small) features for encoding the HTML document into the\n  LDE Document.\n\n\nExamples include conventions for processing groups, connections,\n  numbered lists, section headings, finding meaning in text through\n  regular expressions, and the meanings of various LaTeX-like\n  \n\\shortcuts\n.\n\n\nA document author chooses which subset of these features to enable by\n  making choices in the document settings dialog.  Those settings are\n  stored in document metadata, and propagate to dependencies (defined\n  below).\n\n\nThe UI will have very little hard-coded (i.e., non-customizable)\n  procedures for interpreting the HTML document into the LDE document;\n  the settings above are highly choosable by the user.\n\n\nThe only constrained interpretation conventions (i.e., few or no\n  options for changing the interpretation) would be those that have\n  mathematical names, such as \"proof,\" which have a specific meaning\n  that it would be educationally counterproductive to interpret another\n  way.\n\n\nIn addition, we may choose a specific set of document settings to use\n  throughout the standard libraries that ship with Lurch, to show best\n  practices and help users with consistency and predictability.\n\n\n\n\n\n\nOther UI details:\n\n\nBecause we have a UI that allows users to make connections among\n  groups, the structures in the hierarchy may include, among their\n  attributes, a binary, edge-labeled multigraph.  (Note that this does\n  not require that every connection in the HTML document become two\n  Structures in the LDE Document with attributes connecting them.  Nor\n  does it stipulate that some concept--such as labeling--that we might\n  decide to represent as part of this multigraph can't also be\n  represented sometimes in another way as well.)\n\n\nIf we require the LDE to send a signal when validation completes,\n  then we can make a UI setting of whether to show feedback as the\n  feedback arrives, or only after the \"all validation complete\" signal\n  arrives (and thus feedback has stabilized).\n\n\n\n\n\n\n\n\nStructures are OOP Objects\n\n\n\n\nA structure exposes a set of data and methods about its internal state\n   to the rest of the app, in much the same way as Objects in OOP do, with\n   the type of structure (from the list above, e.g., Theorem or Example)\n   functioning as the \"class\" of the Object.\n\n\nSome methods in a structure will be time-intensive to run, and thus\n   should use an asynchronous paradigm, queueing the tasks for running when\n   the LDE thread has time.  The most time-intensive tasks, such as\n   matching and parsing, may be delegated to yet other background threads\n   by the LDE thread.\n\n\n\n\nExporting data from structures\n\n\n\n\nHere is an important example method that all structures should have\n   (though each class may implement it differently):\n\n\nA method that reports which structures (usually child structures of\n  A), if any, are to be made accessible to any structure B in the scope\n  of A (thus changing the normal scoping rules).\n\n\nThe flexibility inherent in the vagueness of this exporting notion is\n  useful.  For instance, a single theorem in the document might be\n  encoded in the LDE document as having many children, some of which\n  are its various interpretations as a rule of inference, and export\n  them all, so that any can be used/cited later.\n\n\nNote that the exports method need not copy child structures directly\n  for exporting.  It may combine/manipulate/compute structures to\n  export based on its children in any way.  Thus \"scope\" is a simple\n  and clean definition, which this function sort of indirectly extends.\n\n\n\n\n\n\nWe will define much of the functionality of the LDE as the various\n   structures in the document calling methods in one another, which is\n   simple and elegant.  But it requires that we carefully track and cache\n   the clean/dirty status of each structure, to retain efficiency.\n\n\n\n\nDependencies as a special case\n\n\n\n\nThe current paradigm (already implemented) in webLurch is that a\n   dependency must specify what data it exports to any document that\n   depends on it.\n\n\nSuch data will be stored in the dependency document's metadata, so that\n   documents depending on it can easily import it.  It will include\n   anything that the dependency imported from its dependencies, and so on\n   to arbitrary depth.\n\n\nBecause we now require every structure to know what it exports to later\n   structures, the question of what a document exports is simply a special\n   case of that.  The document is itself a structure, and thus it can\n   already answer the \"what does this document export?\" question.\n\n\nRecall from above that one of the pieces of data that a document will\n   export is its document settings, as described earlier.\n\n\n\n\nDesign Phases\n\n\n\n\nThe question, \"Which structure should be designed first?\" is tricky\n   because each structure is rather complex, and they're rather\n   interdependent.\n\n\nOne approach would be to design each structure incrementally, adding\n   features in phases.\n\n\nThus we might begin with an LDE implementation that has just a few\n   features for a few structure types, and yet is sufficient for building\n   very simply Lurch libraries.\n\n\nThis lets us build familiarity and knowledge as we do the design, so\n   we're better at it by the time we get to the hard stuff.\n\n\nPhases 2, 3, and so on can add features and structure types, thus\n   enabling more and more sophisticated Lurch libraries, until we have\n   reached the level of power that supports a first proof course.\n\n\n\n\nHow to design support for new concepts\n\n\n\n\nBegin with how the new concept will be represented in the Output Tree\n   (OT).  As you do so, respect these constraints.\n\n\nThe OT is pure data that the user never sees, so we are free to store\n  things there without concern for how they will appear to users.\n\n\nThe OT must support validation, so we are constrained to storing\n  things there in a way that makes it easy to write and maintain\n  validation algorithms.\n\n\nValidation is complicated, and yet it must be 100% airtight and\n  correct; therefore we don't want our data storage decisions to add\n  any unnecessary complexity to validation and/or the OT.\n\n\nAs a consequence, there should be one unique, canonical way to store\n  any given concept in the OT.\n\n\n\n\n\n\nThen ask \nbriefly\n how the concept will show up in the main Lurch UI.\n\n\nAdmit up front that it is something that will expand a lot with\n  time.  That is, whatever we design now will be the tip of the iceberg\n  of ideas that will occur to us over the coming years, and we should\n  accept that up front and plan for that as best we can.\n\n\nStart by listing the few ways that you already know that the new\n  feature will show up in the UI, simultaneously admitting that it is\n  just a sample of the ways that the feature might eventually appear.\n\n\n\n\n\n\nCome to the middle of the pipeline, the Input Tree (IT), whose job is to\n   bridge between the UI and the OT.  Recall that the UI will have many ways\n   to represent the new features, and the OT only one.  There are two steps\n   of translation between there that could possibly handle the conversion:\n   Should the UI-to-InputTree phase handle it, or should interpretation\n   handle it, or some combination?  Decide based on these guidelines:\n\n\nThe UI-to-IT conversion does not know about the array of accessible\n  nodes, nor does it know about any of their semantics.  Only the\n  interpretation phase can depend on the semantics of all nodes\n  accessible to the one being interpreted.  So if that information is\n  relevant, the computation must be pushed to the interpretation\n  phase.  For instance, if some feature needs to know what variables\n  are declared and in scope, it would need to wait for the\n  interpretation phase, which will have access to all accessible nodes,\n  including all declarations.\n\n\nOnly the UI knows about any of its features that are specific to that\n  UI.  For instance in the main UI, there may be features specific to\n  HTML and/or mouse events, or in a LaTeX package there may be features\n  specific to LaTeX.  Obviously such features must be handled in the\n  UI-to-IT conversion, because they depend upon the specific UI in\n  which they were invented.\n\n\nIf the previous guidelines do not apply, prefer doing the work in the\n  interpretation phase rather than the UI-to-IT phase, for these\n  reasons:\n\n\nDoing so makes the whole LDE better, rather than just making one\n     of its UIs better.\n\n\nThe interpretation phase can be converted into a queue and handled\n     efficiently, so adding computation burden to it is better than\n     adding computation burden where such efficiency measures are not\n     available.\n\n\nKeep in mind at all times that the features in the UI that\n  interpretation must support are just an example set that will grow\n  over time, so try to design an interpretation phase that can easily\n  be expanded also, to be ready for such later expansion in the UI.\n\n\n\n\n\n\n\n\nSee other documentation on this site for the contents of each design phase.", 
            "title": "Overview"
        }, 
        {
            "location": "/design-overview/#lde-design-overview", 
            "text": "This page lists the design principles adopted by the Lurch team to date\nregarding the LDE, with reasons and explanations for each.  This document\ncan be used as reference, and to guide development, but it may also be\nchanged as better ideas come along.  To see the specific phases of development planned for the LDE, and what's\ncompleted, use the \"Phases\" menu above.", 
            "title": "LDE Design Overview"
        }, 
        {
            "location": "/design-overview/#elegance-and-simplicity", 
            "text": "These are of utmost importance, because   they make Lurch easier to explain to students or in an Advanced User's\n   Guide (AUG),  they make Lurch easier to test because it has fewer unusual corner cases\n   or special handling of odd circumstances,  they make Lurch easier to implement for the same reason, and  they make it easier for us to be confident that our designs are good,\n   because they're easier to hold in your head and grok all at once.", 
            "title": "Elegance and Simplicity"
        }, 
        {
            "location": "/design-overview/#feedback-and-validation", 
            "text": "The primary purpose of the Lurch application is to give feedback to the\n   user about the work they type into their document.  Because this will often involve validating steps of work in a proof, we\n   may use the terms \"feedback\" and \"validation\" interchangeably, even\n   though technically validation is just a particular type of feedback\n   (though the most common type in our case).  One-Pass Validation (OPV)  is a paradigm in which, whenever the app\n   needs to update feedback in response to changes made by the user, it\n   does so by reprocessing every bit of meaningful content from scratch, in\n   one (large, possibly time-consuming) pass over the whole document.  Real-Time Validation (RTV)  is a paradigm in which, whenever the app\n   needs to update feedback in response to changes made by the user, it\n   attempts to re-use as much information from previous validation as\n   possible, only updating those portions of it that need updating in\n   response to the specific change the user just made.  Thus RTV is\n   trickier to design and implement than OPV, but more efficient at\n   run-time.  An important concept for our test suite is that any RTV design can be\n   converted to an OPV design trivially, and then used for comparison\n   testing.  Simply replace all sophisticated RTV-style change event\n   handlers with OPV-style ones, that mark the entire document as needing\n   reprocessing.  Then any potential change that can be made to the user's\n   document can be run through each of these engines in parallel, and the\n   results compared for equivalence.  Note that the choice of OPV vs. RTV is independent of the choice of\n   manual validation vs. automatic validation.  RTV certainly makes\n   automatic validation nicer, and thus makes manual validation less\n   appealing, but you could choose anything from among\n    \\{\\text{OPV},\\text{RTV}\\}\\times\\{\\text{auto},\\text{manual}\\} .", 
            "title": "Feedback and Validation"
        }, 
        {
            "location": "/design-overview/#lde-and-ui", 
            "text": "We have a paradigm in which the UI is exactly that (user interface) and\n   the LDE (Lurch Deductive Engine) is the brain that operates in one or\n   more background threads, processing what the user has given the app\n   through the UI.  We aim to implement every feature in the LDE if possible, but implement\n   in the UI only those features that can't be implemented in the LDE.\n   Here, \"if possible\" means that it would not break the model-view\n   paradigm to implement it in the LDE (i.e., the LDE wouldn't need to\n   speak HTML).  Reasons for this:  The LDE will be implemented in pure JS, no DOM, so that it can be\n  used in a WebWorker and in the unit testing suite.  Therefore the bigger the LDE is, the more of our code has been\n  subject to rigorous unit tests.  And the bigger the LDE is, the more of our code is run out of the UX\n  thread, and thus the more responsive our app is.    The decisions recorded here are almost entirely about the design of the\n   LDE, not the UI.", 
            "title": "LDE and UI"
        }, 
        {
            "location": "/design-overview/#structures", 
            "text": "Define a  structure  to be the basic unit of meaning in the LDE.  This includes document-level structures such as a section,\n  subsection, proof, subproof, etc., which are analogous to block-level\n  items like DIV or P in HTML, and  \\begin{X}...\\end{X}  in LaTeX.  But it also includes inline structures (SPANs in HTML,  \\foo{...}  or\n   $...$  in LaTeX).  Structures can be nested acyclically.    Examples of types of structures that we may choose to define later:  Proofs/Subproofs, with one specific flavor of it being the kind that\n  declares a variable first  Definitions of rules, axioms, language rules  Formal systems (or \"mathematical topics\")  Theorems and pairing of them with proofs  Expressions  Maybe variables will be declared by based on placing a variable\n  inside an expression by itself, at the head of a variable declaration\n  subproof, or maybe by creating a new structure type for variable\n  declarations, or maybe something else  Homework problems  Examples (an environment in which anything you declare ends its scope\n  at the end of the example, no matter what it was)    The set of structure types should equal the set of common mathematical\n   structures that mathematics students should be learning anyway, and they\n   should behave the same in Lurch as in mathematics.  This ensures that\n   Lurch doesn't add to the mathematics learning curve in this sense.  Not every structure is permitted to contain every other type of\n   structure.  But such rules are enforced through validation, which we\n   will not be defining for some time yet, so this comment is just a\n   preview of what's to come.  For instance, expressions can contain only\n   other expressions.  At some later point, we may care about the meanings of structures, so\n   that they can be used as premises in proofs.  At such a time, we will\n   ensure that a structure's meaning includes the unjustified steps in the\n   structure (which function as premises), the final step in the structure\n   (which functions as its conclusion), any variables declared within it\n   (which are bound in it), and so on, but it is not necessary to define\n   those details yet.  I mention them here merely so that the idea is not\n   lost.", 
            "title": "Structures"
        }, 
        {
            "location": "/design-overview/#accessibility", 
            "text": "A structure A is accessible to a structure B if some ancestor structure\n   of B (possibly B itself) is a sibling of A, but A is the (strictly)\n   earlier of the two siblings within their parent structure.  Equivalently, we can speak of \"scope\" rather than accessibility.  The\n   scope of a structure A is all later siblings of A in the same parent,\n   along with all their descendants.  Thus B is in the scope of A iff A is\n   accessible to B.", 
            "title": "Accessibility"
        }, 
        {
            "location": "/design-overview/#attributes", 
            "text": "Every structure contains a key-value dictionary called  attributes, \n   which are read-only from the point of view of the LDE, and are\n   read-write from the point of view of the UI.  From the LDE's point of\n   view, they come from elsewhere (the UI).", 
            "title": "Attributes"
        }, 
        {
            "location": "/design-overview/#document", 
            "text": "The entire document will be represented to the LDE as a single\n   structure, usually with a nonzero number of inner structures.  We call the representation of the entire document as a structure the LDE\n   Document, a phrase chosen to connote \"the LDE's view of the document,\n   not the one the user sees in the UI.\"  One main job of the UI is to convert from what the user sees into the\n   LDE Document.  So to the list of structure types above, add \"Document.\"  The entire LDE Document data structure will live inside the LDE module.\n   In the main Lurch app, this implies that the LDE Document will be stored\n   in the background thread where the LDE runs, not in the UI.  Thus the UI\n   will communicate across threads to create the LDE Document.  Details on\n   this later.", 
            "title": "Document"
        }, 
        {
            "location": "/design-overview/#some-brief-ui-comments", 
            "text": "Most of the purpose of the UI will be to convert the HTML document the\n   user sees into the LDE Document the LDE processes, then to show the user\n   in the HTML document and feedback the LDE sends back.  In service to that purpose, the UI contains many (largely independent\n  and usually small) features for encoding the HTML document into the\n  LDE Document.  Examples include conventions for processing groups, connections,\n  numbered lists, section headings, finding meaning in text through\n  regular expressions, and the meanings of various LaTeX-like\n   \\shortcuts .  A document author chooses which subset of these features to enable by\n  making choices in the document settings dialog.  Those settings are\n  stored in document metadata, and propagate to dependencies (defined\n  below).  The UI will have very little hard-coded (i.e., non-customizable)\n  procedures for interpreting the HTML document into the LDE document;\n  the settings above are highly choosable by the user.  The only constrained interpretation conventions (i.e., few or no\n  options for changing the interpretation) would be those that have\n  mathematical names, such as \"proof,\" which have a specific meaning\n  that it would be educationally counterproductive to interpret another\n  way.  In addition, we may choose a specific set of document settings to use\n  throughout the standard libraries that ship with Lurch, to show best\n  practices and help users with consistency and predictability.    Other UI details:  Because we have a UI that allows users to make connections among\n  groups, the structures in the hierarchy may include, among their\n  attributes, a binary, edge-labeled multigraph.  (Note that this does\n  not require that every connection in the HTML document become two\n  Structures in the LDE Document with attributes connecting them.  Nor\n  does it stipulate that some concept--such as labeling--that we might\n  decide to represent as part of this multigraph can't also be\n  represented sometimes in another way as well.)  If we require the LDE to send a signal when validation completes,\n  then we can make a UI setting of whether to show feedback as the\n  feedback arrives, or only after the \"all validation complete\" signal\n  arrives (and thus feedback has stabilized).", 
            "title": "Some brief UI comments"
        }, 
        {
            "location": "/design-overview/#structures-are-oop-objects", 
            "text": "A structure exposes a set of data and methods about its internal state\n   to the rest of the app, in much the same way as Objects in OOP do, with\n   the type of structure (from the list above, e.g., Theorem or Example)\n   functioning as the \"class\" of the Object.  Some methods in a structure will be time-intensive to run, and thus\n   should use an asynchronous paradigm, queueing the tasks for running when\n   the LDE thread has time.  The most time-intensive tasks, such as\n   matching and parsing, may be delegated to yet other background threads\n   by the LDE thread.", 
            "title": "Structures are OOP Objects"
        }, 
        {
            "location": "/design-overview/#exporting-data-from-structures", 
            "text": "Here is an important example method that all structures should have\n   (though each class may implement it differently):  A method that reports which structures (usually child structures of\n  A), if any, are to be made accessible to any structure B in the scope\n  of A (thus changing the normal scoping rules).  The flexibility inherent in the vagueness of this exporting notion is\n  useful.  For instance, a single theorem in the document might be\n  encoded in the LDE document as having many children, some of which\n  are its various interpretations as a rule of inference, and export\n  them all, so that any can be used/cited later.  Note that the exports method need not copy child structures directly\n  for exporting.  It may combine/manipulate/compute structures to\n  export based on its children in any way.  Thus \"scope\" is a simple\n  and clean definition, which this function sort of indirectly extends.    We will define much of the functionality of the LDE as the various\n   structures in the document calling methods in one another, which is\n   simple and elegant.  But it requires that we carefully track and cache\n   the clean/dirty status of each structure, to retain efficiency.", 
            "title": "Exporting data from structures"
        }, 
        {
            "location": "/design-overview/#dependencies-as-a-special-case", 
            "text": "The current paradigm (already implemented) in webLurch is that a\n   dependency must specify what data it exports to any document that\n   depends on it.  Such data will be stored in the dependency document's metadata, so that\n   documents depending on it can easily import it.  It will include\n   anything that the dependency imported from its dependencies, and so on\n   to arbitrary depth.  Because we now require every structure to know what it exports to later\n   structures, the question of what a document exports is simply a special\n   case of that.  The document is itself a structure, and thus it can\n   already answer the \"what does this document export?\" question.  Recall from above that one of the pieces of data that a document will\n   export is its document settings, as described earlier.", 
            "title": "Dependencies as a special case"
        }, 
        {
            "location": "/design-overview/#design-phases", 
            "text": "The question, \"Which structure should be designed first?\" is tricky\n   because each structure is rather complex, and they're rather\n   interdependent.  One approach would be to design each structure incrementally, adding\n   features in phases.  Thus we might begin with an LDE implementation that has just a few\n   features for a few structure types, and yet is sufficient for building\n   very simply Lurch libraries.  This lets us build familiarity and knowledge as we do the design, so\n   we're better at it by the time we get to the hard stuff.  Phases 2, 3, and so on can add features and structure types, thus\n   enabling more and more sophisticated Lurch libraries, until we have\n   reached the level of power that supports a first proof course.", 
            "title": "Design Phases"
        }, 
        {
            "location": "/design-overview/#how-to-design-support-for-new-concepts", 
            "text": "Begin with how the new concept will be represented in the Output Tree\n   (OT).  As you do so, respect these constraints.  The OT is pure data that the user never sees, so we are free to store\n  things there without concern for how they will appear to users.  The OT must support validation, so we are constrained to storing\n  things there in a way that makes it easy to write and maintain\n  validation algorithms.  Validation is complicated, and yet it must be 100% airtight and\n  correct; therefore we don't want our data storage decisions to add\n  any unnecessary complexity to validation and/or the OT.  As a consequence, there should be one unique, canonical way to store\n  any given concept in the OT.    Then ask  briefly  how the concept will show up in the main Lurch UI.  Admit up front that it is something that will expand a lot with\n  time.  That is, whatever we design now will be the tip of the iceberg\n  of ideas that will occur to us over the coming years, and we should\n  accept that up front and plan for that as best we can.  Start by listing the few ways that you already know that the new\n  feature will show up in the UI, simultaneously admitting that it is\n  just a sample of the ways that the feature might eventually appear.    Come to the middle of the pipeline, the Input Tree (IT), whose job is to\n   bridge between the UI and the OT.  Recall that the UI will have many ways\n   to represent the new features, and the OT only one.  There are two steps\n   of translation between there that could possibly handle the conversion:\n   Should the UI-to-InputTree phase handle it, or should interpretation\n   handle it, or some combination?  Decide based on these guidelines:  The UI-to-IT conversion does not know about the array of accessible\n  nodes, nor does it know about any of their semantics.  Only the\n  interpretation phase can depend on the semantics of all nodes\n  accessible to the one being interpreted.  So if that information is\n  relevant, the computation must be pushed to the interpretation\n  phase.  For instance, if some feature needs to know what variables\n  are declared and in scope, it would need to wait for the\n  interpretation phase, which will have access to all accessible nodes,\n  including all declarations.  Only the UI knows about any of its features that are specific to that\n  UI.  For instance in the main UI, there may be features specific to\n  HTML and/or mouse events, or in a LaTeX package there may be features\n  specific to LaTeX.  Obviously such features must be handled in the\n  UI-to-IT conversion, because they depend upon the specific UI in\n  which they were invented.  If the previous guidelines do not apply, prefer doing the work in the\n  interpretation phase rather than the UI-to-IT phase, for these\n  reasons:  Doing so makes the whole LDE better, rather than just making one\n     of its UIs better.  The interpretation phase can be converted into a queue and handled\n     efficiently, so adding computation burden to it is better than\n     adding computation burden where such efficiency measures are not\n     available.  Keep in mind at all times that the features in the UI that\n  interpretation must support are just an example set that will grow\n  over time, so try to design an interpretation phase that can easily\n  be expanded also, to be ready for such later expansion in the UI.     See other documentation on this site for the contents of each design phase.", 
            "title": "How to design support for new concepts"
        }, 
        {
            "location": "/phase1-structures/", 
            "text": "We have designed the work on the Lurch Deductive Engine (LDE) to progress in\nphases.  The idea is that each phase ends with a completed whole that can be\ntested in that state, and that provides more features than the previous\nstate did.  By the time the final phase is complete, the LDE will be a\nrobust and useful product.\n\n\nLDE Design Phase 1: Structures\n\n\nContent\n\n\nIn this phase, we just design the generic Structure class on which\neverything else will depend, and the infrastructure of the LDE itself.\n\n\nThe \nStructure\n module defines a single \nStructure\n class, and has been\nimplemented. \nIts API Documentation appears here\n.\n\n\nThe \nLDE\n module defines several global functions, and has been implemented.\n\nIts API Documentation appears here\n.\n\n\nGoal\n\n\nAt the end of this phase, we could write unit tests of the whole Structure\nclass and its LDE context, thus guaranteeing that all later phases rest on a\ngood foundation.\n\n\nStatus\n\n\nThis phase has been implemented and documented in the API Documentation,\nand then was thoroughly overhauled to match a new and updated design.  That\noverhaul is complete, and this phase is ready to be used in later phases.", 
            "title": "Phase 1, Structures"
        }, 
        {
            "location": "/phase1-structures/#lde-design-phase-1-structures", 
            "text": "", 
            "title": "LDE Design Phase 1: Structures"
        }, 
        {
            "location": "/phase1-structures/#content", 
            "text": "In this phase, we just design the generic Structure class on which\neverything else will depend, and the infrastructure of the LDE itself.  The  Structure  module defines a single  Structure  class, and has been\nimplemented.  Its API Documentation appears here .  The  LDE  module defines several global functions, and has been implemented. Its API Documentation appears here .", 
            "title": "Content"
        }, 
        {
            "location": "/phase1-structures/#goal", 
            "text": "At the end of this phase, we could write unit tests of the whole Structure\nclass and its LDE context, thus guaranteeing that all later phases rest on a\ngood foundation.", 
            "title": "Goal"
        }, 
        {
            "location": "/phase1-structures/#status", 
            "text": "This phase has been implemented and documented in the API Documentation,\nand then was thoroughly overhauled to match a new and updated design.  That\noverhaul is complete, and this phase is ready to be used in later phases.", 
            "title": "Status"
        }, 
        {
            "location": "/phase2-input-tree/", 
            "text": "We have designed the work on the Lurch Deductive Engine (LDE) to progress in\nphases.  The idea is that each phase ends with a completed whole that can be\ntested in that state, and that provides more features than the previous\nstate did.  By the time the final phase is complete, the LDE will be a\nrobust and useful product.\n\n\nLDE Design Phase 2: The Input Tree\n\n\nContent\n\n\nIn this phase, we add the Input Tree, a hierarchy comprised of a new kind of\n\nStructure\n subclass, called \nInputStructure\n.\n\n\nGoal\n\n\nThe \nInputStructure\n class will exist and be used by the LDE module.\n\n\nStatus\n\n\nThis has been partially implemented.  See the tasks below, some marked\ncomplete and some not yet marked complete.\n\n\nInputStructure\n class\n\n\n\n\n Create a subclass of \nStructure\n, in its own new module,\n   \nsrc/input-structure.litcoffee\n.\n\n\n Add documentation explaining what it is and will do (though that\n   documentation can grow with time).\n\n\n Ensure that the \nInputStructure\n subclass registers itself with the\n   serialization code, as\n   \nthe documentation here\n\n   describes.  (That is, use a line like\n   \nclassName : Structure.addSubclass 'InputStructure', InputStructure\n in\n   the \nInputStructure\n class code.)\n\n\n Rewrite the LDE module so that it no longer takes as input generic\n   \nStructure\n instances, but specifically \nInputStructure\n instances.  All\n   of its methods should be updated to use \nInputStructure\ns where they\n   currently use \nStructure\ns.  This will require importing the\n   \ninput-structure.litcoffee\n module instead of the generic\n   \nstructure.litcoffee\n one.\n\n\n Rename the global \nStructure\n hierarchy in that file to be\n   \nInputTree\n rather than \nLDEDocument\n.\n\n\n Update all documentation in that file to reflect the changes just\n   made.\n\n\n Update all unit tests of the LDE module to reflect this change to\n   \nInputStructure\ns.  This will require importing the\n   \ninput-structure.litcoffee\n module instead of the generic\n   \nstructure.litcoffeee\n one.\n\n\n Create a new unit test file for \nInputStructure\ns that is extremely\n   basic, just testing to be sure that the symbol \nInputStructure\n is\n   defined at the global scope and creates things that are instances of the\n   generic \nStructure\n base class.\n\n\n Add documentation for that unit test file, following the pattern\n   established in the documentation of other unit test files in this\n   repository.\n\n\n Once the unit tests pass, build everything and commit.\n\n\n\n\nAccepting actual instances\n\n\n\n\n The LDE module was written to accept only JSON-serialized forms of\n   \nStructure\ns as parameters to its methods.  Update those functions so\n   that they now accept either serialized forms or actual instances, and can\n   tell the difference and respond appropriately.  (That is, deserialize any\n   serialized instances, but don't do that if the argument was already an\n   instance.)\n\n\n Extend the unit test suite of the LDE module so that it tests this\n   new feature of each API method of the LDE module.\n\n\n Update all documentation in that file to reflect the changes just\n   made.\n\n\n Once the unit tests pass, build everything and commit.\n\n\n\n\nMarking structures dirty\n\n\n\n\n Extend the base \nStructure\n class with a field called \ndirty\n, which\n   is initialized to false in the constructor.  This field does not need to\n   be part of any serialization or deserialization of instances.\n\n\n Create an \nisDirty()\n method that returns the value of that member\n   variable.\n\n\n Create a \nmarkDirty()\n method in the \nInputStructure\n class that sets\n   the \ndirty\n flag to true, and does so for all ancestors as well.\n\n\n Update all documentation in that file to reflect the changes just\n   made.\n\n\n Add to the unit tests for \nInputStructure\ns a few simple tests for\n   these new routines.\n\n\n Add documentation in that file describing the changes just made.\n\n\n Once the unit tests pass, build everything and commit.\n\n\n\n\nConnecting modules\n\n\n\n\n Give the \nStructure\n class a class method called \nfeedback\n, whose\n   default implementation just writes to the console saying that the\n   feedback implementation doesn't exist yet.\n\n\n Give the \nInputStructure\n class a method called \nfeedback\n, accepting\n   a data object as parameter, and extending it with a \nsubject\n field whose\n   value is the unique ID of the \nInputStructure\n in question, then passing\n   that new object on to the \nfeedback\n class method in the \nStructure\n\n   class.\n\n\n In the LDE module, if it detects that it has been loaded in Node.js\n   or the main browser thread, then create a global variable called\n   \nFeedback\n that is an instance of \nEventTarget\n.  In the module case,\n   export that variable; in the browser case, just let it be global.\n\n\n In the LDE, create a module-global \nfeedback\n function that does one\n   of two things:\n\n\nIf it detects that the LDE is running in a Node.js module or in the\n  main browser thread, it calls, in the global \nFeedback\n object,\n  \ndispatchEvent(e)\n, where the \nEvent e\n holds the parameter passed to\n  \nfeedback\n.\n\n\nIf it detects that the LDE is running in a WebWorker (or the\n  equivalent construct in Node.js), it sends its parameter along by\n  posting a message to be heard by the parent thread.\n\n\n\n\n\n\n In the LDE, when it imports the \nStructure\n module, have it overwrite\n   the default implementation of \nfeedback\n in the \nStructure\n class with\n   a call directly to the \nfeedback\n function in the LDE.\n\n\n Update all documentation in that file to reflect the changes just\n   made.\n\n\n Add to the unit tests for the LDE module a few simple tests for\n   these new routines.\n\n\n Add documentation in that file describing the changes just made.\n\n\n Once the unit tests pass, build everything and commit.\n\n\n\n\nLDE API\n\n\nSmall, Miscellaneous Updates\n\n\n\n\n Now that we have changed from a generic \nStructure\n class paradigm to\n   specific Input and Output Structures, reread the API Documentation of\n   both \nthe LDE\n and \nthe Structure class\n,\n   updating anything that's out-of-date.\n\n\n Add a page to the API documentation for the \nInputStructure\n class\n   and all of its upcoming subclasses.\n\n\n Update \nmkdocs.yml\n in the project root to include that new file in\n   the generated documentation.\n\n\n Update the API in the LDE module to include the word \"Structure\" in\n   each method call, because we will soon add methods for connections as\n   well.  So for instance, make it \ninsertStructure\n rather than just\n   \ninsert\n, and so on.\n\n\n Update all unit tests and API documentation, and when the unit test\n   pass, then commit.\n\n\n Tweak the existing \nsetStructureAttribute()\n API method so that it\n   does not permit the client to use attribute names that begin with an\n   underscore, so that we can \"namespace\" those for internal purposes.\n\n\n Update the LDE API documentation page to cover these new routines.\n\n\n Add a unit test for that change to \nsetStructureAttribute()\n as well.\n\n\n\n\nUpgrading Connections\n\n\n\n\n\n\n Remove the \nallConnectionsIn()\n, \nallConnectionsOut()\n, and\n   \nallConnectionsTo()\n functions and their unit tests.\n\n\n\n\n\n\n Create a unit test that verifies that when \nuntrackIDs()\n or\n   \nclearIDs()\n is called in a \nStructure\n, then all connections to/from\n   that structure are first removed.  This unit test will not pass, at\n   first.\n\n\n\n\n Update \nuntrackIDs()\n to make that unit test pass for it.\n\n\n\n\n Update \nclearIDs()\n to make that unit test pass for it.\n\n\n\n\n\n\n Define \nconnectionIDs : { }\n in the \nStructure\n class.\n\n\n\n\n Define \n@sourceOfConnection : ( id ) -\n Structure::connectionIDs[id]\n\n   in the \nStructure\n class.\n\n\n\n\n Ensure that this did not break any unit tests.\n\n\n\n\n\n\n Disable all unit tests for \nconnectTo\n and \ndisconnectFrom\n, then\n   ensure that all remaining unit tests pass.\n\n\n\n\n\n\n Rewrite \nStructure::connect(source,target,data)\n to do this:\n\n\n\n\nQuit if \ndata.id\n is already used in \nStructure::connectionIDs\n;\n  return false in that case.\n\n\nWrite the target's ID to the \n\"_conn #{id} to\"\n attribute of the\n  source.\n\n\nWrite the source's ID to the \n\"_conn #{id} from\"\n attribute of the\n  target.\n\n\nWrite the data to the \n\"_conn #{id} data\"\n attribute of the source.\n\n\nAdd \ndata.id\n to \nStructure::connectionIDs\n.\n\n\nCall the \nconnectionInserted\n handler, if it exists, in the source and\n  target \nStructure\ns.\n\n\nReturn true.\n\n\n\n\n\n\n Ensure that \nsomeStruct.connectTo(t,d)\n is an alias for\n   \nStructure::connect(someStruct,t,d)\n.\n\n\n Replace \ndisconnectFrom()\n with \nStructure::disconnect(connectionID)\n\n   that does this:\n\n\nQuit unless \nconnectionID\n is already used in\n  \nStructure::connectionIDs\n; return false in that case.\n\n\nGet the structure that is the source.  From it, get the target.\n\n\nIn the source, remove the \n\"_conn #{id} to\"\n attribute.\n\n\nIn the source, remove the \n\"_conn #{id} data\"\n attribute.\n\n\nIn the target, remove the \n\"_conn #{id} from\"\n attribute.\n\n\nRemove \ndata.id\n from \nStructure::connectionIDs\n.\n\n\nCall the \nconnectionRemoved\n handler, if it exists, in the source and\n  target \nStructure\ns.\n\n\nReturn true.\n\n\n\n\n\n\n Ensure that \nsomeStruct.disconnect(id)\n is an alias for\n   \nStructure::disconnect(id)\n.\n\n\n Add \nStructure::setConnectionData(connID,key,value)\n that does this:\n\n\nQuit unless \nconnID\n is already used in \nStructure::connectionIDs\n;\n  if so, return false.\n\n\nIf \nvalue\n is undefined, remove any existing key-value pair with the\n  given \nkey\n from the connection data for the specified connection.\n\n\nOtherwise, replace any existing key-value pair with the given one in\n  the specified connection.\n\n\nIn any case, call the \nconnectionChanged\n handler, if it exists, in\n  the source and target \nStructure\ns.\n\n\nReturn true.\n\n\n\n\n\n\n\n\n Ensure that \nsomeStruct.setConnectionData(id,k,v)\n is an alias for\n   \nStructure::setConnectionData(id,k,v)\n.\n\n\n\n\n\n\n Implement \nStructure::getConnectionSource(id)\n and ensure that\n   \nsomeStruct.getConnectionSource(id)\n is an alias for it.\n\n\n\n\n Implement \nStructure::getConnectionTarget(id)\n and ensure that\n   \nsomeStruct.getConnectionTarget(id)\n is an alias for it.\n\n\n Implement \nStructure::getConnectionData(id)\n and ensure that\n   \nsomeStruct.getConnectionData(id)\n is an alias for it.\n\n\n Implement \nsomeStruct.getConnectionsIn()\n, returning a list of IDs.\n\n\n Implement \nsomeStruct.getConnectionsOut()\n, returning a list of IDs.\n\n\n Implement \nsomeStruct.getAllConnections()\n, returning a list of IDs.\n\n\n\n\n Reimplement a new version of \nremoveAllConnections()\n that uses these\n   new functions to do its work.\n\n\n\n\n\n\n Replace all the old unit tests for \nconnectTo\n and \ndisconnectFrom\n\n   with new ones that test all the features just added by all the recent\n   changes.\n\n\n\n\n\n\n Add unit tests for all new functions and features added in the steps\n   above.\n\n\n\n\n Test \ntrackIDs()\n and \nnoticeAllConnections()\n.\n\n\n Test \nStructure.sourceOfConnection()\n.\n\n\n Test \ngetConnectionSource()\n, \ngetConnectionTarget()\n, and\n  \ngetConnectionData()\n.\n\n\n Test \nsetConnectionData()\n.\n\n\n Test event handlers \nconnectionWillBeInserted()\n and\n  \nconnectionWasInserted()\n.\n\n\n Test event handlers \nconnectionWillBeRemoved()\n and\n  \nconnectionWasRemoved()\n.\n\n\n Test event handlers \nconnectionWillBeChanged()\n and\n  \nconnectionWasChanged()\n.\n\n\n Verify that functions fail when their preconditions aren't\n  satisfied.\n\n\n\n\n\n\n\n\n Add to the API a new method, \ninsertConnection(source,target,data)\n,\n   which directly calls \nStructure::connect()\n, but only if both the source\n   and the target are \nInputStructure\n instances.\n\n\n\n\n Add to the API a new method, \nremoveConnection(id)\n, which\n   directly calls \nStructure::disconnect()\n, but only if both the source\n   and the target are \nInputStructure\n instances.\n\n\n Add to the API a new method,\n   \nsetConnectionAttribute(connection,key,value)\n, which directly calls\n   \nStructure::setConnectionData(connection,key,value)\n, but only if both\n   the source and the target are \nInputStructure\n instances.\n\n\n Create unit tests for all of these new routines and ensure that they\n   pass.\n\n\n Add API documentation for all events (\nwasInserted\n, \nwasRemoved\n,\n   \nwasChanged\n, \nconnectionWasInserted\n, \nconnectionWasRemoved\n,\n   \nconnectionWasChanged\n, and the \nwillBe\n variants for all of them).\n   Link to that documentation from the unit tests.\n\n\n Rebuild docs and commit.\n\n\n\n\nPolicing Connections\n\n\n\n\n Add unit tests to ensure that removing or replacing nodes in the\n   Input Tree automatically severs any relevant connections on the outgoing\n   node.\n\n\n Create a function in the \nStructure\n class that will transfer all\n   connections in/out of node \nX\n to node \nY\n instead, written as\n   \nX.transferConnectionsTo( Y )\n.\n\n\n Document the above routine as something that \ninterpret()\n routines\n   are welcome to use, if it is useful to them.\n\n\n Add an optional third parameter to \nreplaceStructure()\n, which\n   defaults to false, but can be set to true to have \nreplaceStructure()\n\n   transfer all such connections to the replacement structure, rather than\n   just sever them.\n\n\n Add unit tests to ensure that these features work.\n\n\n Rebuild and commit.", 
            "title": "Phase 2, The Input Tree"
        }, 
        {
            "location": "/phase2-input-tree/#lde-design-phase-2-the-input-tree", 
            "text": "", 
            "title": "LDE Design Phase 2: The Input Tree"
        }, 
        {
            "location": "/phase2-input-tree/#content", 
            "text": "In this phase, we add the Input Tree, a hierarchy comprised of a new kind of Structure  subclass, called  InputStructure .", 
            "title": "Content"
        }, 
        {
            "location": "/phase2-input-tree/#goal", 
            "text": "The  InputStructure  class will exist and be used by the LDE module.", 
            "title": "Goal"
        }, 
        {
            "location": "/phase2-input-tree/#status", 
            "text": "This has been partially implemented.  See the tasks below, some marked\ncomplete and some not yet marked complete.", 
            "title": "Status"
        }, 
        {
            "location": "/phase2-input-tree/#inputstructure-class", 
            "text": "Create a subclass of  Structure , in its own new module,\n    src/input-structure.litcoffee .   Add documentation explaining what it is and will do (though that\n   documentation can grow with time).   Ensure that the  InputStructure  subclass registers itself with the\n   serialization code, as\n    the documentation here \n   describes.  (That is, use a line like\n    className : Structure.addSubclass 'InputStructure', InputStructure  in\n   the  InputStructure  class code.)   Rewrite the LDE module so that it no longer takes as input generic\n    Structure  instances, but specifically  InputStructure  instances.  All\n   of its methods should be updated to use  InputStructure s where they\n   currently use  Structure s.  This will require importing the\n    input-structure.litcoffee  module instead of the generic\n    structure.litcoffee  one.   Rename the global  Structure  hierarchy in that file to be\n    InputTree  rather than  LDEDocument .   Update all documentation in that file to reflect the changes just\n   made.   Update all unit tests of the LDE module to reflect this change to\n    InputStructure s.  This will require importing the\n    input-structure.litcoffee  module instead of the generic\n    structure.litcoffeee  one.   Create a new unit test file for  InputStructure s that is extremely\n   basic, just testing to be sure that the symbol  InputStructure  is\n   defined at the global scope and creates things that are instances of the\n   generic  Structure  base class.   Add documentation for that unit test file, following the pattern\n   established in the documentation of other unit test files in this\n   repository.   Once the unit tests pass, build everything and commit.", 
            "title": "InputStructure class"
        }, 
        {
            "location": "/phase2-input-tree/#accepting-actual-instances", 
            "text": "The LDE module was written to accept only JSON-serialized forms of\n    Structure s as parameters to its methods.  Update those functions so\n   that they now accept either serialized forms or actual instances, and can\n   tell the difference and respond appropriately.  (That is, deserialize any\n   serialized instances, but don't do that if the argument was already an\n   instance.)   Extend the unit test suite of the LDE module so that it tests this\n   new feature of each API method of the LDE module.   Update all documentation in that file to reflect the changes just\n   made.   Once the unit tests pass, build everything and commit.", 
            "title": "Accepting actual instances"
        }, 
        {
            "location": "/phase2-input-tree/#marking-structures-dirty", 
            "text": "Extend the base  Structure  class with a field called  dirty , which\n   is initialized to false in the constructor.  This field does not need to\n   be part of any serialization or deserialization of instances.   Create an  isDirty()  method that returns the value of that member\n   variable.   Create a  markDirty()  method in the  InputStructure  class that sets\n   the  dirty  flag to true, and does so for all ancestors as well.   Update all documentation in that file to reflect the changes just\n   made.   Add to the unit tests for  InputStructure s a few simple tests for\n   these new routines.   Add documentation in that file describing the changes just made.   Once the unit tests pass, build everything and commit.", 
            "title": "Marking structures dirty"
        }, 
        {
            "location": "/phase2-input-tree/#connecting-modules", 
            "text": "Give the  Structure  class a class method called  feedback , whose\n   default implementation just writes to the console saying that the\n   feedback implementation doesn't exist yet.   Give the  InputStructure  class a method called  feedback , accepting\n   a data object as parameter, and extending it with a  subject  field whose\n   value is the unique ID of the  InputStructure  in question, then passing\n   that new object on to the  feedback  class method in the  Structure \n   class.   In the LDE module, if it detects that it has been loaded in Node.js\n   or the main browser thread, then create a global variable called\n    Feedback  that is an instance of  EventTarget .  In the module case,\n   export that variable; in the browser case, just let it be global.   In the LDE, create a module-global  feedback  function that does one\n   of two things:  If it detects that the LDE is running in a Node.js module or in the\n  main browser thread, it calls, in the global  Feedback  object,\n   dispatchEvent(e) , where the  Event e  holds the parameter passed to\n   feedback .  If it detects that the LDE is running in a WebWorker (or the\n  equivalent construct in Node.js), it sends its parameter along by\n  posting a message to be heard by the parent thread.     In the LDE, when it imports the  Structure  module, have it overwrite\n   the default implementation of  feedback  in the  Structure  class with\n   a call directly to the  feedback  function in the LDE.   Update all documentation in that file to reflect the changes just\n   made.   Add to the unit tests for the LDE module a few simple tests for\n   these new routines.   Add documentation in that file describing the changes just made.   Once the unit tests pass, build everything and commit.", 
            "title": "Connecting modules"
        }, 
        {
            "location": "/phase2-input-tree/#lde-api", 
            "text": "", 
            "title": "LDE API"
        }, 
        {
            "location": "/phase2-input-tree/#small-miscellaneous-updates", 
            "text": "Now that we have changed from a generic  Structure  class paradigm to\n   specific Input and Output Structures, reread the API Documentation of\n   both  the LDE  and  the Structure class ,\n   updating anything that's out-of-date.   Add a page to the API documentation for the  InputStructure  class\n   and all of its upcoming subclasses.   Update  mkdocs.yml  in the project root to include that new file in\n   the generated documentation.   Update the API in the LDE module to include the word \"Structure\" in\n   each method call, because we will soon add methods for connections as\n   well.  So for instance, make it  insertStructure  rather than just\n    insert , and so on.   Update all unit tests and API documentation, and when the unit test\n   pass, then commit.   Tweak the existing  setStructureAttribute()  API method so that it\n   does not permit the client to use attribute names that begin with an\n   underscore, so that we can \"namespace\" those for internal purposes.   Update the LDE API documentation page to cover these new routines.   Add a unit test for that change to  setStructureAttribute()  as well.", 
            "title": "Small, Miscellaneous Updates"
        }, 
        {
            "location": "/phase2-input-tree/#upgrading-connections", 
            "text": "Remove the  allConnectionsIn() ,  allConnectionsOut() , and\n    allConnectionsTo()  functions and their unit tests.     Create a unit test that verifies that when  untrackIDs()  or\n    clearIDs()  is called in a  Structure , then all connections to/from\n   that structure are first removed.  This unit test will not pass, at\n   first.    Update  untrackIDs()  to make that unit test pass for it.    Update  clearIDs()  to make that unit test pass for it.     Define  connectionIDs : { }  in the  Structure  class.    Define  @sourceOfConnection : ( id ) -  Structure::connectionIDs[id] \n   in the  Structure  class.    Ensure that this did not break any unit tests.     Disable all unit tests for  connectTo  and  disconnectFrom , then\n   ensure that all remaining unit tests pass.     Rewrite  Structure::connect(source,target,data)  to do this:   Quit if  data.id  is already used in  Structure::connectionIDs ;\n  return false in that case.  Write the target's ID to the  \"_conn #{id} to\"  attribute of the\n  source.  Write the source's ID to the  \"_conn #{id} from\"  attribute of the\n  target.  Write the data to the  \"_conn #{id} data\"  attribute of the source.  Add  data.id  to  Structure::connectionIDs .  Call the  connectionInserted  handler, if it exists, in the source and\n  target  Structure s.  Return true.     Ensure that  someStruct.connectTo(t,d)  is an alias for\n    Structure::connect(someStruct,t,d) .   Replace  disconnectFrom()  with  Structure::disconnect(connectionID) \n   that does this:  Quit unless  connectionID  is already used in\n   Structure::connectionIDs ; return false in that case.  Get the structure that is the source.  From it, get the target.  In the source, remove the  \"_conn #{id} to\"  attribute.  In the source, remove the  \"_conn #{id} data\"  attribute.  In the target, remove the  \"_conn #{id} from\"  attribute.  Remove  data.id  from  Structure::connectionIDs .  Call the  connectionRemoved  handler, if it exists, in the source and\n  target  Structure s.  Return true.     Ensure that  someStruct.disconnect(id)  is an alias for\n    Structure::disconnect(id) .   Add  Structure::setConnectionData(connID,key,value)  that does this:  Quit unless  connID  is already used in  Structure::connectionIDs ;\n  if so, return false.  If  value  is undefined, remove any existing key-value pair with the\n  given  key  from the connection data for the specified connection.  Otherwise, replace any existing key-value pair with the given one in\n  the specified connection.  In any case, call the  connectionChanged  handler, if it exists, in\n  the source and target  Structure s.  Return true.      Ensure that  someStruct.setConnectionData(id,k,v)  is an alias for\n    Structure::setConnectionData(id,k,v) .     Implement  Structure::getConnectionSource(id)  and ensure that\n    someStruct.getConnectionSource(id)  is an alias for it.    Implement  Structure::getConnectionTarget(id)  and ensure that\n    someStruct.getConnectionTarget(id)  is an alias for it.   Implement  Structure::getConnectionData(id)  and ensure that\n    someStruct.getConnectionData(id)  is an alias for it.   Implement  someStruct.getConnectionsIn() , returning a list of IDs.   Implement  someStruct.getConnectionsOut() , returning a list of IDs.   Implement  someStruct.getAllConnections() , returning a list of IDs.    Reimplement a new version of  removeAllConnections()  that uses these\n   new functions to do its work.     Replace all the old unit tests for  connectTo  and  disconnectFrom \n   with new ones that test all the features just added by all the recent\n   changes.     Add unit tests for all new functions and features added in the steps\n   above.    Test  trackIDs()  and  noticeAllConnections() .   Test  Structure.sourceOfConnection() .   Test  getConnectionSource() ,  getConnectionTarget() , and\n   getConnectionData() .   Test  setConnectionData() .   Test event handlers  connectionWillBeInserted()  and\n   connectionWasInserted() .   Test event handlers  connectionWillBeRemoved()  and\n   connectionWasRemoved() .   Test event handlers  connectionWillBeChanged()  and\n   connectionWasChanged() .   Verify that functions fail when their preconditions aren't\n  satisfied.      Add to the API a new method,  insertConnection(source,target,data) ,\n   which directly calls  Structure::connect() , but only if both the source\n   and the target are  InputStructure  instances.    Add to the API a new method,  removeConnection(id) , which\n   directly calls  Structure::disconnect() , but only if both the source\n   and the target are  InputStructure  instances.   Add to the API a new method,\n    setConnectionAttribute(connection,key,value) , which directly calls\n    Structure::setConnectionData(connection,key,value) , but only if both\n   the source and the target are  InputStructure  instances.   Create unit tests for all of these new routines and ensure that they\n   pass.   Add API documentation for all events ( wasInserted ,  wasRemoved ,\n    wasChanged ,  connectionWasInserted ,  connectionWasRemoved ,\n    connectionWasChanged , and the  willBe  variants for all of them).\n   Link to that documentation from the unit tests.   Rebuild docs and commit.", 
            "title": "Upgrading Connections"
        }, 
        {
            "location": "/phase2-input-tree/#policing-connections", 
            "text": "Add unit tests to ensure that removing or replacing nodes in the\n   Input Tree automatically severs any relevant connections on the outgoing\n   node.   Create a function in the  Structure  class that will transfer all\n   connections in/out of node  X  to node  Y  instead, written as\n    X.transferConnectionsTo( Y ) .   Document the above routine as something that  interpret()  routines\n   are welcome to use, if it is useful to them.   Add an optional third parameter to  replaceStructure() , which\n   defaults to false, but can be set to true to have  replaceStructure() \n   transfer all such connections to the replacement structure, rather than\n   just sever them.   Add unit tests to ensure that these features work.   Rebuild and commit.", 
            "title": "Policing Connections"
        }, 
        {
            "location": "/phase3-output-tree/", 
            "text": "We have designed the work on the Lurch Deductive Engine (LDE) to progress in\nphases.  The idea is that each phase ends with a completed whole that can be\ntested in that state, and that provides more features than the previous\nstate did.  By the time the final phase is complete, the LDE will be a\nrobust and useful product.\n\n\nLDE Design Phase 3: The Output Tree\n\n\nContent\n\n\nIn this phase, we add the Output Tree, a hierarchy comprised of a new kind\nof \nStructure\n subclass, called \nOutputStructure\n.\n\n\nGoal\n\n\nThe \nOutputStructure\n class will exist, but will not yet be used by the LDE\nmodule.\n\n\nStatus\n\n\nThis has not been implemented.  See the tasks below.\n\n\nOutputStructure\n class\n\n\n\n\n Create a subclass of \nStructure\n, in its own new module,\n   \nsrc/output-structure.litcoffee\n.\n\n\n Add documentation explaining what it is and will do (though that\n   documentation can grow with time).\n\n\n Ensure that the \nOutputStructure\n subclass registers itself with the\n   serialization code, as\n   \nthe documentation here\n\n   describes.  (That is, use a line like\n   \nclassName : Structure.addSubclass 'OutputStructure', OutputStructure\n in\n   the \nOutputStructure\n class code.)\n\n\n Create a new unit test file for \nOutputStructure\ns that is extremely\n   basic, just testing to be sure that the symbol \nOutputStructure\n is\n   defined at the global scope and creates things that are instances of the\n   generic \nStructure\n base class.\n\n\n Add documentation for that unit test file, following the pattern\n   established in the documentation of other unit test files in this\n   repository.\n\n\n Update the LDE module to import the \noutput-structure.litcoffee\n\n   module in addition to the generic \nstructure.litcoffeee\n one and the one\n   for \nInputStructure\ns.\n\n\n Add a global \nStructure\n hierarchy in that file, called the\n   \nOutputTree\n, parallel to the \nInputTree\n.\n\n\n Add a function that the LDE module exports that serializes the entire\n   \nInputTree\n and the entire \nOutputTree\n and returns them as a pair.\n\n\n Add a function that is the reverse, taking a pair of serialized trees\n   and deserializing them into the \nInputTree\n and the \nOutputTree\n.\n\n\n Update all unit tests of the LDE module to reflect the introduction\n   of \nOutputStructure\ns.\n\n\n Once the unit tests pass, build everything and commit.\n\n\n\n\nMarking structures dirty\n\n\n\n\n Create a \nmarkDirty()\n function in the \nOutputStructure\n class that\n   marks the instance dirty (but with no propagation, unlike with\n   \nInputStructure\n instances).\n\n\n Extend the \nOutputStructure\n constructor to mark all instances dirty.\n\n\n Update all documentation in that file to reflect the changes just\n   made.\n\n\n Add to the unit tests for \nOutputStructure\ns a few simple tests for\n   these new routines.\n\n\n Add documentation in that file describing the changes just made.\n\n\n Once the unit tests pass, build everything and commit.\n\n\n\n\nConnecting modules\n\n\n\n\n Give the \nOutputStructure\n class a method called \nfeedback\n, whose\n   default behavior is the same as that of \nInputStructure\n.\n\n\n Add to the unit tests for \nOutputStructure\ns a few simple tests for\n   these new routines.\n\n\n Add documentation in that file describing the changes just made.\n\n\n Once the unit tests pass, build everything and commit.\n\n\n\n\nAPI Documentation\n\n\n\n\n Add a page to the API documentation for the \nOutputStructure\n class\n   and all of its upcoming subclasses.\n\n\n Update \nmkdocs.yml\n in the project root to include that new file in\n   the generated documentation.\n\n\n Rebuild docs and commit.", 
            "title": "Phase 3, The Output Tree"
        }, 
        {
            "location": "/phase3-output-tree/#lde-design-phase-3-the-output-tree", 
            "text": "", 
            "title": "LDE Design Phase 3: The Output Tree"
        }, 
        {
            "location": "/phase3-output-tree/#content", 
            "text": "In this phase, we add the Output Tree, a hierarchy comprised of a new kind\nof  Structure  subclass, called  OutputStructure .", 
            "title": "Content"
        }, 
        {
            "location": "/phase3-output-tree/#goal", 
            "text": "The  OutputStructure  class will exist, but will not yet be used by the LDE\nmodule.", 
            "title": "Goal"
        }, 
        {
            "location": "/phase3-output-tree/#status", 
            "text": "This has not been implemented.  See the tasks below.", 
            "title": "Status"
        }, 
        {
            "location": "/phase3-output-tree/#outputstructure-class", 
            "text": "Create a subclass of  Structure , in its own new module,\n    src/output-structure.litcoffee .   Add documentation explaining what it is and will do (though that\n   documentation can grow with time).   Ensure that the  OutputStructure  subclass registers itself with the\n   serialization code, as\n    the documentation here \n   describes.  (That is, use a line like\n    className : Structure.addSubclass 'OutputStructure', OutputStructure  in\n   the  OutputStructure  class code.)   Create a new unit test file for  OutputStructure s that is extremely\n   basic, just testing to be sure that the symbol  OutputStructure  is\n   defined at the global scope and creates things that are instances of the\n   generic  Structure  base class.   Add documentation for that unit test file, following the pattern\n   established in the documentation of other unit test files in this\n   repository.   Update the LDE module to import the  output-structure.litcoffee \n   module in addition to the generic  structure.litcoffeee  one and the one\n   for  InputStructure s.   Add a global  Structure  hierarchy in that file, called the\n    OutputTree , parallel to the  InputTree .   Add a function that the LDE module exports that serializes the entire\n    InputTree  and the entire  OutputTree  and returns them as a pair.   Add a function that is the reverse, taking a pair of serialized trees\n   and deserializing them into the  InputTree  and the  OutputTree .   Update all unit tests of the LDE module to reflect the introduction\n   of  OutputStructure s.   Once the unit tests pass, build everything and commit.", 
            "title": "OutputStructure class"
        }, 
        {
            "location": "/phase3-output-tree/#marking-structures-dirty", 
            "text": "Create a  markDirty()  function in the  OutputStructure  class that\n   marks the instance dirty (but with no propagation, unlike with\n    InputStructure  instances).   Extend the  OutputStructure  constructor to mark all instances dirty.   Update all documentation in that file to reflect the changes just\n   made.   Add to the unit tests for  OutputStructure s a few simple tests for\n   these new routines.   Add documentation in that file describing the changes just made.   Once the unit tests pass, build everything and commit.", 
            "title": "Marking structures dirty"
        }, 
        {
            "location": "/phase3-output-tree/#connecting-modules", 
            "text": "Give the  OutputStructure  class a method called  feedback , whose\n   default behavior is the same as that of  InputStructure .   Add to the unit tests for  OutputStructure s a few simple tests for\n   these new routines.   Add documentation in that file describing the changes just made.   Once the unit tests pass, build everything and commit.", 
            "title": "Connecting modules"
        }, 
        {
            "location": "/phase3-output-tree/#api-documentation", 
            "text": "Add a page to the API documentation for the  OutputStructure  class\n   and all of its upcoming subclasses.   Update  mkdocs.yml  in the project root to include that new file in\n   the generated documentation.   Rebuild docs and commit.", 
            "title": "API Documentation"
        }, 
        {
            "location": "/phase4-modification/", 
            "text": "We have designed the work on the Lurch Deductive Engine (LDE) to progress in\nphases.  The idea is that each phase ends with a completed whole that can be\ntested in that state, and that provides more features than the previous\nstate did.  By the time the final phase is complete, the LDE will be a\nrobust and useful product.\n\n\nLDE Design Phase 4: Expressions and Modifiers\n\n\nContent\n\n\nIn this phase, we specialize the \nInputStructure\n class into two subclasses,\n\nInputExpression\n and \nInputModifier\n.\n\n\nGoal\n\n\nThe \nInputExpression\n and \nInputModifier\n classes will exist with all their\nmethods and the Modification phase will be implemented.\n\n\nStatus\n\n\nThis has not been implemented.  See the tasks below.\n\n\nInputExpression\n class\n\n\n\n\n Create a subclass of \nInputStructure\n, in the \nInputStructure\n\n   module, called \nInputExpression\n.\n\n\n Add documentation explaining what it is and will do (though that\n   documentation can grow with time).\n\n\n Ensure that the \nInputExpression\n subclass registers itself with the\n   serialization code, as\n   \nthe documentation here\n\n   describes.  (That is, use a line like\n   \nclassName : Structure.addSubclass 'InputExpression', InputExpression\n in\n   the \nInputExpression\n class code.)\n\n\n Create a new unit test file for \nInputExpression\ns that is extremely\n   basic, just testing to be sure that the symbol \nInputExpression\n is\n   defined at the global scope and creates things that are instances of the\n   \nInputStructure\n class.\n\n\n Add documentation for that unit test file, following the pattern\n   established in the documentation of other unit test files in this\n   repository.\n\n\n Once the unit tests pass, build everything and commit.\n\n\n\n\nConvenience functions\n\n\nAll of the following functions should be added as members in the\n\nInputExpression\n class.\n\n\n\n\n A function for marking an attribute of the expression as having been\n   changed by an \nInputModifier\n (a class that we will define later, as\n   described below).  If the function is called on attribute key \nk\n, it\n   could, for example, just call \nX.setAttribute( \"IM changed \"+k, true )\n.\n\n\n Extend the new unit test file for \nInputExpression\ns to test this\n   new routine and document such tests.\n\n\n A function for creating a backup copy of all attributes set by\n   modifiers, which loops through all attribute keys, and when it encounters\n   any of the form \"IM changed $k$\", it lifts out the value associated with\n   $k$ and stores a copy of it in the backup being generated.  That backup\n   object is returned.\n\n\n Extend the new unit test file for \nInputExpression\ns to test this\n   new routine and document such tests.\n\n\n A function for comparing the state of an \nInputExpression\n to such a\n   backup, either reporting that its set of attributes changed by modifiers\n   matches the backup (nothing has changed) or it does not (something was\n   added, removed, or changed by an IM).\n\n\n A function for deleting all attributes set by modifiers (which not\n   only deletes a pair $(k,v)$, but also the corresponding attribute with\n   key \"IM changed $k$\").\n\n\n Extend the new unit test file for \nInputExpression\ns to test this\n   new routine and document such tests.\n\n\n A function \nsetSingleValue(k,v)\n that first checks whether the\n   expression has an attribute with key $k$.  If so, it returns false and\n   takes no further action.  If it doesn't have such an attribute, this one\n   adds it and marks it as having been changed by a modifier.  Thus this\n   function is intended only to be called by IMs.  In such a case, it\n   returns true.\n\n\n Extend the new unit test file for \nInputExpression\ns to test this\n   new routine and document such tests.\n\n\n A function \naddListItem(k,i)\n that first checks whether the\n   expression has an attribute with key $k$ and value an array.  If not,\n   it sets the value to \n[ i ]\n, an array containing the item \ni\n.  If it\n   already had an array value, we append \ni\n to it.  In either case, we mark\n   this as having been changed by a modifier.  Thus this function is\n   intended only to be called by IMs.\n\n\n Extend the new unit test file for \nInputExpression\ns to test this\n   new routine and document such tests.\n\n\n A function \naddSetElement(k,e)\n that first checks whether the\n   expression has an attribute with key $k$ and value an array.  If not,\n   it sets the value to \n[ e ]\n, a set containing the element \ne\n.  If it\n   already had an array value, we append \ne\n to it iff it was not already in\n   the array.  In any of these cases (even the one where nothing changed),\n   we mark this as having been changed by a modifier.  Thus this function is\n   intended only to be called by IMs.\n\n\n Extend the new unit test file for \nInputExpression\ns to test this\n   new routine and document such tests.\n\n\n Once the unit tests pass, build everything and commit.\n\n\n\n\nInputModifier\n class\n\n\n\n\n Create a subclass of \nInputStructure\n, in the \nInputStructure\n\n   module, called \nInputModifier\n.\n\n\n Add documentation explaining what it is and will do (though that\n   documentation can grow with time).\n\n\n Ensure that the \nInputModifier\n subclass registers itself with the\n   serialization code, as\n   \nthe documentation here\n\n   describes.  (That is, use a line like\n   \nclassName : Structure.addSubclass 'InputModifier', InputModifier\n in\n   the \nInputModifier\n class code.)\n\n\n The class should provide two functions that, in the base class, do\n   nothing, but will be overridden by subclasses to do something smarter.\n   These are \nupdateConnections()\n and \nupdateDataIn(target)\n.  Add these\n   stubs now.\n\n\n Document the two functions you just added regarding their purposes\n   in subclasses.\n\n\n Create a new unit test file for \nInputModifier\ns that is extremely\n   basic, just testing to be sure that the symbol \nInputModifier\n is\n   defined at the global scope and creates things that are instances of the\n   \nInputStructure\n class.\n\n\n Add documentation for that unit test file, following the pattern\n   established in the documentation of other unit test files in this\n   repository.\n\n\n Once the unit tests pass, build everything and commit.\n\n\n\n\nBasicInputModifier\n class\n\n\n\n\n Create a subclass of \nInputModifier\n, in the \nInputStructure\n\n   module, called \nBasicInputModifier\n.  It takes a set of key-value-type\n   triples at construction time and stores them for later embedding in a\n   target.  The \"type\" of the triple will be which kind of function should\n   be used to insert it (single value, list item, set element).\n\n\n Override the \nupdateDataIn(target)\n function to embed exactly those\n   key-value pairs in the target.  Take care to ensure that copies of values\n   are used rather than the original objects.  Be sure to use the\n   appropriate functions that will mark the attribute as having been set by\n   an \nInputModifier\n.\n\n\n Add documentation explaining what it is and does.\n\n\n Ensure that the \nBasicInputModifier\n subclass registers itself with the\n   serialization code, as\n   \nthe documentation here\n\n   describes.  (That is, use a line like\n   \nclassName : Structure.addSubclass 'BasicInputModifier', BasicInputModifier\n\n   in the \nBasicInputModifier\n class code.)\n\n\n Create a new unit test file for \nBasicInputModifier\ns that not only\n   ensures that the symbol \nBasicInputModifier\n is defined at the global\n   scope and that its instances are also instances of the \nInputStructure\n\n   class, but also that the \nupdateDataIn(target)\n function behaves as\n   intended.\n\n\n Add documentation for that unit test file, following the pattern\n   established in the documentation of other unit test files in this\n   repository.\n\n\n Once the unit tests pass, build everything and commit.\n\n\n\n\nExtending \nInputExpression\n\n\n\n\n Implement \nInputExpression\n's \nupdateData()\n function to loop through\n   all \nInputModifiers\n that connect to it as the target and call their\n   \nupdateDataIn()\n routines on itself.  Be sure to begin by using the\n   function that clears out all attributes set by a modifier.\n\n\n Create unit tests for this, probably located in the \nInputExpression\n\n   unit test file.\n\n\n Increase efficiency by calling the backup routine in the target\n   first, and at the end marks itself dirty if and only if its new state is\n   different from its original state in some attribute set by a modifier.\n   (Note that this task, since it is just an increase in efficiency, can be\n   deferred until later in the project, and can even be considered optional\n   if we notice no performance problems without implementing it.)\n\n\n Extend the unit tests to handle this new feature.\n\n\n Once the unit tests pass, build everything and commit.\n\n\n\n\nThe Modification Phase\n\n\n\n\n Implement a \nrunModification()\n method in the LDE module.  It should\n   run the \nupdateConnections()\n function in every IM in the Input Tree, in\n   an unspecified order, and then call a callback.  (This function is\n   asynchronous.)\n\n\n\n\nThe remainder of this section is efficiency improvements.  Consequently,\nthey can be deferred until later in the project, and can even be considered\noptional if we notice no performance problems without implementing them.  If\nyou wish to skip them for now, simply jump to the last few tasks in this\nsection, about unit tests and documentation.\n\n\n\n\n Extend the unit tests of the LDE to test this new function.  This\n   will require creating some dummy subclasses of \nInputModifier\n that\n   implement \nupdateConnections()\n in various ways.\n\n\n Enhance \nrunModification()\n to initialize a list of \nInputModifier\n\n   instances that are to be processed, then start a chain of \nsetTimeout()\n\n   calls that pop things off the list and process them, calling the callback\n   when the list is empty.  (Use extremely brief timeout delays.)\n\n\n Ensure that the unit tests still handle this asynchronous version.\n\n\n Enhance \nrunModification()\n so that, if any LDE API call is made\n   while the modification phase is ongoing, it resets the list of instances\n   to process to be the entire set of \nInputModifier\ns in the Input Tree,\n   thus restarting the whole modification process.\n\n\n Extend the unit tests to test this feature.  That is, make some\n   \nupdateConnections()\n routines that take a long time to compute (say, 0.5\n   seconds) and that also log their calls to a global array.  Make a set of\n   API calls in succession about 0.3 seconds apart, and ensure that the\n   global call log is as expected.\n\n\n Extend each of the four LDE API functions so that it calls\n   \nmarkDirty()\n on the appropriate \nInputStructure\n instance, then\n   \nrunModification()\n.\n\n\n Update the documentation to describe the changes just made.\n\n\n Extend the unit tests for the LDE module to verify that this works.\n\n\n Once the unit tests pass, build everything and commit.\n\n\n\n\nAPI Documentation\n\n\n\n\n Extend the \nInputStructure\n page of the API Documentation to include\n   all the work done in this phase.\n\n\n Add a page to the API Documentation for the phases of processing the\n   Input and Output Trees.  Begin it by documenting the modification phase,\n   and say that more content is to come later.\n\n\n Update \nmkdocs.yml\n in the project root to include that new file in\n   the generated documentation.\n\n\n Rebuild docs and commit.", 
            "title": "Phase 4, Modification"
        }, 
        {
            "location": "/phase4-modification/#lde-design-phase-4-expressions-and-modifiers", 
            "text": "", 
            "title": "LDE Design Phase 4: Expressions and Modifiers"
        }, 
        {
            "location": "/phase4-modification/#content", 
            "text": "In this phase, we specialize the  InputStructure  class into two subclasses, InputExpression  and  InputModifier .", 
            "title": "Content"
        }, 
        {
            "location": "/phase4-modification/#goal", 
            "text": "The  InputExpression  and  InputModifier  classes will exist with all their\nmethods and the Modification phase will be implemented.", 
            "title": "Goal"
        }, 
        {
            "location": "/phase4-modification/#status", 
            "text": "This has not been implemented.  See the tasks below.", 
            "title": "Status"
        }, 
        {
            "location": "/phase4-modification/#inputexpression-class", 
            "text": "Create a subclass of  InputStructure , in the  InputStructure \n   module, called  InputExpression .   Add documentation explaining what it is and will do (though that\n   documentation can grow with time).   Ensure that the  InputExpression  subclass registers itself with the\n   serialization code, as\n    the documentation here \n   describes.  (That is, use a line like\n    className : Structure.addSubclass 'InputExpression', InputExpression  in\n   the  InputExpression  class code.)   Create a new unit test file for  InputExpression s that is extremely\n   basic, just testing to be sure that the symbol  InputExpression  is\n   defined at the global scope and creates things that are instances of the\n    InputStructure  class.   Add documentation for that unit test file, following the pattern\n   established in the documentation of other unit test files in this\n   repository.   Once the unit tests pass, build everything and commit.", 
            "title": "InputExpression class"
        }, 
        {
            "location": "/phase4-modification/#convenience-functions", 
            "text": "All of the following functions should be added as members in the InputExpression  class.    A function for marking an attribute of the expression as having been\n   changed by an  InputModifier  (a class that we will define later, as\n   described below).  If the function is called on attribute key  k , it\n   could, for example, just call  X.setAttribute( \"IM changed \"+k, true ) .   Extend the new unit test file for  InputExpression s to test this\n   new routine and document such tests.   A function for creating a backup copy of all attributes set by\n   modifiers, which loops through all attribute keys, and when it encounters\n   any of the form \"IM changed $k$\", it lifts out the value associated with\n   $k$ and stores a copy of it in the backup being generated.  That backup\n   object is returned.   Extend the new unit test file for  InputExpression s to test this\n   new routine and document such tests.   A function for comparing the state of an  InputExpression  to such a\n   backup, either reporting that its set of attributes changed by modifiers\n   matches the backup (nothing has changed) or it does not (something was\n   added, removed, or changed by an IM).   A function for deleting all attributes set by modifiers (which not\n   only deletes a pair $(k,v)$, but also the corresponding attribute with\n   key \"IM changed $k$\").   Extend the new unit test file for  InputExpression s to test this\n   new routine and document such tests.   A function  setSingleValue(k,v)  that first checks whether the\n   expression has an attribute with key $k$.  If so, it returns false and\n   takes no further action.  If it doesn't have such an attribute, this one\n   adds it and marks it as having been changed by a modifier.  Thus this\n   function is intended only to be called by IMs.  In such a case, it\n   returns true.   Extend the new unit test file for  InputExpression s to test this\n   new routine and document such tests.   A function  addListItem(k,i)  that first checks whether the\n   expression has an attribute with key $k$ and value an array.  If not,\n   it sets the value to  [ i ] , an array containing the item  i .  If it\n   already had an array value, we append  i  to it.  In either case, we mark\n   this as having been changed by a modifier.  Thus this function is\n   intended only to be called by IMs.   Extend the new unit test file for  InputExpression s to test this\n   new routine and document such tests.   A function  addSetElement(k,e)  that first checks whether the\n   expression has an attribute with key $k$ and value an array.  If not,\n   it sets the value to  [ e ] , a set containing the element  e .  If it\n   already had an array value, we append  e  to it iff it was not already in\n   the array.  In any of these cases (even the one where nothing changed),\n   we mark this as having been changed by a modifier.  Thus this function is\n   intended only to be called by IMs.   Extend the new unit test file for  InputExpression s to test this\n   new routine and document such tests.   Once the unit tests pass, build everything and commit.", 
            "title": "Convenience functions"
        }, 
        {
            "location": "/phase4-modification/#inputmodifier-class", 
            "text": "Create a subclass of  InputStructure , in the  InputStructure \n   module, called  InputModifier .   Add documentation explaining what it is and will do (though that\n   documentation can grow with time).   Ensure that the  InputModifier  subclass registers itself with the\n   serialization code, as\n    the documentation here \n   describes.  (That is, use a line like\n    className : Structure.addSubclass 'InputModifier', InputModifier  in\n   the  InputModifier  class code.)   The class should provide two functions that, in the base class, do\n   nothing, but will be overridden by subclasses to do something smarter.\n   These are  updateConnections()  and  updateDataIn(target) .  Add these\n   stubs now.   Document the two functions you just added regarding their purposes\n   in subclasses.   Create a new unit test file for  InputModifier s that is extremely\n   basic, just testing to be sure that the symbol  InputModifier  is\n   defined at the global scope and creates things that are instances of the\n    InputStructure  class.   Add documentation for that unit test file, following the pattern\n   established in the documentation of other unit test files in this\n   repository.   Once the unit tests pass, build everything and commit.", 
            "title": "InputModifier class"
        }, 
        {
            "location": "/phase4-modification/#basicinputmodifier-class", 
            "text": "Create a subclass of  InputModifier , in the  InputStructure \n   module, called  BasicInputModifier .  It takes a set of key-value-type\n   triples at construction time and stores them for later embedding in a\n   target.  The \"type\" of the triple will be which kind of function should\n   be used to insert it (single value, list item, set element).   Override the  updateDataIn(target)  function to embed exactly those\n   key-value pairs in the target.  Take care to ensure that copies of values\n   are used rather than the original objects.  Be sure to use the\n   appropriate functions that will mark the attribute as having been set by\n   an  InputModifier .   Add documentation explaining what it is and does.   Ensure that the  BasicInputModifier  subclass registers itself with the\n   serialization code, as\n    the documentation here \n   describes.  (That is, use a line like\n    className : Structure.addSubclass 'BasicInputModifier', BasicInputModifier \n   in the  BasicInputModifier  class code.)   Create a new unit test file for  BasicInputModifier s that not only\n   ensures that the symbol  BasicInputModifier  is defined at the global\n   scope and that its instances are also instances of the  InputStructure \n   class, but also that the  updateDataIn(target)  function behaves as\n   intended.   Add documentation for that unit test file, following the pattern\n   established in the documentation of other unit test files in this\n   repository.   Once the unit tests pass, build everything and commit.", 
            "title": "BasicInputModifier class"
        }, 
        {
            "location": "/phase4-modification/#extending-inputexpression", 
            "text": "Implement  InputExpression 's  updateData()  function to loop through\n   all  InputModifiers  that connect to it as the target and call their\n    updateDataIn()  routines on itself.  Be sure to begin by using the\n   function that clears out all attributes set by a modifier.   Create unit tests for this, probably located in the  InputExpression \n   unit test file.   Increase efficiency by calling the backup routine in the target\n   first, and at the end marks itself dirty if and only if its new state is\n   different from its original state in some attribute set by a modifier.\n   (Note that this task, since it is just an increase in efficiency, can be\n   deferred until later in the project, and can even be considered optional\n   if we notice no performance problems without implementing it.)   Extend the unit tests to handle this new feature.   Once the unit tests pass, build everything and commit.", 
            "title": "Extending InputExpression"
        }, 
        {
            "location": "/phase4-modification/#the-modification-phase", 
            "text": "Implement a  runModification()  method in the LDE module.  It should\n   run the  updateConnections()  function in every IM in the Input Tree, in\n   an unspecified order, and then call a callback.  (This function is\n   asynchronous.)   The remainder of this section is efficiency improvements.  Consequently,\nthey can be deferred until later in the project, and can even be considered\noptional if we notice no performance problems without implementing them.  If\nyou wish to skip them for now, simply jump to the last few tasks in this\nsection, about unit tests and documentation.    Extend the unit tests of the LDE to test this new function.  This\n   will require creating some dummy subclasses of  InputModifier  that\n   implement  updateConnections()  in various ways.   Enhance  runModification()  to initialize a list of  InputModifier \n   instances that are to be processed, then start a chain of  setTimeout() \n   calls that pop things off the list and process them, calling the callback\n   when the list is empty.  (Use extremely brief timeout delays.)   Ensure that the unit tests still handle this asynchronous version.   Enhance  runModification()  so that, if any LDE API call is made\n   while the modification phase is ongoing, it resets the list of instances\n   to process to be the entire set of  InputModifier s in the Input Tree,\n   thus restarting the whole modification process.   Extend the unit tests to test this feature.  That is, make some\n    updateConnections()  routines that take a long time to compute (say, 0.5\n   seconds) and that also log their calls to a global array.  Make a set of\n   API calls in succession about 0.3 seconds apart, and ensure that the\n   global call log is as expected.   Extend each of the four LDE API functions so that it calls\n    markDirty()  on the appropriate  InputStructure  instance, then\n    runModification() .   Update the documentation to describe the changes just made.   Extend the unit tests for the LDE module to verify that this works.   Once the unit tests pass, build everything and commit.", 
            "title": "The Modification Phase"
        }, 
        {
            "location": "/phase4-modification/#api-documentation", 
            "text": "Extend the  InputStructure  page of the API Documentation to include\n   all the work done in this phase.   Add a page to the API Documentation for the phases of processing the\n   Input and Output Trees.  Begin it by documenting the modification phase,\n   and say that more content is to come later.   Update  mkdocs.yml  in the project root to include that new file in\n   the generated documentation.   Rebuild docs and commit.", 
            "title": "API Documentation"
        }, 
        {
            "location": "/phase5-interpretation/", 
            "text": "We have designed the work on the Lurch Deductive Engine (LDE) to progress in\nphases.  The idea is that each phase ends with a completed whole that can be\ntested in that state, and that provides more features than the previous\nstate did.  By the time the final phase is complete, the LDE will be a\nrobust and useful product.\n\n\nLDE Design Phase 5: Interpretation\n\n\nContent\n\n\nIn this phase, we implement the Interpretation Phase of the LDE.\n\n\nGoal\n\n\nThe LDE will be able to interpret the Input Tree, creating an Output Tree\nfrom it.\n\n\nStatus\n\n\nThis has not been implemented.  See the tasks below.\n\n\nBuilding interpretation routines\n\n\n\n\n Create an \ninterpret\n routine in the \nInputStructure\n class that\n   takes three arguments, \naccessibles\n (a list of \nOutputStructure\ns\n   accessible to the \nInputStructure\n in question), \nchildResults\n (a list\n   of lists of \nOutputStructure\n instances that were generated by recursive\n   interpretation calls), and \nscope\n (a list of the top-level structures\n   that are in the scope of the one in which \ninterpret\n was invoked).  The\n   implementation in this base class should be to create a generic\n   \nOutputStructure\n instance and flatten all the \nchildResults\n arrays\n   into it as children, in order.  Pseudocode:\n\n\n\n\nlet result = new OutputStructure() // plain vanilla wrapper node\nfor each childArray in childResults:\n    for each node in childArray:\n        result.appendChild( node ) // put everything in it\n        return [ result ] // return an array of exactly one tree\n\n\n\n\n\n\n Add documentation in that file describing the changes just made.\n\n\n Extend the unit tests for the \nInputStructure\n module to include some\n   calls to this routine, passing it various example parameters and\n   verifying that it does its job as specified.\n\n\n Add documentation in that test file describing the changes just made.\n\n\n Once the unit tests pass, build everything and commit.\n\n\n Add documentation stating the limitations on how subclasses are\n   permitted to override the \ninterpret\n routine from the \nInputStructure\n\n   class.  Specifically, the following rules must be obeyed:\n\n\nThe routine should depend upon only the data passed to it in its\n  first two parameters.\n\n\nIf \nX.interpret()\n calls \nY.markDirty()\n, then \nY\n must be in scope\n  (that is, one of the elements of the \nscope\n array or one of their\n  descendants).\n\n\n\n\n\n\n Rebuild the docs and commit.\n\n\n\n\nCaching interpretation results\n\n\nThis section is efficiency improvements.  Consequently, they can be deferred\nuntil later in the project, and can even be considered optional if we notice\nno performance problems without implementing them.  If you wish to skip them\nfor now, simply move on to the next section, or implement these routines as\nstubs that do nothing yet.\n\n\n\n\n Extend the \nInputStructure\n class with a field called\n   \nlastInterpretation\n, which is initialized to undefined in the\n   constructor.  This field does not need to be part of any serialization\n   or deserialization of instances.\n\n\n Create an \ngetLastInterpretation()\n method that returns the value of\n   that member variable.\n\n\n Create a \nsaveInterpretation(I)\n method in the \nInputStructure\n class\n   that stores the array \nI\n (of zero or more Output Structures) in the\n   \nlastInterpretation\n field.  If no parameter is passed, clear the cached\n   value.\n\n\n Update all documentation in that file to reflect the changes just\n   made.\n\n\n Add to the unit tests for \nInputStructure\ns a few simple tests for\n   these new routines.\n\n\n Add documentation in that file describing the changes just made.\n\n\n Once the unit tests pass, build everything and commit.\n\n\n\n\nHere is another miscellaneous efficiency improvement related to\ninterpretation, so I will place it here:\n\n\n\n\n Create a \nsetChildrenList(newChildren)\n function in the \nStructure\n\n   base class.  It should change as little as possible (maybe nothing) to\n   make the structure's children array equal to the given one.  This lets\n   \ninterpret()\n routines reuse old Output Structures from cache, just\n   adjusting their children lists, rather than constructing new ones, even\n   if their children list changed.  Many \ninterpret()\n routines may\n   therefore be simply \nlastInterpretation.setChildrenList(childResults)\n\n   followed by returning the last interpretation again.  This will often\n   just verify that the children list is already correct, change nothing,\n   and move on.\n\n\n Add to the unit tests for this new routine.\n\n\n Add documentation in the \nStructure\n module describing the new\n   routine.\n\n\n Once the unit tests pass, build everything and commit.\n\n\n\n\nBuilding recursive interpretation\n\n\n\n\n Create a \nrecursiveInterpret\n routine in the \nInputStructure\n class\n   that takes two arguments, \naccessibles\n (with the same meaning as in the\n   \ninterpret\n routine) and \nscope\n (which should be the list of top-level\n   structures in the scope of the object in which the function is being\n   invoked).  Both arguments should default to an empty array.\n   Pseudocode:\n\n\n\n\n// use the cache if it's there:\nif my lastInterpretation() is not undefined, return that and quit\notherwise...\n// remember the size of accessibles for later:\nlet L = the current length of the accessibles array.\n// we will be recursively computing child result arrays,\n// and will want to keep a list of them, so initialize that list to empty:\nlet allChildResults = [ ]\n// we need to pass those children their scopes as well, so start with:\nlet childScope = a shallow copy of the list of children\n// now the loop for the recursive work:\nfor each child C of X do the following:\n    // update the child scope list by popping off its first element:\n    childScope.shift()\n    // do the recursion.\n    // note that for the first child, the same list of accessibles for the\n    // parent applies to that child:\n    let childResult = C.recursiveInterpret( accessibles, childScope )\n    // but for later children, more things are accessible.  specifically,\n    // anything just created by interpreting C should be accessible to\n    // C.nextSibling(), so:\n    let accessibles = the concatenation of accessibles\n        with childResult (thus extending accessibles)\n    // and of course remember the result of the recursive call we just made:\n    append childResult as a new entry to the end of allChildResults\n        // (which is an array of arrays)\n// now that we're done recurring,\n// we want to restore the accessibles array to its old state:\nlet accessibles = just the first L entries of accessibles\n    // (restoring it to what it was at the start of this routine)\n// this is because we will now ask this node X to interpret itself in\n// light of (a) what's accessible to it and (b) all the recursive\n// results of interpreting its children.\n// So we need the right accessibles array to do this:\nsaveInterpretation(\n    X.interpret( accessibles, allChildResults, childScope ) )\nmark X as no longer dirty\nthen return lastInterpretation() as the result of this function\n\n\n\n\n\n\n Add documentation in that file describing the changes just made.\n\n\n Extend the unit tests for the \nInputStructure\n module to include some\n   calls to this routine, passing it various example parameters and\n   verifying that it does its job as specified.\n\n\n Write more unit tests that create and register some dummy subclasses\n   of \nInputStructure\n that have example custom \ninterpret\n routines.\n   Verify that those routines get called and do exactly what's expected in\n   the creation of their portion of the Output Tree.  Ensure you test a\n   variety of different kinds of \ninterpret\n routines, including ones that\n   copy or create attributes, delete children, don't include the default\n   wrapper, etc.\n\n\n Add documentation in that test file describing the changes just made.\n\n\n Once the unit tests pass, build everything and commit.\n\n\n\n\nThe remainder of this section is efficiency improvements.  Consequently,\nthey can be deferred until later in the project, and can even be considered\noptional if we notice no performance problems without implementing them.  If\nyou wish to skip them for now, simply jump to the last few tasks in this\nsection, about unit tests and documentation.\n\n\n\n\n Create a subclass of \nOutputStructure\n, in the \nOutputStructure\n\n   module, called \nInterpretationDirective\n.\n\n\n Add documentation explaining what it is and will do (though that\n   documentation can grow with time).\n\n\n Ensure that the \nInterpretationDirective\n subclass registers itself\n   with the serialization code, as\n   \nthe documentation here\n\n   describes.  (That is, use a line like\n   \nclassName : Structure.addSubclass 'InterpretationDirective', InterpretationDirective\n in\n   the \nInterpretationDirective\n class code.)\n\n\n Create a new unit test file for \nInterpretationDirective\ns that is\n   extremely basic, just testing to be sure that the symbol\n   \nInterpretationDirective\n is defined at the global scope and creates\n   things that are instances of the \nInterpretationDirective\n class.\n\n\n Add documentation for that unit test file, following the pattern\n   established in the documentation of other unit test files in this\n   repository.\n\n\n Create a subclass \nFilterableArray\n of \nArray\n that, at construction\n   time, is given a predicate.  It stores, internally, a filtered version of\n   itself, which is initialized to the empty array.  It guarantees to keep\n   this filtered version correct iff it is manipulated only through calls to\n   its \npush()\n and \npop()\n routines, which we override below.\n\n\n Override \nFilterableArray::push()\n to do an ordinary \nArray::push()\n\n   and then also a push on the internal filtered version iff the predicate\n   holds of the new item.\n\n\n Override \nFilterableArray::pop()\n to do an ordinary \nArray::pop()\n\n   and then also a pop on the internal filtered version iff the object\n   popped was also on the end of that array.\n\n\n Add a new method \nFilterableArray::filtered()\n that returns the\n   filtered version.\n\n\n Update the default version of \nrecursiveInterpret()\n to create the\n   \naccessibles\n array as an instance of \nFilterableArray\n, with the\n   predicate being whether the Structure is an instance of the\n   \nInterpretationDirective\n class.  Ensure that adding items to the array\n   and removing them from it are done with calls to \npush()\n and \npop()\n.\n\n\n Document this so that later implementations of \ninterpret()\n can be\n   faster by leveraging \naccessibles.filtered()\n rather than the entire\n   \naccessibles\n array.\n\n\n Ensure all the unit tests still pass.\n\n\n Add new unit tests for the \nFilterableArray\n class independently of\n   the rest of the LDE.\n\n\n Add some new unit tests that verify that \naccessibles.filtered()\n is\n   exactly what it should be (i.e., the Interpretation Directive predicate\n   is being used correctly).\n\n\n Once the unit tests pass, build everything and commit.\n\n\n\n\nTracking origins\n\n\n\n\n Create a class variable in the \nInputStructure\n class called\n   \ninstancesBeingInterpreted\n that is initialized to the empty array.\n\n\n Extend the \nrecursiveInterpret\n routine so that, before each call to\n   \nX.interpret()\n, it pushes \nX\n onto \ninstanceBeingInterpreted\n, then pops\n   after \nX.interpret()\n is complete.\n\n\n Extend the constructor for \nOutputStructure\n nodes so that, if the\n   global \nInputStructure\n class is defined, and its\n   \ninstanceBeingInterpreted\n array is non-empty, then its last entry is\n   stored within the newly constructed \nOutputStructure\n in a field called\n   \norigin\n.  Otherwise, \norigin\n should be undefined (or null, whatever).\n\n\n Override the \nOutputStructure\n's routine for creating connections so\n   that, in addition to forming the connection, it also adds to its JSON\n   data an \n_origin\n key whose value is the unique id in the Input Tree of\n   the last entry on the \ninstanceBeingInterpreted\n array, if one exists.\n   (If not, leave the \n_origin\n field undefined.)\n\n\n Extend the unit tests for the LDE module to verify that Output Trees\n   now have, in each of their nodes, the correct origin node from the Input\n   Tree that gave rise to that \nOutputStructure\n.\n\n\n Once the unit tests pass, build everything and commit.\n\n\n\n\nThe Interpretation Phase\n\n\n\n\n Implement a \nrunInterpretation()\n method in the LDE module.  It\n   should just call \nrecursiveInterpret()\n in the root of the Input Tree,\n   store the result in the global Output Tree object, and then call a\n   callback.\n\n\n Extend that implementation so that it also sends a feedback message\n   when it replaces the Output Tree, indicating that the Input and Output\n   Trees have been updated and are ready for exporting, should the client\n   wish to query them.\n\n\n Extend the unit tests of the LDE to test this new function.  This\n   should just involve taking some of the existing tests of\n   \nrecursiveInterpret()\n and redoing them to use this new name.\n\n\n Extend \nrunModification()\n so that it no longer calls its own\n   callback when complete, but instead calls \nrunInterpretation()\n and\n   passes the callback along to that function.\n\n\n Extend the unit tests to test this feature.\n\n\n Once the unit tests pass, build everything and commit.\n\n\n\n\nAdding security\n\n\nOne of the policies by which interpretation functions must abide is that an\n\nInputStructure\n can call \nmarkDirty()\n only in another \nInputStructure\n\nthat is on the \nscope\n list, or whose ancestor is on the \nscope\n list.  We\nintroduce policing for that policy here, to prevent infinite loops in\ninterpretation.  We rely on the fact that one \nInputStructure\n is in the\n\nscope\n variable of another (which is not the same as scope in the Input\nTree) iff it is interpreted after the other.\n\n\n\n\n Have the \nrunInterpretation()\n method initialize a global variable to\n   an empty array; it will contain the list of instances whose\n   interpretations have begun.\n\n\n Each step in the \nrecursiveInterpret()\n process should begin by\n   adding the \nInputStructure\n being interepreted to that global array and\n   writing a flag into the \nInputStructure\n object itself as well.\n\n\n When \nrunInterpretation()\n calls its callback or quits and restarts\n   the modification phase, erase the flags in all \nInputStructure\n instances\n   in that array, then set the array to empty again.\n\n\n Extend \nmarkDirty()\n in the \nInputStructure\n class so that if the\n   instance has the flag set that indicates that its interpretation has\n   begun, we do not obey the request, but instead send a feedback message\n   about an internal error and also write the error message to the console.\n\n\n\n\nAnother of the policies interpretation must obey is that it should not yield\nan Output Tree in which any one of the \nOutputStructure\n nodes has a\nconnection to a node outside the Output Tree.  We enforce that policy as\nfollows.\n\n\n\n\n Add to the end of the \nrunInterpretation()\n function a full traversal\n   of the newly created Output Tree.  At every subtree, if that node has any\n   connections, examine the other side of the connection, and walk up its\n   ancestor chain to verify that it is in the Output Tree.  If not, sever\n   the connection.\n\n\n Add unit tests of this feature by creating a few different situations\n   in which such an invalid Output Tree might arise, and verifying that the\n   invalid connections (and no others) are removed in each case.\n\n\n Once the unit tests pass, build everything and commit.\n\n\n\n\nDependency support\n\n\n\n\n Create a subclass of \nInputExpression\n, in the \nInputStructure\n\n   module, called \nDependency\n.  It takes an array of \nOutputStructure\n\n   instances at construction time, and stores them.  It provides a getter\n   for that same array, which can be overridden in subclasses to filter the\n   array in cases where it would be helpful to do so.\n\n\n Make its \ninterpret()\n routine simply call the getter, not even\n   bothering to make copies of the results; return the original array it was\n   given at construction time.\n\n\n Add documentation explaining what it is and does.\n\n\n Ensure that the \nDependency\n subclass registers itself with the\n   serialization code, as\n   \nthe documentation here\n\n   describes.  (That is, use a line like\n   \nclassName : Structure.addSubclass 'Dependency', Dependency\n in the\n   \nDependency\n class code.)\n\n\n Create a new unit test file for \nDependency\n instances that not only\n   ensures that the symbol \nDependency\n is defined at the global scope and\n   that its instances are also instances of the \nInputStructure\n class, but\n   also that the \ninterpret()\n routine behaves as intended, including in the\n   context of recursive interpretation of the entire Input Tree.\n\n\n Add documentation for that unit test file, following the pattern\n   established in the documentation of other unit test files in this\n   repository.\n\n\n Once the unit tests pass, build everything and commit.\n\n\n\n\nAPI Documentation\n\n\n\n\n Extend the processing phases page of the API Documentation to include\n   all the work done in this phase, including interpretation.\n\n\n Rebuild docs and commit.", 
            "title": "Phase 5, Interpretation"
        }, 
        {
            "location": "/phase5-interpretation/#lde-design-phase-5-interpretation", 
            "text": "", 
            "title": "LDE Design Phase 5: Interpretation"
        }, 
        {
            "location": "/phase5-interpretation/#content", 
            "text": "In this phase, we implement the Interpretation Phase of the LDE.", 
            "title": "Content"
        }, 
        {
            "location": "/phase5-interpretation/#goal", 
            "text": "The LDE will be able to interpret the Input Tree, creating an Output Tree\nfrom it.", 
            "title": "Goal"
        }, 
        {
            "location": "/phase5-interpretation/#status", 
            "text": "This has not been implemented.  See the tasks below.", 
            "title": "Status"
        }, 
        {
            "location": "/phase5-interpretation/#building-interpretation-routines", 
            "text": "Create an  interpret  routine in the  InputStructure  class that\n   takes three arguments,  accessibles  (a list of  OutputStructure s\n   accessible to the  InputStructure  in question),  childResults  (a list\n   of lists of  OutputStructure  instances that were generated by recursive\n   interpretation calls), and  scope  (a list of the top-level structures\n   that are in the scope of the one in which  interpret  was invoked).  The\n   implementation in this base class should be to create a generic\n    OutputStructure  instance and flatten all the  childResults  arrays\n   into it as children, in order.  Pseudocode:   let result = new OutputStructure() // plain vanilla wrapper node\nfor each childArray in childResults:\n    for each node in childArray:\n        result.appendChild( node ) // put everything in it\n        return [ result ] // return an array of exactly one tree    Add documentation in that file describing the changes just made.   Extend the unit tests for the  InputStructure  module to include some\n   calls to this routine, passing it various example parameters and\n   verifying that it does its job as specified.   Add documentation in that test file describing the changes just made.   Once the unit tests pass, build everything and commit.   Add documentation stating the limitations on how subclasses are\n   permitted to override the  interpret  routine from the  InputStructure \n   class.  Specifically, the following rules must be obeyed:  The routine should depend upon only the data passed to it in its\n  first two parameters.  If  X.interpret()  calls  Y.markDirty() , then  Y  must be in scope\n  (that is, one of the elements of the  scope  array or one of their\n  descendants).     Rebuild the docs and commit.", 
            "title": "Building interpretation routines"
        }, 
        {
            "location": "/phase5-interpretation/#caching-interpretation-results", 
            "text": "This section is efficiency improvements.  Consequently, they can be deferred\nuntil later in the project, and can even be considered optional if we notice\nno performance problems without implementing them.  If you wish to skip them\nfor now, simply move on to the next section, or implement these routines as\nstubs that do nothing yet.    Extend the  InputStructure  class with a field called\n    lastInterpretation , which is initialized to undefined in the\n   constructor.  This field does not need to be part of any serialization\n   or deserialization of instances.   Create an  getLastInterpretation()  method that returns the value of\n   that member variable.   Create a  saveInterpretation(I)  method in the  InputStructure  class\n   that stores the array  I  (of zero or more Output Structures) in the\n    lastInterpretation  field.  If no parameter is passed, clear the cached\n   value.   Update all documentation in that file to reflect the changes just\n   made.   Add to the unit tests for  InputStructure s a few simple tests for\n   these new routines.   Add documentation in that file describing the changes just made.   Once the unit tests pass, build everything and commit.   Here is another miscellaneous efficiency improvement related to\ninterpretation, so I will place it here:    Create a  setChildrenList(newChildren)  function in the  Structure \n   base class.  It should change as little as possible (maybe nothing) to\n   make the structure's children array equal to the given one.  This lets\n    interpret()  routines reuse old Output Structures from cache, just\n   adjusting their children lists, rather than constructing new ones, even\n   if their children list changed.  Many  interpret()  routines may\n   therefore be simply  lastInterpretation.setChildrenList(childResults) \n   followed by returning the last interpretation again.  This will often\n   just verify that the children list is already correct, change nothing,\n   and move on.   Add to the unit tests for this new routine.   Add documentation in the  Structure  module describing the new\n   routine.   Once the unit tests pass, build everything and commit.", 
            "title": "Caching interpretation results"
        }, 
        {
            "location": "/phase5-interpretation/#building-recursive-interpretation", 
            "text": "Create a  recursiveInterpret  routine in the  InputStructure  class\n   that takes two arguments,  accessibles  (with the same meaning as in the\n    interpret  routine) and  scope  (which should be the list of top-level\n   structures in the scope of the object in which the function is being\n   invoked).  Both arguments should default to an empty array.\n   Pseudocode:   // use the cache if it's there:\nif my lastInterpretation() is not undefined, return that and quit\notherwise...\n// remember the size of accessibles for later:\nlet L = the current length of the accessibles array.\n// we will be recursively computing child result arrays,\n// and will want to keep a list of them, so initialize that list to empty:\nlet allChildResults = [ ]\n// we need to pass those children their scopes as well, so start with:\nlet childScope = a shallow copy of the list of children\n// now the loop for the recursive work:\nfor each child C of X do the following:\n    // update the child scope list by popping off its first element:\n    childScope.shift()\n    // do the recursion.\n    // note that for the first child, the same list of accessibles for the\n    // parent applies to that child:\n    let childResult = C.recursiveInterpret( accessibles, childScope )\n    // but for later children, more things are accessible.  specifically,\n    // anything just created by interpreting C should be accessible to\n    // C.nextSibling(), so:\n    let accessibles = the concatenation of accessibles\n        with childResult (thus extending accessibles)\n    // and of course remember the result of the recursive call we just made:\n    append childResult as a new entry to the end of allChildResults\n        // (which is an array of arrays)\n// now that we're done recurring,\n// we want to restore the accessibles array to its old state:\nlet accessibles = just the first L entries of accessibles\n    // (restoring it to what it was at the start of this routine)\n// this is because we will now ask this node X to interpret itself in\n// light of (a) what's accessible to it and (b) all the recursive\n// results of interpreting its children.\n// So we need the right accessibles array to do this:\nsaveInterpretation(\n    X.interpret( accessibles, allChildResults, childScope ) )\nmark X as no longer dirty\nthen return lastInterpretation() as the result of this function    Add documentation in that file describing the changes just made.   Extend the unit tests for the  InputStructure  module to include some\n   calls to this routine, passing it various example parameters and\n   verifying that it does its job as specified.   Write more unit tests that create and register some dummy subclasses\n   of  InputStructure  that have example custom  interpret  routines.\n   Verify that those routines get called and do exactly what's expected in\n   the creation of their portion of the Output Tree.  Ensure you test a\n   variety of different kinds of  interpret  routines, including ones that\n   copy or create attributes, delete children, don't include the default\n   wrapper, etc.   Add documentation in that test file describing the changes just made.   Once the unit tests pass, build everything and commit.   The remainder of this section is efficiency improvements.  Consequently,\nthey can be deferred until later in the project, and can even be considered\noptional if we notice no performance problems without implementing them.  If\nyou wish to skip them for now, simply jump to the last few tasks in this\nsection, about unit tests and documentation.    Create a subclass of  OutputStructure , in the  OutputStructure \n   module, called  InterpretationDirective .   Add documentation explaining what it is and will do (though that\n   documentation can grow with time).   Ensure that the  InterpretationDirective  subclass registers itself\n   with the serialization code, as\n    the documentation here \n   describes.  (That is, use a line like\n    className : Structure.addSubclass 'InterpretationDirective', InterpretationDirective  in\n   the  InterpretationDirective  class code.)   Create a new unit test file for  InterpretationDirective s that is\n   extremely basic, just testing to be sure that the symbol\n    InterpretationDirective  is defined at the global scope and creates\n   things that are instances of the  InterpretationDirective  class.   Add documentation for that unit test file, following the pattern\n   established in the documentation of other unit test files in this\n   repository.   Create a subclass  FilterableArray  of  Array  that, at construction\n   time, is given a predicate.  It stores, internally, a filtered version of\n   itself, which is initialized to the empty array.  It guarantees to keep\n   this filtered version correct iff it is manipulated only through calls to\n   its  push()  and  pop()  routines, which we override below.   Override  FilterableArray::push()  to do an ordinary  Array::push() \n   and then also a push on the internal filtered version iff the predicate\n   holds of the new item.   Override  FilterableArray::pop()  to do an ordinary  Array::pop() \n   and then also a pop on the internal filtered version iff the object\n   popped was also on the end of that array.   Add a new method  FilterableArray::filtered()  that returns the\n   filtered version.   Update the default version of  recursiveInterpret()  to create the\n    accessibles  array as an instance of  FilterableArray , with the\n   predicate being whether the Structure is an instance of the\n    InterpretationDirective  class.  Ensure that adding items to the array\n   and removing them from it are done with calls to  push()  and  pop() .   Document this so that later implementations of  interpret()  can be\n   faster by leveraging  accessibles.filtered()  rather than the entire\n    accessibles  array.   Ensure all the unit tests still pass.   Add new unit tests for the  FilterableArray  class independently of\n   the rest of the LDE.   Add some new unit tests that verify that  accessibles.filtered()  is\n   exactly what it should be (i.e., the Interpretation Directive predicate\n   is being used correctly).   Once the unit tests pass, build everything and commit.", 
            "title": "Building recursive interpretation"
        }, 
        {
            "location": "/phase5-interpretation/#tracking-origins", 
            "text": "Create a class variable in the  InputStructure  class called\n    instancesBeingInterpreted  that is initialized to the empty array.   Extend the  recursiveInterpret  routine so that, before each call to\n    X.interpret() , it pushes  X  onto  instanceBeingInterpreted , then pops\n   after  X.interpret()  is complete.   Extend the constructor for  OutputStructure  nodes so that, if the\n   global  InputStructure  class is defined, and its\n    instanceBeingInterpreted  array is non-empty, then its last entry is\n   stored within the newly constructed  OutputStructure  in a field called\n    origin .  Otherwise,  origin  should be undefined (or null, whatever).   Override the  OutputStructure 's routine for creating connections so\n   that, in addition to forming the connection, it also adds to its JSON\n   data an  _origin  key whose value is the unique id in the Input Tree of\n   the last entry on the  instanceBeingInterpreted  array, if one exists.\n   (If not, leave the  _origin  field undefined.)   Extend the unit tests for the LDE module to verify that Output Trees\n   now have, in each of their nodes, the correct origin node from the Input\n   Tree that gave rise to that  OutputStructure .   Once the unit tests pass, build everything and commit.", 
            "title": "Tracking origins"
        }, 
        {
            "location": "/phase5-interpretation/#the-interpretation-phase", 
            "text": "Implement a  runInterpretation()  method in the LDE module.  It\n   should just call  recursiveInterpret()  in the root of the Input Tree,\n   store the result in the global Output Tree object, and then call a\n   callback.   Extend that implementation so that it also sends a feedback message\n   when it replaces the Output Tree, indicating that the Input and Output\n   Trees have been updated and are ready for exporting, should the client\n   wish to query them.   Extend the unit tests of the LDE to test this new function.  This\n   should just involve taking some of the existing tests of\n    recursiveInterpret()  and redoing them to use this new name.   Extend  runModification()  so that it no longer calls its own\n   callback when complete, but instead calls  runInterpretation()  and\n   passes the callback along to that function.   Extend the unit tests to test this feature.   Once the unit tests pass, build everything and commit.", 
            "title": "The Interpretation Phase"
        }, 
        {
            "location": "/phase5-interpretation/#adding-security", 
            "text": "One of the policies by which interpretation functions must abide is that an InputStructure  can call  markDirty()  only in another  InputStructure \nthat is on the  scope  list, or whose ancestor is on the  scope  list.  We\nintroduce policing for that policy here, to prevent infinite loops in\ninterpretation.  We rely on the fact that one  InputStructure  is in the scope  variable of another (which is not the same as scope in the Input\nTree) iff it is interpreted after the other.    Have the  runInterpretation()  method initialize a global variable to\n   an empty array; it will contain the list of instances whose\n   interpretations have begun.   Each step in the  recursiveInterpret()  process should begin by\n   adding the  InputStructure  being interepreted to that global array and\n   writing a flag into the  InputStructure  object itself as well.   When  runInterpretation()  calls its callback or quits and restarts\n   the modification phase, erase the flags in all  InputStructure  instances\n   in that array, then set the array to empty again.   Extend  markDirty()  in the  InputStructure  class so that if the\n   instance has the flag set that indicates that its interpretation has\n   begun, we do not obey the request, but instead send a feedback message\n   about an internal error and also write the error message to the console.   Another of the policies interpretation must obey is that it should not yield\nan Output Tree in which any one of the  OutputStructure  nodes has a\nconnection to a node outside the Output Tree.  We enforce that policy as\nfollows.    Add to the end of the  runInterpretation()  function a full traversal\n   of the newly created Output Tree.  At every subtree, if that node has any\n   connections, examine the other side of the connection, and walk up its\n   ancestor chain to verify that it is in the Output Tree.  If not, sever\n   the connection.   Add unit tests of this feature by creating a few different situations\n   in which such an invalid Output Tree might arise, and verifying that the\n   invalid connections (and no others) are removed in each case.   Once the unit tests pass, build everything and commit.", 
            "title": "Adding security"
        }, 
        {
            "location": "/phase5-interpretation/#dependency-support", 
            "text": "Create a subclass of  InputExpression , in the  InputStructure \n   module, called  Dependency .  It takes an array of  OutputStructure \n   instances at construction time, and stores them.  It provides a getter\n   for that same array, which can be overridden in subclasses to filter the\n   array in cases where it would be helpful to do so.   Make its  interpret()  routine simply call the getter, not even\n   bothering to make copies of the results; return the original array it was\n   given at construction time.   Add documentation explaining what it is and does.   Ensure that the  Dependency  subclass registers itself with the\n   serialization code, as\n    the documentation here \n   describes.  (That is, use a line like\n    className : Structure.addSubclass 'Dependency', Dependency  in the\n    Dependency  class code.)   Create a new unit test file for  Dependency  instances that not only\n   ensures that the symbol  Dependency  is defined at the global scope and\n   that its instances are also instances of the  InputStructure  class, but\n   also that the  interpret()  routine behaves as intended, including in the\n   context of recursive interpretation of the entire Input Tree.   Add documentation for that unit test file, following the pattern\n   established in the documentation of other unit test files in this\n   repository.   Once the unit tests pass, build everything and commit.", 
            "title": "Dependency support"
        }, 
        {
            "location": "/phase5-interpretation/#api-documentation", 
            "text": "Extend the processing phases page of the API Documentation to include\n   all the work done in this phase, including interpretation.   Rebuild docs and commit.", 
            "title": "API Documentation"
        }, 
        {
            "location": "/phase6-labels/", 
            "text": "We have designed the work on the Lurch Deductive Engine (LDE) to progress in\nphases.  The idea is that each phase ends with a completed whole that can be\ntested in that state, and that provides more features than the previous\nstate did.  By the time the final phase is complete, the LDE will be a\nrobust and useful product.\n\n\nLDE Design Phase 6: Labels\n\n\nContent\n\n\nIn this phase, we make it possible for \nOutputStructure\n instances to be\nlabeled.\n\n\nGoal\n\n\nThe LDE will be able to look up \nOutputStructure\n instances by the labels\nattached to them, and we will have a convention for citing labels\nestablished and implemented.\n\n\nStatus\n\n\nThis has not been implemented.  See the tasks below.\n\n\nLabeling \nOutputStructure\n instances\n\n\n\n\n Create in the \nOutputStructure\n base class a function called\n   \nhasLabel(str)\n that returns false always.\n\n\n Create a function \naddLabel(targets)\n in the \nInputStructure\n class.\n   It should accept an array of \nOutputStructure\n instances, and should loop\n   through all of them, obeying the following conventions.\n\n\nIf the \nInputStructure\n has an attribute with key \"label regex\", then\n  place into the \nOutputStructure\ns a \nhasLabel(str)\n function that\n  tests the given string against the given regular expression.\n\n\nIf the \nInputStructure\n has an attribute with key \"label regex flags\",\n  then apply those to the regular expression object you create in the\n  previous item.\n\n\nIf the \nInputStructure\n has an attribute with key \"label targets\",\n  then call its value $V$ and apply the above techniques to only those\n  targets whose indices are on the $V$, when $V$ is treated as an array.\n\n\n\n\n\n\n Add documentation in that file describing the changes just made.\n\n\n Extend the unit tests for the \nInputStructure\n module to include some\n   calls to this routine, passing it various example parameters and\n   verifying that it does its job as specified.\n\n\n Extend \nrecursiveInterpret()\n so that it calls this function in an\n   \nInputStructure\n as soon as it has completed \ninterpret()\n on that\n   structure, passing in the set of interpretation results.\n\n\n Extend the unit tests to ensure that this is now a part of the\n   Interpretation Phase.\n\n\n Once the unit tests pass, build everything and commit.\n\n\n\n\nCitations\n\n\n\n\n Create a stub function \ncopyCitations(targets)\n in the\n   \nInputStructure\n base class, but at first it should do nothing.\n\n\n Establish a convention for use in the Input Tree for citing reasons\n   and premises and document that convention above the stub function just\n   created.  Possibilities include the following.\n\n\nAn attribute with key \"premise citations\" indicates that its value is\n  a list of premise citations by label (that should be looked up with\n  the labels feature described above).  If its value is an array, it\n  will be treated as an array of strings.  If its value is not an array,\n  it will be converted to a string and treated as a one-element array\n  containing that string.\n\n\nAn attribute with key \"reason citations\" behaves the same way, but\n  with obviously different semantics.\n\n\nA connection of type \"premise citation\" indicates that the source\n  wants to cite the target as a premise.\n\n\nA connection of type \"reason citation\" behaves the same way, but with\n  obviously different semantics.\n\n\n\n\n\n\n Implement the \ncopyCitations(targets)\n function to copy all of the\n   data indicated by those document conventions from the \nInputStructure\n in\n   which it's called into all of the given targets, which will be an array\n   of \nOutputStructure\n instances just created from the given\n   \nInputStructure\n.\n\n\nNote that \nX.copyCitations(targets)\n should copy all citations that go\n  to \nor come from\n nodes \nY\n that are before (or equal to) \nX\n in the\n  Input Tree.\n\n\nIt can make the connections in the Output Tree by looking up the last\n  interpretation of such nodes \nY\n.\n\n\nIf \nX\n has connections to or from nodes that appear after \nX\n in the\n  tree, then those nodes will create the connections later, when\n  recursive interpretation visits them.\n\n\n\n\n\n\n Extend \nrecursiveInterpret()\n so that it calls this function in an\n   \nInputStructure\n as soon as it has completed \ninterpret()\n on that\n   structure, passing in the set of interpretation results.\n\n\n Extend the unit tests to ensure that this is now a part of the\n   Interpretation Phase.  Be sure to test connections that go both\n   directions (forward and backward) in the Input Tree and ensure that they\n   are both correctly copied to the Output Tree.  Ensure that no connection\n   is copied redundantly.\n\n\n Once the unit tests pass, build everything and commit.\n\n\n\n\nLookup\n\n\n\n\n Create a class method \nlookup(string,accessibles)\n in the\n   \nOutputStructure\n class, which loops backwards through the list of\n   \naccessibles\n, trying to find one that \nhasLabel()\n the given \nstring\n.\n   It returns the latest one found, or null if there is none.\n\n\n Create an instance method \nlookup(string)\n in the \nOutputStructure\n\n   class, which loops backwards through the list of structures accessible to\n   the one on which it was called, trying to find one that \nhasLabel()\n the\n   given \nstring\n.  It returns the first one encountered, or null if there\n   is none.\n\n\n\n\nThe remainder of this section is efficiency improvements.  Consequently,\nthey can be deferred until later in the project, and can even be considered\noptional if we notice no performance problems without implementing them.  If\nyou wish to skip them for now, simply jump to the last few tasks in this\nsection, about unit tests and documentation.\n\n\n\n\n Extend the \nDependency\n subclass of IS so that it marks all of its\n   interpretation results with an attribute, flagging them as having come\n   from a dependency.  Let us call such \nOutputStructures\n \"fromdeps,\" and\n   \nOutputStructures\n that are not so marked we will call \"non-fromdeps.\"\n\n\n We will be creating a cache to speed up lookups into dependencies.\n   To support this, create an LDE-global variable\n   \nLDE.dependencyLookupCache\n, and initialize it to the empty object.\n\n\n Extend the \nlookup(string)\n routine so that any time it is called\n   from a non-fromdep, and the result is either null or a fromdep, then we\n   store in \nLDE.dependencyLookupCache\n the association of the given\n   \nstring\n as a key with the result (a fromdep or null) as the value.\n   Future calls of \nlookup()\n from a non-fromdep can be sped up by, whenever\n   their search first comes upon a fromdep, if there is a cached result\n   (which can be null) for the \nstring\n they're searching, just return that\n   immediately.  This work is not yet correct without the next bullet point.\n\n\n Extend the \nDependency\n subclass of IS so that, if it ever needs to\n   actually reload content from the dependency, and thus possibly change the\n   set of fromdeps it placed in the Output Tree, then it should also revert\n   the value of \nLDE.dependencyLookupCache\n to the empty object.\n\n\n Extend the unit tests to ensure that this works.  This can be done by\n   defining a custom \nhasLabel()\n routine that records when it was called,\n   and ensuring it is called only once for many lookups.\n\n\n Once the unit tests pass, build everything and commit.\n\n\n\n\nAPI Documentation\n\n\n\n\n Extend the \nOutputStructure\n page of the API Documentation to include\n   all the work done in this phase.\n\n\n Rebuild docs and commit.", 
            "title": "Phase 6, Labels"
        }, 
        {
            "location": "/phase6-labels/#lde-design-phase-6-labels", 
            "text": "", 
            "title": "LDE Design Phase 6: Labels"
        }, 
        {
            "location": "/phase6-labels/#content", 
            "text": "In this phase, we make it possible for  OutputStructure  instances to be\nlabeled.", 
            "title": "Content"
        }, 
        {
            "location": "/phase6-labels/#goal", 
            "text": "The LDE will be able to look up  OutputStructure  instances by the labels\nattached to them, and we will have a convention for citing labels\nestablished and implemented.", 
            "title": "Goal"
        }, 
        {
            "location": "/phase6-labels/#status", 
            "text": "This has not been implemented.  See the tasks below.", 
            "title": "Status"
        }, 
        {
            "location": "/phase6-labels/#labeling-outputstructure-instances", 
            "text": "Create in the  OutputStructure  base class a function called\n    hasLabel(str)  that returns false always.   Create a function  addLabel(targets)  in the  InputStructure  class.\n   It should accept an array of  OutputStructure  instances, and should loop\n   through all of them, obeying the following conventions.  If the  InputStructure  has an attribute with key \"label regex\", then\n  place into the  OutputStructure s a  hasLabel(str)  function that\n  tests the given string against the given regular expression.  If the  InputStructure  has an attribute with key \"label regex flags\",\n  then apply those to the regular expression object you create in the\n  previous item.  If the  InputStructure  has an attribute with key \"label targets\",\n  then call its value $V$ and apply the above techniques to only those\n  targets whose indices are on the $V$, when $V$ is treated as an array.     Add documentation in that file describing the changes just made.   Extend the unit tests for the  InputStructure  module to include some\n   calls to this routine, passing it various example parameters and\n   verifying that it does its job as specified.   Extend  recursiveInterpret()  so that it calls this function in an\n    InputStructure  as soon as it has completed  interpret()  on that\n   structure, passing in the set of interpretation results.   Extend the unit tests to ensure that this is now a part of the\n   Interpretation Phase.   Once the unit tests pass, build everything and commit.", 
            "title": "Labeling OutputStructure instances"
        }, 
        {
            "location": "/phase6-labels/#citations", 
            "text": "Create a stub function  copyCitations(targets)  in the\n    InputStructure  base class, but at first it should do nothing.   Establish a convention for use in the Input Tree for citing reasons\n   and premises and document that convention above the stub function just\n   created.  Possibilities include the following.  An attribute with key \"premise citations\" indicates that its value is\n  a list of premise citations by label (that should be looked up with\n  the labels feature described above).  If its value is an array, it\n  will be treated as an array of strings.  If its value is not an array,\n  it will be converted to a string and treated as a one-element array\n  containing that string.  An attribute with key \"reason citations\" behaves the same way, but\n  with obviously different semantics.  A connection of type \"premise citation\" indicates that the source\n  wants to cite the target as a premise.  A connection of type \"reason citation\" behaves the same way, but with\n  obviously different semantics.     Implement the  copyCitations(targets)  function to copy all of the\n   data indicated by those document conventions from the  InputStructure  in\n   which it's called into all of the given targets, which will be an array\n   of  OutputStructure  instances just created from the given\n    InputStructure .  Note that  X.copyCitations(targets)  should copy all citations that go\n  to  or come from  nodes  Y  that are before (or equal to)  X  in the\n  Input Tree.  It can make the connections in the Output Tree by looking up the last\n  interpretation of such nodes  Y .  If  X  has connections to or from nodes that appear after  X  in the\n  tree, then those nodes will create the connections later, when\n  recursive interpretation visits them.     Extend  recursiveInterpret()  so that it calls this function in an\n    InputStructure  as soon as it has completed  interpret()  on that\n   structure, passing in the set of interpretation results.   Extend the unit tests to ensure that this is now a part of the\n   Interpretation Phase.  Be sure to test connections that go both\n   directions (forward and backward) in the Input Tree and ensure that they\n   are both correctly copied to the Output Tree.  Ensure that no connection\n   is copied redundantly.   Once the unit tests pass, build everything and commit.", 
            "title": "Citations"
        }, 
        {
            "location": "/phase6-labels/#lookup", 
            "text": "Create a class method  lookup(string,accessibles)  in the\n    OutputStructure  class, which loops backwards through the list of\n    accessibles , trying to find one that  hasLabel()  the given  string .\n   It returns the latest one found, or null if there is none.   Create an instance method  lookup(string)  in the  OutputStructure \n   class, which loops backwards through the list of structures accessible to\n   the one on which it was called, trying to find one that  hasLabel()  the\n   given  string .  It returns the first one encountered, or null if there\n   is none.   The remainder of this section is efficiency improvements.  Consequently,\nthey can be deferred until later in the project, and can even be considered\noptional if we notice no performance problems without implementing them.  If\nyou wish to skip them for now, simply jump to the last few tasks in this\nsection, about unit tests and documentation.    Extend the  Dependency  subclass of IS so that it marks all of its\n   interpretation results with an attribute, flagging them as having come\n   from a dependency.  Let us call such  OutputStructures  \"fromdeps,\" and\n    OutputStructures  that are not so marked we will call \"non-fromdeps.\"   We will be creating a cache to speed up lookups into dependencies.\n   To support this, create an LDE-global variable\n    LDE.dependencyLookupCache , and initialize it to the empty object.   Extend the  lookup(string)  routine so that any time it is called\n   from a non-fromdep, and the result is either null or a fromdep, then we\n   store in  LDE.dependencyLookupCache  the association of the given\n    string  as a key with the result (a fromdep or null) as the value.\n   Future calls of  lookup()  from a non-fromdep can be sped up by, whenever\n   their search first comes upon a fromdep, if there is a cached result\n   (which can be null) for the  string  they're searching, just return that\n   immediately.  This work is not yet correct without the next bullet point.   Extend the  Dependency  subclass of IS so that, if it ever needs to\n   actually reload content from the dependency, and thus possibly change the\n   set of fromdeps it placed in the Output Tree, then it should also revert\n   the value of  LDE.dependencyLookupCache  to the empty object.   Extend the unit tests to ensure that this works.  This can be done by\n   defining a custom  hasLabel()  routine that records when it was called,\n   and ensuring it is called only once for many lookups.   Once the unit tests pass, build everything and commit.", 
            "title": "Lookup"
        }, 
        {
            "location": "/phase6-labels/#api-documentation", 
            "text": "Extend the  OutputStructure  page of the API Documentation to include\n   all the work done in this phase.   Rebuild docs and commit.", 
            "title": "API Documentation"
        }, 
        {
            "location": "/phase7-validation/", 
            "text": "We have designed the work on the Lurch Deductive Engine (LDE) to progress in\nphases.  The idea is that each phase ends with a completed whole that can be\ntested in that state, and that provides more features than the previous\nstate did.  By the time the final phase is complete, the LDE will be a\nrobust and useful product.\n\n\nLDE Design Phase 7: Validation\n\n\nContent\n\n\nIn this phase, we define the Validation Phase.\n\n\nGoal\n\n\nThe LDE will be able to follow the Interpretation Phase with the Validation\nPhase, giving semantic feedback about the validity of steps of work.\n\n\nStatus\n\n\nThis has not been implemented.  See the tasks below.\n\n\nMaking background threads easy to use\n\n\n\n\n Create a worker script that enables us to create instances of\n   \nWebWorker\ns who are able to respond to a variety of functions for\n   installing various routines and data in the workers, including:\n\n\nworker.installScript(filename)\n\n\nworker.installFunction(varname,func)\n\n\nworker.installData(key,value)\n\n\nworker.uninstallData(key)\n\n\nworker.run(code,callback)\n\n\nworker.reboot(callback)\n (which calls \nterminate()\n in the internal\n  \nWebWorker\n instance, then discards it and replaces it with a new one)\n\n\n\n\n\n\n Create a new unit testing file for these advanced \nWebWorker\ns,\n   documenting it in the same style as the rest of the test suite.\n\n\n Once it is robust and all tests pass, commit the changes.\n\n\n Create a global variable in the LDE that holds a pool of these\n   workers, with a function that lets you specify the size of the pool.\n   It should initialize itself, by default, to the number of threads the\n   CPU supports, minus 1 for the main thread.  (The minimum value is 1.)\n\n\n Create a function in each worker for marking it available or\n   unavailable.\n\n\n Create a function in the worker pool for getting the next available\n   worker, or null if there isn't one.\n\n\n Add and document tests for these new features.\n\n\n\n\nThe Validation Phase\n\n\n\n\n Create a global validation pool in the LDE, which is a priority queue\n   that comes with a routine for adding an \nOutputStructure\n instance to the\n   queue, after first verifying that it has a \nvalidate()\n routine.\n\n\n Create a routine that, if a worker is available, dequeues a structure\n   from the validation pool and calls its validation routine, passing it the\n   available worker.  If one is not available, this routine does nothing.\n   In the callback that routine passes the validation routine, place the\n   worker back on the list of available workers.  Also, the routine does\n   nothing in the case where modification or interpretation is currently\n   running.  We expect to define validation routines somewhat like this:\n\n\n\n\nMyOutputStructure.validate = function ( callback, worker ) {\n    worker.installScript( \nsome script file\n );\n    worker.installFunction( \nfoo\n, foo );\n    worker.installData( \nkey\n, value );\n    worker.run( \nsome code\n, function ( result, error ) {\n        // here, generate feedback from result and/or error\n        callback();\n    } );\n};\n\n\n\n\n\n\n Call that dequeueing routine whenever a worker becomes available.\n\n\n Make unit tests for this much functionality, in a new unit testing\n   file for validation specifically.  Document such tests the usual way.\n\n\n Extend the enqueue process so that if a structure is already\n   enqueued, then enqueueing again does nothing.\n\n\n Extend the enqueue process so that if the structure being enqueued,\n   while not currently on the queue, has its validation routine still\n   running in a worker, then we find and reboot that worker, mark the\n   structure as no longer being validated, and \nthen\n enqueue it as usual.\n\n\n Create unit tests that ensure these behaviors work.\n\n\n Create a default implementation of \njustChanged()\n in the\n   \nOutputStructure\n class that does the following things.\n\n\nIf the OS has a validate routine, add it to the global pool.  If its\n  origin IS has a validation priority, use that, otherwise use zero.  If\n  its origin has a validation priority of null, skip this step (no\n  enqueueing).  If you enqueue the OS, emit feedback saying its\n  validation is being recomputed.  If it had null priority, emit\n  feedback saying that its validation is being skipped.\n\n\nIf any OS in the scope of this one cites this one, then add that other\n  OS to the validation pool.  Set priorities and emit feedback in the\n  same way.\n\n\n\n\n\n\n Call the dequeueing routine whenever interpretation ends.\n\n\n Write unit tests to ensure that the already-tested validation\n   features still function when they are automatically triggered at the end\n   of the implementation phase.\n\n\n\n\nAPI Documentation\n\n\n\n\n Extend the processing phases page of the API Documentation to include\n   all the work done in this phase, including validation.\n\n\n Rebuild docs and commit.", 
            "title": "Phase 7, Validation"
        }, 
        {
            "location": "/phase7-validation/#lde-design-phase-7-validation", 
            "text": "", 
            "title": "LDE Design Phase 7: Validation"
        }, 
        {
            "location": "/phase7-validation/#content", 
            "text": "In this phase, we define the Validation Phase.", 
            "title": "Content"
        }, 
        {
            "location": "/phase7-validation/#goal", 
            "text": "The LDE will be able to follow the Interpretation Phase with the Validation\nPhase, giving semantic feedback about the validity of steps of work.", 
            "title": "Goal"
        }, 
        {
            "location": "/phase7-validation/#status", 
            "text": "This has not been implemented.  See the tasks below.", 
            "title": "Status"
        }, 
        {
            "location": "/phase7-validation/#making-background-threads-easy-to-use", 
            "text": "Create a worker script that enables us to create instances of\n    WebWorker s who are able to respond to a variety of functions for\n   installing various routines and data in the workers, including:  worker.installScript(filename)  worker.installFunction(varname,func)  worker.installData(key,value)  worker.uninstallData(key)  worker.run(code,callback)  worker.reboot(callback)  (which calls  terminate()  in the internal\n   WebWorker  instance, then discards it and replaces it with a new one)     Create a new unit testing file for these advanced  WebWorker s,\n   documenting it in the same style as the rest of the test suite.   Once it is robust and all tests pass, commit the changes.   Create a global variable in the LDE that holds a pool of these\n   workers, with a function that lets you specify the size of the pool.\n   It should initialize itself, by default, to the number of threads the\n   CPU supports, minus 1 for the main thread.  (The minimum value is 1.)   Create a function in each worker for marking it available or\n   unavailable.   Create a function in the worker pool for getting the next available\n   worker, or null if there isn't one.   Add and document tests for these new features.", 
            "title": "Making background threads easy to use"
        }, 
        {
            "location": "/phase7-validation/#the-validation-phase", 
            "text": "Create a global validation pool in the LDE, which is a priority queue\n   that comes with a routine for adding an  OutputStructure  instance to the\n   queue, after first verifying that it has a  validate()  routine.   Create a routine that, if a worker is available, dequeues a structure\n   from the validation pool and calls its validation routine, passing it the\n   available worker.  If one is not available, this routine does nothing.\n   In the callback that routine passes the validation routine, place the\n   worker back on the list of available workers.  Also, the routine does\n   nothing in the case where modification or interpretation is currently\n   running.  We expect to define validation routines somewhat like this:   MyOutputStructure.validate = function ( callback, worker ) {\n    worker.installScript(  some script file  );\n    worker.installFunction(  foo , foo );\n    worker.installData(  key , value );\n    worker.run(  some code , function ( result, error ) {\n        // here, generate feedback from result and/or error\n        callback();\n    } );\n};    Call that dequeueing routine whenever a worker becomes available.   Make unit tests for this much functionality, in a new unit testing\n   file for validation specifically.  Document such tests the usual way.   Extend the enqueue process so that if a structure is already\n   enqueued, then enqueueing again does nothing.   Extend the enqueue process so that if the structure being enqueued,\n   while not currently on the queue, has its validation routine still\n   running in a worker, then we find and reboot that worker, mark the\n   structure as no longer being validated, and  then  enqueue it as usual.   Create unit tests that ensure these behaviors work.   Create a default implementation of  justChanged()  in the\n    OutputStructure  class that does the following things.  If the OS has a validate routine, add it to the global pool.  If its\n  origin IS has a validation priority, use that, otherwise use zero.  If\n  its origin has a validation priority of null, skip this step (no\n  enqueueing).  If you enqueue the OS, emit feedback saying its\n  validation is being recomputed.  If it had null priority, emit\n  feedback saying that its validation is being skipped.  If any OS in the scope of this one cites this one, then add that other\n  OS to the validation pool.  Set priorities and emit feedback in the\n  same way.     Call the dequeueing routine whenever interpretation ends.   Write unit tests to ensure that the already-tested validation\n   features still function when they are automatically triggered at the end\n   of the implementation phase.", 
            "title": "The Validation Phase"
        }, 
        {
            "location": "/phase7-validation/#api-documentation", 
            "text": "Extend the processing phases page of the API Documentation to include\n   all the work done in this phase, including validation.   Rebuild docs and commit.", 
            "title": "API Documentation"
        }, 
        {
            "location": "/phase8-expressions-and-rules/", 
            "text": "We have designed the work on the Lurch Deductive Engine (LDE) to progress in\nphases.  The idea is that each phase ends with a completed whole that can be\ntested in that state, and that provides more features than the previous\nstate did.  By the time the final phase is complete, the LDE will be a\nrobust and useful product.\n\n\nLDE Design Phase 8: Expressions and Rules\n\n\nContent\n\n\nIn this phase, we define mathematical expressions and rules of inference.\n\n\nGoal\n\n\nThe LDE will be able to validate much of the mathematics we expect to use it\nfor, without yet permitting customizable mathematical notation.\n\n\nStatus\n\n\nThis has not been implemented.  See the tasks below.\n\n\nExpressions\n\n\n\n\n Create a subclass of \nOutputStructure\n, in the \nOutputStructure\n\n   module, called \nOutputExpression\n.\n\n\n Add documentation explaining what it is and will do.\n\n\n Ensure that the \nOutputExpression\n subclass registers itself with the\n   serialization code, as\n   \nthe documentation here\n\n   describes.  (That is, use a line like\n   \nclassName : Structure.addSubclass 'OutputExpression', OutputExpression\n\n   in the \nOutputExpression\n class code.)\n\n\n Add a constructor that takes three fields: OpenMath type (\nOMS\n,\n   \nOMI\n, etc.), atomic content (if any), and indices of bound variables (if\n   any).\n\n\n Add an instance method \ntoOpenMath()\n that converts instances of\n   the class to OpenMath expressions, using\n   \nthe OpenMath package\n.\n\n\n Add a class method \nfromOpenMath()\n that converts instances of\n   OpenMath expressions into \nOutputExpression\n trees.\n\n\n Extend the OpenMath class with a \ntoOutputExpression()\n function that\n   just defers the task to \nfromOpenMath()\n in the \nOutputExpression\n class.\n\n\n Write and document unit tests.\n\n\n\n\nCommon types of interpretation\n\n\n\n\n Extend the default implementation of \ninterpret()\n so that, if the\n   instance has a property called \ncorrespondingClass\n, then that property\n   is used to instantiate an \nOutputStructure\n instance rather than using\n   the base \nOutputStructure\n class.  This should be sufficient to implement\n   corresponding input and output expressions.\n\n\n Extend the unit tests for interpretation to verify that this can be\n   used to create arbitrary-sized trees that are nested combinations of the\n   correct subclasses of \nOutputStructure\n.  This will require creating some\n   dummy subclasses for testing purposes.\n\n\n Create a subclass \nParsableExpression\n of \nInputExpression\n that has\n   a property \nparse\n that maps strings to \nOutputStructure\n instances.  The\n   \ninterpret()\n routine in the \nParsableExpression\n class should call the\n   parser on the \"text\" attribute of the \nInputExpression\n, returning the\n   result.\n\n\n Add documentation for that new subclass.\n\n\n Ensure that the \nParsableExpression\n subclass registers itself with the\n   serialization code, as\n   \nthe documentation here\n\n   describes.  (That is, use a line like\n   \nclassName : Structure.addSubclass 'ParsableExpression', ParsableExpression\n\n   in the \nParsableExpression\n class code.)\n\n\n Define a global function in the LDE that uses the simple notation in\n   the OpenMath package (e.g., \nf(x,y,2)\n) to create OpenMath instances and\n   then converts them to \nOutputExpression\n trees.\n\n\n Write unit tests that interpretation can use this global function.\n\n\n Repeat the previous two steps for OpenMath XML as well.\n\n\n Extend the unit tests for interpretation to verify that parsable\n   nodes can exist on their own or within corresponding nodes in the Input\n   Tree, and the correct hierarchies will be produced in any case.\n\n\n Once the unit tests pass, build everything and commit.\n\n\n\n\nRules of inference\n\n\n\n\n Create a subclass \nOutputRule\n of \nOutputStructure\n that has\n   a member \nvalidateStep(step,callback,worker)\n that can validate other\n   \nOutputStructure\n instances.  The default implementation just calls the\n   callback object with a feedback object expressing that it didn't\n   actually validate anything.\n\n\n Add documentation for that new subclass.\n\n\n Ensure that the \nOutputRule\n subclass registers itself with the\n   serialization code, as\n   \nthe documentation here\n\n   describes.  (That is, use a line like\n   \nclassName : Structure.addSubclass 'OutputRule', OutputRule\n in the\n   \nOutputRule\n class code.)\n\n\n Define in the LDE a \nbasicValidate(callback,worker)\n function that\n   can be installed in \nOutputStructure\n instances as their \nvalidate\n\n   field, and that finds the rule of inference cited by the\n   \nOutputStructure\n instance and defers validation to that rule's\n   \nvalidateStep()\n routine, passing both parameters along.\n\n\n Test that \nOutputStructures\n can cite rules that will do the\n   validation for the structure.  Ensure that validation continues to work\n   even when delegated (athough so far all feedback will say no work was\n   done).\n\n\n Create a subclass \nTemplateRule\n of \nOutputRule\n.\n\n\n Ensure that the \nTemplateRule\n subclass registers itself with the\n   serialization code, as\n   \nthe documentation here\n\n   describes.  (That is, use a line like\n   \nclassName : Structure.addSubclass 'TemplateRule', TemplateRule\n in the\n   \nTemplateRule\n class code.)\n\n\n In \nTemplateRule\n, override \nvalidateStep()\n so that it reads the\n   appropriate attributes and children of the rule object to determine how\n   to do validation.  For now, assume tree-based matching and if-style\n   inference.  You will need to use\n   \nthe Matching Package\n,\n   probably loaded into background workers.\n\n\n Add documentation for that new subclass.\n\n\n Test that \nOutputStructures\n can cite rules that will do the\n   template-based validation, which is a huge step!\n\n\n Extend \nTemplateRule\n with the option to be iff rather than just if.\n\n\n Add unit tests for this new feature.\n\n\n Extend \nTemplateRule\n with the option to use string-based matching\n   rather than just tree-based matching.\n\n\n Add unit tests for this new feature.\n\n\n Create a subclass \nInputRule\n of \nInputStructure\n.\n\n\n Ensure that the \nInputRule\n subclass registers itself with the\n   serialization code, as\n   \nthe documentation here\n\n   describes.  (That is, use a line like\n   \nclassName : Structure.addSubclass 'InputRule', InputRule\n in the\n   \nInputRule\n class code.)\n\n\n Override \ninterpret()\n in \nInputRule\n to create generic \nOutputRule\n\n   instances if a generic validation procedure is present, or specifically\n   \nTemplateRule\n instances if that kind of data is present.\n\n\n Add unit tests to show that the LDE can validate conclusions based on\n   rules defined earlier in the same document.\n\n\n\n\nAPI Documentation\n\n\n\n\n Extend the \nOutputStructure\n page of the API Documentation to include\n   the \nOutputExpression\n class.\n\n\n Extend the processing phases page of the API Documentation to include\n   the enhancements to interpretation and validation accomplished in this\n   phase.\n\n\n Rebuild docs and commit.", 
            "title": "Phase 8, Expressions and Rules"
        }, 
        {
            "location": "/phase8-expressions-and-rules/#lde-design-phase-8-expressions-and-rules", 
            "text": "", 
            "title": "LDE Design Phase 8: Expressions and Rules"
        }, 
        {
            "location": "/phase8-expressions-and-rules/#content", 
            "text": "In this phase, we define mathematical expressions and rules of inference.", 
            "title": "Content"
        }, 
        {
            "location": "/phase8-expressions-and-rules/#goal", 
            "text": "The LDE will be able to validate much of the mathematics we expect to use it\nfor, without yet permitting customizable mathematical notation.", 
            "title": "Goal"
        }, 
        {
            "location": "/phase8-expressions-and-rules/#status", 
            "text": "This has not been implemented.  See the tasks below.", 
            "title": "Status"
        }, 
        {
            "location": "/phase8-expressions-and-rules/#expressions", 
            "text": "Create a subclass of  OutputStructure , in the  OutputStructure \n   module, called  OutputExpression .   Add documentation explaining what it is and will do.   Ensure that the  OutputExpression  subclass registers itself with the\n   serialization code, as\n    the documentation here \n   describes.  (That is, use a line like\n    className : Structure.addSubclass 'OutputExpression', OutputExpression \n   in the  OutputExpression  class code.)   Add a constructor that takes three fields: OpenMath type ( OMS ,\n    OMI , etc.), atomic content (if any), and indices of bound variables (if\n   any).   Add an instance method  toOpenMath()  that converts instances of\n   the class to OpenMath expressions, using\n    the OpenMath package .   Add a class method  fromOpenMath()  that converts instances of\n   OpenMath expressions into  OutputExpression  trees.   Extend the OpenMath class with a  toOutputExpression()  function that\n   just defers the task to  fromOpenMath()  in the  OutputExpression  class.   Write and document unit tests.", 
            "title": "Expressions"
        }, 
        {
            "location": "/phase8-expressions-and-rules/#common-types-of-interpretation", 
            "text": "Extend the default implementation of  interpret()  so that, if the\n   instance has a property called  correspondingClass , then that property\n   is used to instantiate an  OutputStructure  instance rather than using\n   the base  OutputStructure  class.  This should be sufficient to implement\n   corresponding input and output expressions.   Extend the unit tests for interpretation to verify that this can be\n   used to create arbitrary-sized trees that are nested combinations of the\n   correct subclasses of  OutputStructure .  This will require creating some\n   dummy subclasses for testing purposes.   Create a subclass  ParsableExpression  of  InputExpression  that has\n   a property  parse  that maps strings to  OutputStructure  instances.  The\n    interpret()  routine in the  ParsableExpression  class should call the\n   parser on the \"text\" attribute of the  InputExpression , returning the\n   result.   Add documentation for that new subclass.   Ensure that the  ParsableExpression  subclass registers itself with the\n   serialization code, as\n    the documentation here \n   describes.  (That is, use a line like\n    className : Structure.addSubclass 'ParsableExpression', ParsableExpression \n   in the  ParsableExpression  class code.)   Define a global function in the LDE that uses the simple notation in\n   the OpenMath package (e.g.,  f(x,y,2) ) to create OpenMath instances and\n   then converts them to  OutputExpression  trees.   Write unit tests that interpretation can use this global function.   Repeat the previous two steps for OpenMath XML as well.   Extend the unit tests for interpretation to verify that parsable\n   nodes can exist on their own or within corresponding nodes in the Input\n   Tree, and the correct hierarchies will be produced in any case.   Once the unit tests pass, build everything and commit.", 
            "title": "Common types of interpretation"
        }, 
        {
            "location": "/phase8-expressions-and-rules/#rules-of-inference", 
            "text": "Create a subclass  OutputRule  of  OutputStructure  that has\n   a member  validateStep(step,callback,worker)  that can validate other\n    OutputStructure  instances.  The default implementation just calls the\n   callback object with a feedback object expressing that it didn't\n   actually validate anything.   Add documentation for that new subclass.   Ensure that the  OutputRule  subclass registers itself with the\n   serialization code, as\n    the documentation here \n   describes.  (That is, use a line like\n    className : Structure.addSubclass 'OutputRule', OutputRule  in the\n    OutputRule  class code.)   Define in the LDE a  basicValidate(callback,worker)  function that\n   can be installed in  OutputStructure  instances as their  validate \n   field, and that finds the rule of inference cited by the\n    OutputStructure  instance and defers validation to that rule's\n    validateStep()  routine, passing both parameters along.   Test that  OutputStructures  can cite rules that will do the\n   validation for the structure.  Ensure that validation continues to work\n   even when delegated (athough so far all feedback will say no work was\n   done).   Create a subclass  TemplateRule  of  OutputRule .   Ensure that the  TemplateRule  subclass registers itself with the\n   serialization code, as\n    the documentation here \n   describes.  (That is, use a line like\n    className : Structure.addSubclass 'TemplateRule', TemplateRule  in the\n    TemplateRule  class code.)   In  TemplateRule , override  validateStep()  so that it reads the\n   appropriate attributes and children of the rule object to determine how\n   to do validation.  For now, assume tree-based matching and if-style\n   inference.  You will need to use\n    the Matching Package ,\n   probably loaded into background workers.   Add documentation for that new subclass.   Test that  OutputStructures  can cite rules that will do the\n   template-based validation, which is a huge step!   Extend  TemplateRule  with the option to be iff rather than just if.   Add unit tests for this new feature.   Extend  TemplateRule  with the option to use string-based matching\n   rather than just tree-based matching.   Add unit tests for this new feature.   Create a subclass  InputRule  of  InputStructure .   Ensure that the  InputRule  subclass registers itself with the\n   serialization code, as\n    the documentation here \n   describes.  (That is, use a line like\n    className : Structure.addSubclass 'InputRule', InputRule  in the\n    InputRule  class code.)   Override  interpret()  in  InputRule  to create generic  OutputRule \n   instances if a generic validation procedure is present, or specifically\n    TemplateRule  instances if that kind of data is present.   Add unit tests to show that the LDE can validate conclusions based on\n   rules defined earlier in the same document.", 
            "title": "Rules of inference"
        }, 
        {
            "location": "/phase8-expressions-and-rules/#api-documentation", 
            "text": "Extend the  OutputStructure  page of the API Documentation to include\n   the  OutputExpression  class.   Extend the processing phases page of the API Documentation to include\n   the enhancements to interpretation and validation accomplished in this\n   phase.   Rebuild docs and commit.", 
            "title": "API Documentation"
        }, 
        {
            "location": "/enhancements/", 
            "text": "Enhancements for Later\n\n\nThis page lists helpful enhancements to work already completed, but which\nwere not essential enough to have been included in the work done so far.  We\nlist them here so as not to lose track of important improvements we might\nmake later, and we leave empty check boxes next to them so that we can later\nmark them complete as they are implemented.\n\n\n(Entries that were here have been deleted.  This page continues to exist in\nthe event that it may be used again later for other ideas.)", 
            "title": "Enhancements for Later"
        }, 
        {
            "location": "/enhancements/#enhancements-for-later", 
            "text": "This page lists helpful enhancements to work already completed, but which\nwere not essential enough to have been included in the work done so far.  We\nlist them here so as not to lose track of important improvements we might\nmake later, and we leave empty check boxes next to them so that we can later\nmark them complete as they are implemented.  (Entries that were here have been deleted.  This page continues to exist in\nthe event that it may be used again later for other ideas.)", 
            "title": "Enhancements for Later"
        }, 
        {
            "location": "/api-overview/", 
            "text": "API Documentation Overview\n\n\nDesign Plans vs. API Documentation\n\n\nAt the top of this site, notice the two navigation menus entitled \"Design\nPlans\" and \"API Documentation.\"  The difference between them is this:\n\n\n\n\nDesign Plans\n lists concepts that have not yet been implemented and\n   documented.  Consequently, the concepts are usually not described in full\n   detail, but just the best detail available in the planning phase.\n   It answers the question, \"What do we plan to build?\"\n\n\nAPI Documentation\n lists concepts that have been implemented, and for\n   which the developers have therefore been able to document their work.\n   Having the benefit of hindsight, this is therefore more detailed, and\n   often even contains links directly into the source code.\n   It answers the question, \"What did we build?\" and is the official\n   documentation for the modules.\n\n\n\n\nAny page in the Design Plans that has been complete has had most of its\ncontent removed, because it has been superceded by the corresponding API\ndocumentation.  What remains is just a record of what was planne for that\nphase, with links to the corresponding API Documentation.\n\n\nDeveloper Workflow\n\n\nDevelopers designing and/or implementing concepts should therefore progress\nthose concepts through a lifecycle like so:\n\n\n\n\nDescribe the concept in one of the Design Plans page.  Provide as much\n    detail as you can, knowing of course that full details is impossible to\n    provide before the work has been done.\n\n\nAs you implement and test the concept, update those design documents\n    with whatever new information you create or learn as part of the work,\n    thus making them more precise.\n\n\nOnce the concept is fully implemented and tested, document the work in\n    an existing or new page in the API Documentation section.  This may\n    involve copying and pasting some of the content from the design plan,\n    provided that it still applies.  It will probably also involve adding\n    significant detail about the particulars of the implementation.\n\n\nReplace the original (less detailed) documentation in the design plans\n    with a brief description of the concept, followed by a link to the\n    corresponding part of the API Documentation for full details.\n\n\n\n\nFor the Reader\n\n\nReaders of this documentation will therefore be able to see how much has\nbeen implemented by perusing the Design Plans pages.  Those that are brief\noverviews of concepts with links to API Documentation have been implemented.\nThose that are plans for future work, with no links to any API\nDocumentation, have not yet been implemented.", 
            "title": "Overview"
        }, 
        {
            "location": "/api-overview/#api-documentation-overview", 
            "text": "", 
            "title": "API Documentation Overview"
        }, 
        {
            "location": "/api-overview/#design-plans-vs-api-documentation", 
            "text": "At the top of this site, notice the two navigation menus entitled \"Design\nPlans\" and \"API Documentation.\"  The difference between them is this:   Design Plans  lists concepts that have not yet been implemented and\n   documented.  Consequently, the concepts are usually not described in full\n   detail, but just the best detail available in the planning phase.\n   It answers the question, \"What do we plan to build?\"  API Documentation  lists concepts that have been implemented, and for\n   which the developers have therefore been able to document their work.\n   Having the benefit of hindsight, this is therefore more detailed, and\n   often even contains links directly into the source code.\n   It answers the question, \"What did we build?\" and is the official\n   documentation for the modules.   Any page in the Design Plans that has been complete has had most of its\ncontent removed, because it has been superceded by the corresponding API\ndocumentation.  What remains is just a record of what was planne for that\nphase, with links to the corresponding API Documentation.", 
            "title": "Design Plans vs. API Documentation"
        }, 
        {
            "location": "/api-overview/#developer-workflow", 
            "text": "Developers designing and/or implementing concepts should therefore progress\nthose concepts through a lifecycle like so:   Describe the concept in one of the Design Plans page.  Provide as much\n    detail as you can, knowing of course that full details is impossible to\n    provide before the work has been done.  As you implement and test the concept, update those design documents\n    with whatever new information you create or learn as part of the work,\n    thus making them more precise.  Once the concept is fully implemented and tested, document the work in\n    an existing or new page in the API Documentation section.  This may\n    involve copying and pasting some of the content from the design plan,\n    provided that it still applies.  It will probably also involve adding\n    significant detail about the particulars of the implementation.  Replace the original (less detailed) documentation in the design plans\n    with a brief description of the concept, followed by a link to the\n    corresponding part of the API Documentation for full details.", 
            "title": "Developer Workflow"
        }, 
        {
            "location": "/api-overview/#for-the-reader", 
            "text": "Readers of this documentation will therefore be able to see how much has\nbeen implemented by perusing the Design Plans pages.  Those that are brief\noverviews of concepts with links to API Documentation have been implemented.\nThose that are plans for future work, with no links to any API\nDocumentation, have not yet been implemented.", 
            "title": "For the Reader"
        }, 
        {
            "location": "/api-lde/", 
            "text": "API Documentation for the LDE Module\n\n\nThe main LDE module is not yet complete.  So far it supports only the\nfunctionality documented below, which will grow with time.\n\n\nThe Input Tree\n\n\nThe module initializes a single \nInputStructure\n instance in a global\nvariable, which can be queried with the public API function\n\ngetInputTree()\n.  It begins life as a freshly created \nInputStructure\n with\nno attributes, but an ID.\n\n\nThis structure is called the \nInput Tree,\n and is the structure in which the\nLDE stores all input passed from the client.  In particular, the LDE never\nmodifies this structure except at the request of the client.\n\n\nManipulating the Input Tree\n\n\nThe Input Tree can be manipulated with seven functions in the public API of\nthis module:\n\n\n\n\ninsertStructure(structureToInsert,parentID,insertionIndex)\n inserts a\n   new \nInputStructure\n within the Input Tree, as follows:\n\n\nstructureToInsert\n should be either the structure to insert or the\n  serialized version thereof (optionally created with \n.toJSON()\n in an\n  \nInputStructure\n instance).  After the structure is deserialized (if\n  needed) and inserted into the document, \ntrackIDs()\n will be called\n  in it; for more information on that function, see \nits entry in the\n  API docs\n.  Note that if the deserialized\n  object is not an \nInputStructure\n instance, \ninsertStructure()\n does\n  nothing.\n\n\nparentID\n is the ID of the parent under which this new child should\n  be inserted.  This must be a string ID that belongs to a structure\n  already in the Input Tree.  If it is not, \ninsertStructure()\n does\n  nothing.  Note that the root of the hierarchy is given the ID \"root\"\n  at the time the module is loaded.\n\n\ninsertionIndex\n is the index of the child to insert, which must be\n  greater than or equal to zero and less than or equal to the number of\n  children of the parent.  If that constraint does not hold,\n  \ninsertStructure()\n does nothing.\n\n\n\n\n\n\ndeleteStructure(ID)\n deletes from the Input Tree the structure with the\n   given ID, which is interpreted with the same conventions as the\n   \nparentID\n is for the \ninsertStructure()\n function.  After the structure\n   is deleted, \nuntrackIDs()\n will be called in it; for more information on\n   that function, see \nits entry in the API docs\n.\n\n\nreplaceStructure(ID,newStructure)\n replaces the structure with the\n   given ID with the given new structure.\n\n\nID\n is interpreted with the same conventions as the \nparentID\n is for\n  the \ninsertStructure()\n function\n\n\nnewStructure\n is a structure (optionally serialized), as\n  \nstructureToInsert\n is for the \ninsertStructure()\n function (and\n  again, if it is not an \nInputStructure\n instance or the serialization\n  of one, this function does nothing)\n\n\nAfter this operation, \nuntrackIDs()\n will be called in the replaced\n  structure and \ntrackIDs()\n in the replacement; for more information\n  on those functions, see\n  \ntheir entries in the API docs\n.\n\n\n\n\n\n\nsetStructureAttribute(ID,key,value)\n modifies a single attribute of a\n   structure within the Input Tree, as follows:\n\n\nID\n is interpreted with the same conventions as the \nparentID\n is for\n  the \ninsertStructure()\n function\n\n\nkey\n is the key of the attribute to create or overwrite.  If this\n  key happens to be \"id\", then the class-level tracking of IDs will be\n  updated to respect the change.  This is not permitted to begin with an\n  underscore; such key names are reserved for internal use by the LDE.\n  If the given key begins with an underscore, this function does\n  nothing.\n\n\nvalue\n is the new value, which must be JSON data.  (No checks are\n  done to verify that it is JSON data, but errors will transpire\n  eventually if non-JSON data is passed.)  Alternately, \nvalue\n can be\n  \nundefined\n, which will serve to delete the old key-value pair from\n  the attributes without replacing it with any new key-value pair.\n\n\n\n\n\n\ninsertConnection(sourceID,targetID,connectionData)\n inserts a new\n   connection between two existing \nInputStructure\n instances, as follows:\n\n\nsourceID\n must be the ID of an \nInputStructure\n already in the Input\n  Tree.  If not, this function does nothing.\n\n\ntargetID\n must be the ID of an \nInputStructure\n already in the Input\n  Tree.  If not, this function does nothing.  It is acceptable for the\n  source and target to be the same node; connections from a thing to\n  itself are permitted.\n\n\nconnectionData\n an object containing arbitrary JSON data about the\n  new connection.  It must at least contain a field whose key is \n\"id\"\n\n  and whose value is a new, unique ID (which no connection has yet).\n  If this is not satisfied, this function does nothing.  If all the\n  above conditions are satisfied, a new connection is formed from the\n  source to the target with the given data.\n\n\n\n\n\n\nremoveConnection(ID)\n deletes from the Input Tree the connection with\n   the given ID, which must be the unique ID of a connection given to the\n   \ninsertConnection()\n function documented immediately above, otherwise,\n   this function does nothing.  If it is a valid connection ID, then the\n   connection is removed from the Input Tree and the ID is available to be\n   used again.\n\n\nsetConnectionAttribute(ID,key,value)\n modifies a single attribute of a\n   connection within the Input Tree, as follows:\n\n\nID\n is interpreted just as in \nremoveConnection()\n, above.\n\n\nkey\n is the key of the attribute to create or overwrite.  This may\n  not be the string \n\"id\"\n, which is already used to store the\n  connection's unique ID, which cannot be changed.  (If this is \n\"id\"\n,\n  this function does nothing.)\n\n\nvalue\n is the new value, which must be JSON data.  (No checks are\n  done to verify that it is JSON data, but errors will transpire\n  eventually if non-JSON data is passed.)  Alternately, \nvalue\n can be\n  \nundefined\n, which will serve to delete the old key-value pair from\n  the attributes without replacing it with any new key-value pair.\n\n\n\n\n\n\n\n\nAsynchronous API\n\n\nIf the LDE detects that it is being run in a background thread, it will set\nup listeners for messages from the parent thread.  These listeners will\nhandle messages of four types (\ninsertStructure\n, \ndeleteStructure\n,\n\nreplaceStructure\n, \nsetStructureAttribute\n, and \ngetInputTree\n) mirroring\nthe four functions given above (plus \ngetInputTree()\n) and calling them\ninternally.\n\n\nThey can be called by passing a message of the form \n[ command, args... ]\n,\nwhere the command is a string (one of \n\"insertStructure\"\n,\n\n\"deleteStructure\"\n, etc.) and the arguments list is the same list that\nwould be passed to the function itself, as documented above.\n\n\nFor example, you could start an LDE in a WebWorker and insert a new\n\nInputStructure\n as the first child of its global document as follows.\n\n\n    // import the lde.js file (kept in the release/ folder)\n    // (This requires having the structure.js file in the same folder.)\n    var worker = new Worker( 'lde.js' );\n    var A = new InputStructure();\n    worker.postMessage( [ 'insertStructure', A.toJSON(), 'root', 0 ] );\n\n\n\n\nBecause message passing across thread boundaries can only transfer JSON\ndata, the versions of \ninsertStructure()\n and \nreplaceStructure()\n that take\n\nInputStructure\n instances will need to be called with serialized\n\nInputStructure\ns instead.\n\n\nOnly one of these five functions sends a message back to the parent context.\nIf you post a \ngetInputTree\n message (which requires no parameters), you\nwill immediately get a message in response whose event has the following\nproperties.\n\n\n\n\nevent.data.type\n is the string \n\"getInputTree\"\n.\n\n\nevent.data.payload\n is the JSON representation of the entire Input Tree,\n   as serialized by \nStructure.toJSON()\n.\n\n\n\n\nReceiving Feedback\n\n\nThe LDE will occasionally need to send feedback to the client about the\ninput provided to it.  This takes different forms, depending on how the LDE\nhas been loaded.\n\n\n\n\nIf the LDE has been loaded into a node.js application as a module, using\n   \nrequire()\n, then the module will have a member called \nFeedback\n, an\n   instance of \nEventEmitter\n.  Clients can listen for feedback events by\n   calling \ntheModule.Feedback.addEventListener('feedback',f)\n, with their\n   own function \nf\n.  That function will be called with one argument when\n   the LDE generates feedback, a JSON object with feedback data.  The most\n   important field in the object is the \nsubject\n field, which will contain\n   the ID of the \nInputStructure\n instance to which the feedback pertains.\n\n\nIf the LDE has been loaded into the browser directly (not in a WebWorker\n   instance, but in the UI thread) then it installs a \nFeedback\n object in\n   the \nwindow\n namespace.  The client can listen to events by calling\n   \nwindow.Feedback.addEventListener('feedback',f)\n, and \nf\n will be called\n   with an event \nE\n such that \nE.data\n has the structure described in the\n   previous bullet point (e.g., \nE.data.subject\n is an \nInputStructure\n ID).\n\n\nIf the LDE has been loaded into a node.js application in a background\n   thread, using Workers, then it will occasionally post messages to the\n   parent context when one of its computations requires sending feedback\n   about the result.  If the LDE is loaded into a worker \nW\n, then you can\n   listen for such messages with \nW.onmessage = function (event) {...}\n.\n   Feedback events passed to such a handler will have \nevent.type\n equal to\n   the string \n\"feedback\"\n and \nevent.payload\n equal to the feedback data\n   itself as documented in the previous two bullet points (e.g.,\n   \nevent.payload.subject\n an \nInputStructure\n ID).\n\n\n\n\nFor an example of how this works, see\n\nthe unit tests regarding feedback in the LDE\n.", 
            "title": "The LDE"
        }, 
        {
            "location": "/api-lde/#api-documentation-for-the-lde-module", 
            "text": "The main LDE module is not yet complete.  So far it supports only the\nfunctionality documented below, which will grow with time.", 
            "title": "API Documentation for the LDE Module"
        }, 
        {
            "location": "/api-lde/#the-input-tree", 
            "text": "The module initializes a single  InputStructure  instance in a global\nvariable, which can be queried with the public API function getInputTree() .  It begins life as a freshly created  InputStructure  with\nno attributes, but an ID.  This structure is called the  Input Tree,  and is the structure in which the\nLDE stores all input passed from the client.  In particular, the LDE never\nmodifies this structure except at the request of the client.", 
            "title": "The Input Tree"
        }, 
        {
            "location": "/api-lde/#manipulating-the-input-tree", 
            "text": "The Input Tree can be manipulated with seven functions in the public API of\nthis module:   insertStructure(structureToInsert,parentID,insertionIndex)  inserts a\n   new  InputStructure  within the Input Tree, as follows:  structureToInsert  should be either the structure to insert or the\n  serialized version thereof (optionally created with  .toJSON()  in an\n   InputStructure  instance).  After the structure is deserialized (if\n  needed) and inserted into the document,  trackIDs()  will be called\n  in it; for more information on that function, see  its entry in the\n  API docs .  Note that if the deserialized\n  object is not an  InputStructure  instance,  insertStructure()  does\n  nothing.  parentID  is the ID of the parent under which this new child should\n  be inserted.  This must be a string ID that belongs to a structure\n  already in the Input Tree.  If it is not,  insertStructure()  does\n  nothing.  Note that the root of the hierarchy is given the ID \"root\"\n  at the time the module is loaded.  insertionIndex  is the index of the child to insert, which must be\n  greater than or equal to zero and less than or equal to the number of\n  children of the parent.  If that constraint does not hold,\n   insertStructure()  does nothing.    deleteStructure(ID)  deletes from the Input Tree the structure with the\n   given ID, which is interpreted with the same conventions as the\n    parentID  is for the  insertStructure()  function.  After the structure\n   is deleted,  untrackIDs()  will be called in it; for more information on\n   that function, see  its entry in the API docs .  replaceStructure(ID,newStructure)  replaces the structure with the\n   given ID with the given new structure.  ID  is interpreted with the same conventions as the  parentID  is for\n  the  insertStructure()  function  newStructure  is a structure (optionally serialized), as\n   structureToInsert  is for the  insertStructure()  function (and\n  again, if it is not an  InputStructure  instance or the serialization\n  of one, this function does nothing)  After this operation,  untrackIDs()  will be called in the replaced\n  structure and  trackIDs()  in the replacement; for more information\n  on those functions, see\n   their entries in the API docs .    setStructureAttribute(ID,key,value)  modifies a single attribute of a\n   structure within the Input Tree, as follows:  ID  is interpreted with the same conventions as the  parentID  is for\n  the  insertStructure()  function  key  is the key of the attribute to create or overwrite.  If this\n  key happens to be \"id\", then the class-level tracking of IDs will be\n  updated to respect the change.  This is not permitted to begin with an\n  underscore; such key names are reserved for internal use by the LDE.\n  If the given key begins with an underscore, this function does\n  nothing.  value  is the new value, which must be JSON data.  (No checks are\n  done to verify that it is JSON data, but errors will transpire\n  eventually if non-JSON data is passed.)  Alternately,  value  can be\n   undefined , which will serve to delete the old key-value pair from\n  the attributes without replacing it with any new key-value pair.    insertConnection(sourceID,targetID,connectionData)  inserts a new\n   connection between two existing  InputStructure  instances, as follows:  sourceID  must be the ID of an  InputStructure  already in the Input\n  Tree.  If not, this function does nothing.  targetID  must be the ID of an  InputStructure  already in the Input\n  Tree.  If not, this function does nothing.  It is acceptable for the\n  source and target to be the same node; connections from a thing to\n  itself are permitted.  connectionData  an object containing arbitrary JSON data about the\n  new connection.  It must at least contain a field whose key is  \"id\" \n  and whose value is a new, unique ID (which no connection has yet).\n  If this is not satisfied, this function does nothing.  If all the\n  above conditions are satisfied, a new connection is formed from the\n  source to the target with the given data.    removeConnection(ID)  deletes from the Input Tree the connection with\n   the given ID, which must be the unique ID of a connection given to the\n    insertConnection()  function documented immediately above, otherwise,\n   this function does nothing.  If it is a valid connection ID, then the\n   connection is removed from the Input Tree and the ID is available to be\n   used again.  setConnectionAttribute(ID,key,value)  modifies a single attribute of a\n   connection within the Input Tree, as follows:  ID  is interpreted just as in  removeConnection() , above.  key  is the key of the attribute to create or overwrite.  This may\n  not be the string  \"id\" , which is already used to store the\n  connection's unique ID, which cannot be changed.  (If this is  \"id\" ,\n  this function does nothing.)  value  is the new value, which must be JSON data.  (No checks are\n  done to verify that it is JSON data, but errors will transpire\n  eventually if non-JSON data is passed.)  Alternately,  value  can be\n   undefined , which will serve to delete the old key-value pair from\n  the attributes without replacing it with any new key-value pair.", 
            "title": "Manipulating the Input Tree"
        }, 
        {
            "location": "/api-lde/#asynchronous-api", 
            "text": "If the LDE detects that it is being run in a background thread, it will set\nup listeners for messages from the parent thread.  These listeners will\nhandle messages of four types ( insertStructure ,  deleteStructure , replaceStructure ,  setStructureAttribute , and  getInputTree ) mirroring\nthe four functions given above (plus  getInputTree() ) and calling them\ninternally.  They can be called by passing a message of the form  [ command, args... ] ,\nwhere the command is a string (one of  \"insertStructure\" , \"deleteStructure\" , etc.) and the arguments list is the same list that\nwould be passed to the function itself, as documented above.  For example, you could start an LDE in a WebWorker and insert a new InputStructure  as the first child of its global document as follows.      // import the lde.js file (kept in the release/ folder)\n    // (This requires having the structure.js file in the same folder.)\n    var worker = new Worker( 'lde.js' );\n    var A = new InputStructure();\n    worker.postMessage( [ 'insertStructure', A.toJSON(), 'root', 0 ] );  Because message passing across thread boundaries can only transfer JSON\ndata, the versions of  insertStructure()  and  replaceStructure()  that take InputStructure  instances will need to be called with serialized InputStructure s instead.  Only one of these five functions sends a message back to the parent context.\nIf you post a  getInputTree  message (which requires no parameters), you\nwill immediately get a message in response whose event has the following\nproperties.   event.data.type  is the string  \"getInputTree\" .  event.data.payload  is the JSON representation of the entire Input Tree,\n   as serialized by  Structure.toJSON() .", 
            "title": "Asynchronous API"
        }, 
        {
            "location": "/api-lde/#receiving-feedback", 
            "text": "The LDE will occasionally need to send feedback to the client about the\ninput provided to it.  This takes different forms, depending on how the LDE\nhas been loaded.   If the LDE has been loaded into a node.js application as a module, using\n    require() , then the module will have a member called  Feedback , an\n   instance of  EventEmitter .  Clients can listen for feedback events by\n   calling  theModule.Feedback.addEventListener('feedback',f) , with their\n   own function  f .  That function will be called with one argument when\n   the LDE generates feedback, a JSON object with feedback data.  The most\n   important field in the object is the  subject  field, which will contain\n   the ID of the  InputStructure  instance to which the feedback pertains.  If the LDE has been loaded into the browser directly (not in a WebWorker\n   instance, but in the UI thread) then it installs a  Feedback  object in\n   the  window  namespace.  The client can listen to events by calling\n    window.Feedback.addEventListener('feedback',f) , and  f  will be called\n   with an event  E  such that  E.data  has the structure described in the\n   previous bullet point (e.g.,  E.data.subject  is an  InputStructure  ID).  If the LDE has been loaded into a node.js application in a background\n   thread, using Workers, then it will occasionally post messages to the\n   parent context when one of its computations requires sending feedback\n   about the result.  If the LDE is loaded into a worker  W , then you can\n   listen for such messages with  W.onmessage = function (event) {...} .\n   Feedback events passed to such a handler will have  event.type  equal to\n   the string  \"feedback\"  and  event.payload  equal to the feedback data\n   itself as documented in the previous two bullet points (e.g.,\n    event.payload.subject  an  InputStructure  ID).   For an example of how this works, see the unit tests regarding feedback in the LDE .", 
            "title": "Receiving Feedback"
        }, 
        {
            "location": "/api-structures/", 
            "text": "API Documentation for the \nStructure\n Class\n\n\nSource Code\n\n\n\n\nThe \nStructure\n class\n\n\nUnit tests of the \nStructure\n class\n\n\n\n\nPurpose\n\n\nThe Lurch Deductive Engine (LDE, \ndocumented here\n) maintains\ntwo data structures, one called the Input Tree and one called the Output\nTree.  In both cases, the trees' nodes are instances of this class\n(\nStructure\n).  In particular, the Input Tree is composed of\n\nInputStructure\n instances (a direct subclass of \nStructure\n) and the Output\nTree is composed of \nOutputStructure\n instances (another direct subclass).\nSee also \nthe API documentation for the \nInputStructure\n class and its\nsubclasses\n.\n\n\nWe build into this base class all the functionality that must be present at\nevery point in those hierarchies, and leave to subclasses that functionality\nthat makes sense only for specific types of structures.  For instance, this\nclass contains no functionality to support rules of inference, because they\nare one specific type of \nOutputStructure\n, so their functionality will be\nimplemented in a subclass for that purpose.\n\n\nConstructing and Serialization\n\n\nThere is one constructor for the class\n(\nsee source code\n):\n\n\nStructure(child1,child2,...)\n creates a new instance, with the given list\nof children, each of which must be a \nStructure\n instance (or it will be\nignored).  All such children are removed from any old parent they had before\nbeing inserted into this newly created one.\n\n\nInstances can be converted to and from JSON, for saving to a file, storing\npermanently anywhere, or transmitting across threads or network connections.\nTo ensure that deserialization correctly reconstructs instances of the right\nsubclass of \nStructure\n, each subclass must be registered.  To do so, we\nprovide the \naddSubclass\n function.  Use it like so.\n\n\nJavaScript:\n\n\n    MySubclass = function ( /* ... */ ) { /* ... */ };\n    // ...\n    MySubclass.prototype.className = Structure.addSubclass( 'MySubclass', MySubclass );\n\n\n\n\nCoffeeScript, somewhere inside the class definition:\n\n\n    class MySubclass extends Structure\n        # ...\n        className : Structure.addSubclass 'MySubclass', MySubclass\n        # ...\n\n\n\n\nThen one can serialize and deserialize any hierarchy containing \nStructure\n\ninstances, as well as instances of its subclasses, using the member function\n\nsomeInstance.toJSON()\n (which obviously yields a JSON structure) or the\nclass function \nStructure.fromJSON(data)\n, which accepts JSON data created\nfrom the first function.\n\n\nSerializing a structure preserves its class, its attributes (\ndocumented\nbelow\n), and the hierarchy for which\nit is the root.\n\n\nStructure hierarchies\n\n\nTo navigate or alter a hierarchy of \nStructure\n instances, use the\nfollowing member functions present in each instance.\n\n\n\n\ninstance.parent()\n yields the parent structure, or \nnull\n if there is\n   no parent (i.e., the instance is the root of a hierarchy)\n\n\ninstance.children()\n yields an array containing the children structures,\n   in order, or an empty array if there are none\n\n\ninstance.indexInParent()\n yields the index of the child in its parent's\n   ordered list of children, or unddefined if the instance has no parent\n\n\ninstance.previousSibling()\n and \ninstance.nextSibling()\n yield the\n   adjacent structure in the parent's child list, forward or backward, as\n   expected, or undefined if there is no such sibling\n\n\ninstance.removeFromParent()\n drops the instance from it's parent's list\n   of children (thereby decreasing the length of that child list by 1) and\n   thus making \ninstance.parent()\n null\n\n\ninstance.removeChild(index)\n is a convenience equivalent to\n   \ninstance.children()[index].removeFromParent()\n\n\ninstance.insertChild(child,index)\n expects a structure instance as the\n   first argument and an index into the children list as the second.  It\n   inserts the new child at that index, thus increasing the number of\n   children by 1.  You may use an index equal to the length of the child\n   list to append.  The child is removed from its previous parent, if any,\n   before being inserted here.\n\n\ninstance.replaceWith(other)\n expects another structure instance as its\n   argument.  It removes \ninstance\n from its parent, if there is one, and\n   then inserts \nother\n at the same index in the parent, thus replacing\n   \ninstance\n.  This has no effect if \ninstance\n has no parent.  It is\n   equivalent to successive calls to \nremoveFromParent()\n and\n   \ninsertChild()\n at the instance and its parent, respectively.\n\n\ninstance.copy()\n makes a deep copy of the instance, including all nodes\n   below it in the hierarchy.  This new copy will have all the same IDs as\n   the previous copy, so to preserve uniqueness of IDs, you will usually\n   want to call \ncopiedInstance.clearIDs()\n afterwards.\n\n\n\n\nThe order of nodes in the hierarchy is often important.  We have one simple\norder relation on the nodes in the hierarchy and one more complex.  The\nsimplest is just whether node A is \"earlier than\" node B, in the order\ninduced by an in-order tree traversal (that is, the order in which the open\nparentheses would appear if the tree were written as a LISP expression).\nThis relation can be tested with \ninstance.isEarlierThan(other)\n.\n\n\nThe more complex order relation is accessibility, which we do not define\nhere, because it is already defined \nin the source code\ndocumentation\n.\nThat relation is implemented with the following member functions available\nin all instances of the class.\n\n\n\n\nA.isAccessibleTo(B)\n implements the relation as defined at the link\n   given above.\n\n\nA.isInTheScopeOf(B)\n is equivalent to \nB.isAccessibleTo(A)\n.\n\n\nA.iteratorOverAccessibles()\n yields an \"iterator\" object, which is an\n   object that can produce the list of nodes accessible to \nA\n by repeated\n   calls to the \nnext()\n member of the object.  Consider the following\n   JavaScript code that would use such an iterator.\n\n\n\n\n    var iterator = A.iteratorOverAccessibles();\n    var accessible;\n    while ( accessible = iterator.next() ) {\n        console.log( 'The next accessible structure is:',\n            accessible.toJSON() );\n    }\n\n\n\n\nNodes are produced by the iterator in reverse order (under the\n\nisEarlierThan\n relation) starting from the first accessible node before\n\nA\n.  When the \nnext()\n function yields null for the first time, the end of\nthe list has been reached.  (The \nnext()\n function will yield null forever\nthereafter.)\n\n\nIterators are more efficient than producing the entire list and returning\nit, because the client may be seeking just one particular node in the list,\nand thus producing the entire list so that the client can search just a\nsmall part of it could be wasteful.\n\n\nThere is an analogous function for scopes.\n\n\n\n\nA.iteratorOverScope()\n functions like \nA.iteratorOverAccessibles()\n, but\n   walks forwards through the structure, including precisely those nodes for\n   which \nB.isInTheScopeOf(A)\n holds true.\n\n\n\n\nThere are then four functions that use these iterators under the hood.\nClients will most likely wish to use these rather than have direct access\nto the iterators.\n\n\n\n\nA.firstAccessible(P)\n expects \nP\n to be a one-place predicate (that is,\n   a JavaScript function that can be evaluated on a single argument, and\n   yields true or false in each case) and yields the first item on the\n   \"accessibles\" list (as given by \nA.iteratorOverAccessibles()\n) for which\n   \nP\n yields true.  It returns undefined if there is no such thing.\n\n\nA.firstInScope(P)\n expects \nP\n to be a one-place predicate, as just\n   defined, and behaves just like \nfirstAccessible()\n, except it walks\n   through \nA.iteratorOverScope()\n instead.\n\n\nA.allAccessibles(P)\n expects \nP\n as in the previous two functions, and\n   yields all nodes accessible to \nA\n that satisfy \nP\n, in the same order\n   they would be reported by \niteratorOverAccessibles()\n.\n\n\nA.allInScope(P)\n expects \nP\n as in the previous two functions, and\n   yields all nodes in the scope of \nA\n that satisfy \nP\n, in the same order\n   they would be reported by \niteratorOverScope()\n.\n\n\n\n\nStructure attributes\n\n\nThe following functions available in each instance of the structure class\nsupport attributes.\n\n\n\n\ninstance.getAttribute(key)\n looks up attributes by a given string \nkey\n.\n\n\ninstance.setAttribute(key,value)\n stores attributes under a given\n   string \nkey\n with value \nvalue\n, which should be a JSON structure (or\n   atomic data).  No check is made to verify that the value is of this\n   type, but errors will transpire later if this condition is not satisfied\n   (specifically, serialization errors).\n\n\ninstance.clearAttributes(key1,key2,...)\n removes the key-value pairs\n   of attributes associated with any of the keys passed as parameters.  It\n   is acceptable to pass any number of keys, including just one.  If zero\n   are passed, \nall\n key-value pairs are removed.\n\n\ninstance.attr(object)\n adds all attributes of the given object as\n   attributes to the instance, and returns the instance itself.  This is\n   useful when constructing hierarchies, as follows.\n\n\n\n\n    var A = new Structure(\n        ( new Structure() ).attr( { name : 'example structure' } ),\n        ( new Structure() ).attr( { color : '#99ff00' } )\n    );\n\n\n\n\nYou may not use attribute keys that begin with an underscore.  These are\nreserved for internal use.\n\n\nConnections\n\n\nStructure hierarchies support the notion of making connections (directed\nedges, in the graph theory sense) between any two nodes in a hierarchy.\n(Actually, between any two \nStructure\n instances at all, but typically we\nuse it within the same hierarchy.)  Each such edge can have arbitrary JSON\ndata attached to it.\n\n\nTo enable this feature, we expose the following functions from the\n\nStructure\n class.  They will function only if both ends of the connection\nhave a unique ID, as documented \nbelow\n.\n\n\nTo create or destroy connections, use these functions:\n\n\n\n\nsource.connectTo(target,data)\n, where \nsource\n and \ntarget\n are\n   \nStructure\n instances and \ndata\n is an object containing the JSON data of\n   connection, which must at least contain the connection's unique ID in the\n   \n\"id\"\n field.  There can be multiple connections between the same two\n   structures, even with the same JSON data, except for their unique IDs.\n   Returns true if the connection was formed, false if some error prevented\n   it (such as the destination not being a structure, or not having an ID,\n   or the source not having an ID, or the connection ID already in use).\n\n\nStructure.disconnect(connectionID)\n undoes the previous operation.\n   Returns true on success or false on failure (for example, if there were\n   no connection with that ID).\n\n\nStructure.setConnectionData(connectionID,key,value)\n can be called after\n   a connection was already formed to update its data.\n\n\nmyStructure.removeAllConnections()\n does exactly what it sounds like;\n   the \nStructure\n will then have no connections in or out.\n\n\n\n\nYou can query the connections among structures with these functions:\n\n\n\n\nsource.getConnectionsOut()\n returns a list of unique IDs for\n   connections (which are different than the IDs for structures\n   themselves).  To see what you can do with a connection ID, read on.\n   The IDs are always returned in alphabetical order.\n\n\ntarget.getConnectionsIn()\n functions analogously to the previous, but\n   for connections into a target, rather than out from a source.\n\n\nnode.getAllConnections()\n returns the union of the previous two lists,\n   each entry listed only once (even if the node connects to itself), and\n   still in alphabetical order.\n\n\nStructure.getConnectionSource(ID)\n returns the \nStructure\n instance that\n   is the source for the connection with the given ID (or undefined if the\n   ID is not in use).\n\n\nStructure.getConnectionTarget(ID)\n and \nStructure.getConnectionData(ID)\n\n   are similar to the previous.\n\n\n\n\nExample usage:\n\n\nfunction getConnectionsBetween ( A, B ) {\n    var result = [ ];\n    var connIDs = A.getConnectionsOut();\n    for ( var i = 0 ; i \n connIDs.length ; i++ ) {\n        if ( target == Structure.getConnectionTarget( connIDs[i] ) )\n            result.push( Structure.getConnectionData( connIDs[i] ) );\n    }\n    return result;\n}\n\n\n\n\nUnique IDs\n\n\nThe \nStructure\n class maintains a mapping from IDs (as strings) to instances\nof the class.  An instance gets its ID from the attribute with key \"id.\"\nAll IDs in a hierarchy can be tracked (that is, recorded into this\nclass-level mapping) with the \ntrackIDs()\n function documented below.\n\n\nHere are the relevant functions:\n\n\n\n\ninstance.id()\n returns the instance's ID, if it has one, or undefined if\n   not\n\n\ninstance.trackIDs()\n asks the class to update the class variable that\n   maps IDs to instances, recording the connection of all IDs for all nodes\n   in the hierarchy whose root is \ninstance\n.  This will overwrite earlier\n   data in that mapping if and only if you have not kept IDs unique.\n\n\ninstance.untrackIDs()\n removes from the class-level mapping all IDs that\n   appear in the hierarchy whose root is \ninstance\n.  If you are done with\n   a \nStructure\n instance, you must call this function in it, so that its\n   memory is guaranteed to eventually be garbage collected.\n\n\nStructure.instanceWithID(id)\n takes a string ID and yields the instance\n   with that ID, if there is one, and that instance has recorded its ID in\n   the class-level variable for this purpose by means of a call to\n   \ntrackIDs()\n, or null or undefined if there is none.\n\n\n\n\nEvents and event handlers\n\n\nAny \nStructure\n instance fires up to twelve different types of events during\nits lifetime:\n\n\n\n\nwillBeInserted\n\n\nwillBeRemoved\n\n\nwillBeChanged\n\n\nwasInserted\n\n\nwasRemoved\n\n\nwasChanged\n\n\nconnectionWillBeInserted\n\n\nconnectionWillBeRemoved\n\n\nconnectionWillBeChanged\n\n\nconnectionWasInserted\n\n\nconnectionWasRemoved\n\n\nconnectionWasChanged\n\n\n\n\nTo install an event handler for one of these, simply overwrite that key in\nthe \nStructure\n object itself, as in \nmyStructure.willBeRemoved =\nmyHandlerFunction\n.\n\n\nInsertion events are fired immediately before/after the \nStructure\n is added\nas a child under a new parent.  Removal events are fired immediately\nbefore/after the \nStructure\n is removed from an existing parent.  Change\nevents are fired immediately before/after an attribute of the \nStructure\n\ninstance changes.  The same holds true for changing connections, and the\nevents fire on both the source and target of the connection.  (In the case\nwhere the source is the target, this will result in the event firing twice.)\n\n\nExample:\n\n\n    var A = new Structure();\n    var B = new Structure();\n    A.willBeInserted = function () { console.log( 'Now!' ); };\n    B.insertChild( A ); // prints 'Now!' to console just before inserting", 
            "title": "Structures"
        }, 
        {
            "location": "/api-structures/#api-documentation-for-the-structure-class", 
            "text": "", 
            "title": "API Documentation for the Structure Class"
        }, 
        {
            "location": "/api-structures/#source-code", 
            "text": "The  Structure  class  Unit tests of the  Structure  class", 
            "title": "Source Code"
        }, 
        {
            "location": "/api-structures/#purpose", 
            "text": "The Lurch Deductive Engine (LDE,  documented here ) maintains\ntwo data structures, one called the Input Tree and one called the Output\nTree.  In both cases, the trees' nodes are instances of this class\n( Structure ).  In particular, the Input Tree is composed of InputStructure  instances (a direct subclass of  Structure ) and the Output\nTree is composed of  OutputStructure  instances (another direct subclass).\nSee also  the API documentation for the  InputStructure  class and its\nsubclasses .  We build into this base class all the functionality that must be present at\nevery point in those hierarchies, and leave to subclasses that functionality\nthat makes sense only for specific types of structures.  For instance, this\nclass contains no functionality to support rules of inference, because they\nare one specific type of  OutputStructure , so their functionality will be\nimplemented in a subclass for that purpose.", 
            "title": "Purpose"
        }, 
        {
            "location": "/api-structures/#constructing-and-serialization", 
            "text": "There is one constructor for the class\n( see source code ):  Structure(child1,child2,...)  creates a new instance, with the given list\nof children, each of which must be a  Structure  instance (or it will be\nignored).  All such children are removed from any old parent they had before\nbeing inserted into this newly created one.  Instances can be converted to and from JSON, for saving to a file, storing\npermanently anywhere, or transmitting across threads or network connections.\nTo ensure that deserialization correctly reconstructs instances of the right\nsubclass of  Structure , each subclass must be registered.  To do so, we\nprovide the  addSubclass  function.  Use it like so.  JavaScript:      MySubclass = function ( /* ... */ ) { /* ... */ };\n    // ...\n    MySubclass.prototype.className = Structure.addSubclass( 'MySubclass', MySubclass );  CoffeeScript, somewhere inside the class definition:      class MySubclass extends Structure\n        # ...\n        className : Structure.addSubclass 'MySubclass', MySubclass\n        # ...  Then one can serialize and deserialize any hierarchy containing  Structure \ninstances, as well as instances of its subclasses, using the member function someInstance.toJSON()  (which obviously yields a JSON structure) or the\nclass function  Structure.fromJSON(data) , which accepts JSON data created\nfrom the first function.  Serializing a structure preserves its class, its attributes ( documented\nbelow ), and the hierarchy for which\nit is the root.", 
            "title": "Constructing and Serialization"
        }, 
        {
            "location": "/api-structures/#structure-hierarchies", 
            "text": "To navigate or alter a hierarchy of  Structure  instances, use the\nfollowing member functions present in each instance.   instance.parent()  yields the parent structure, or  null  if there is\n   no parent (i.e., the instance is the root of a hierarchy)  instance.children()  yields an array containing the children structures,\n   in order, or an empty array if there are none  instance.indexInParent()  yields the index of the child in its parent's\n   ordered list of children, or unddefined if the instance has no parent  instance.previousSibling()  and  instance.nextSibling()  yield the\n   adjacent structure in the parent's child list, forward or backward, as\n   expected, or undefined if there is no such sibling  instance.removeFromParent()  drops the instance from it's parent's list\n   of children (thereby decreasing the length of that child list by 1) and\n   thus making  instance.parent()  null  instance.removeChild(index)  is a convenience equivalent to\n    instance.children()[index].removeFromParent()  instance.insertChild(child,index)  expects a structure instance as the\n   first argument and an index into the children list as the second.  It\n   inserts the new child at that index, thus increasing the number of\n   children by 1.  You may use an index equal to the length of the child\n   list to append.  The child is removed from its previous parent, if any,\n   before being inserted here.  instance.replaceWith(other)  expects another structure instance as its\n   argument.  It removes  instance  from its parent, if there is one, and\n   then inserts  other  at the same index in the parent, thus replacing\n    instance .  This has no effect if  instance  has no parent.  It is\n   equivalent to successive calls to  removeFromParent()  and\n    insertChild()  at the instance and its parent, respectively.  instance.copy()  makes a deep copy of the instance, including all nodes\n   below it in the hierarchy.  This new copy will have all the same IDs as\n   the previous copy, so to preserve uniqueness of IDs, you will usually\n   want to call  copiedInstance.clearIDs()  afterwards.   The order of nodes in the hierarchy is often important.  We have one simple\norder relation on the nodes in the hierarchy and one more complex.  The\nsimplest is just whether node A is \"earlier than\" node B, in the order\ninduced by an in-order tree traversal (that is, the order in which the open\nparentheses would appear if the tree were written as a LISP expression).\nThis relation can be tested with  instance.isEarlierThan(other) .  The more complex order relation is accessibility, which we do not define\nhere, because it is already defined  in the source code\ndocumentation .\nThat relation is implemented with the following member functions available\nin all instances of the class.   A.isAccessibleTo(B)  implements the relation as defined at the link\n   given above.  A.isInTheScopeOf(B)  is equivalent to  B.isAccessibleTo(A) .  A.iteratorOverAccessibles()  yields an \"iterator\" object, which is an\n   object that can produce the list of nodes accessible to  A  by repeated\n   calls to the  next()  member of the object.  Consider the following\n   JavaScript code that would use such an iterator.       var iterator = A.iteratorOverAccessibles();\n    var accessible;\n    while ( accessible = iterator.next() ) {\n        console.log( 'The next accessible structure is:',\n            accessible.toJSON() );\n    }  Nodes are produced by the iterator in reverse order (under the isEarlierThan  relation) starting from the first accessible node before A .  When the  next()  function yields null for the first time, the end of\nthe list has been reached.  (The  next()  function will yield null forever\nthereafter.)  Iterators are more efficient than producing the entire list and returning\nit, because the client may be seeking just one particular node in the list,\nand thus producing the entire list so that the client can search just a\nsmall part of it could be wasteful.  There is an analogous function for scopes.   A.iteratorOverScope()  functions like  A.iteratorOverAccessibles() , but\n   walks forwards through the structure, including precisely those nodes for\n   which  B.isInTheScopeOf(A)  holds true.   There are then four functions that use these iterators under the hood.\nClients will most likely wish to use these rather than have direct access\nto the iterators.   A.firstAccessible(P)  expects  P  to be a one-place predicate (that is,\n   a JavaScript function that can be evaluated on a single argument, and\n   yields true or false in each case) and yields the first item on the\n   \"accessibles\" list (as given by  A.iteratorOverAccessibles() ) for which\n    P  yields true.  It returns undefined if there is no such thing.  A.firstInScope(P)  expects  P  to be a one-place predicate, as just\n   defined, and behaves just like  firstAccessible() , except it walks\n   through  A.iteratorOverScope()  instead.  A.allAccessibles(P)  expects  P  as in the previous two functions, and\n   yields all nodes accessible to  A  that satisfy  P , in the same order\n   they would be reported by  iteratorOverAccessibles() .  A.allInScope(P)  expects  P  as in the previous two functions, and\n   yields all nodes in the scope of  A  that satisfy  P , in the same order\n   they would be reported by  iteratorOverScope() .", 
            "title": "Structure hierarchies"
        }, 
        {
            "location": "/api-structures/#structure-attributes", 
            "text": "The following functions available in each instance of the structure class\nsupport attributes.   instance.getAttribute(key)  looks up attributes by a given string  key .  instance.setAttribute(key,value)  stores attributes under a given\n   string  key  with value  value , which should be a JSON structure (or\n   atomic data).  No check is made to verify that the value is of this\n   type, but errors will transpire later if this condition is not satisfied\n   (specifically, serialization errors).  instance.clearAttributes(key1,key2,...)  removes the key-value pairs\n   of attributes associated with any of the keys passed as parameters.  It\n   is acceptable to pass any number of keys, including just one.  If zero\n   are passed,  all  key-value pairs are removed.  instance.attr(object)  adds all attributes of the given object as\n   attributes to the instance, and returns the instance itself.  This is\n   useful when constructing hierarchies, as follows.       var A = new Structure(\n        ( new Structure() ).attr( { name : 'example structure' } ),\n        ( new Structure() ).attr( { color : '#99ff00' } )\n    );  You may not use attribute keys that begin with an underscore.  These are\nreserved for internal use.", 
            "title": "Structure attributes"
        }, 
        {
            "location": "/api-structures/#connections", 
            "text": "Structure hierarchies support the notion of making connections (directed\nedges, in the graph theory sense) between any two nodes in a hierarchy.\n(Actually, between any two  Structure  instances at all, but typically we\nuse it within the same hierarchy.)  Each such edge can have arbitrary JSON\ndata attached to it.  To enable this feature, we expose the following functions from the Structure  class.  They will function only if both ends of the connection\nhave a unique ID, as documented  below .  To create or destroy connections, use these functions:   source.connectTo(target,data) , where  source  and  target  are\n    Structure  instances and  data  is an object containing the JSON data of\n   connection, which must at least contain the connection's unique ID in the\n    \"id\"  field.  There can be multiple connections between the same two\n   structures, even with the same JSON data, except for their unique IDs.\n   Returns true if the connection was formed, false if some error prevented\n   it (such as the destination not being a structure, or not having an ID,\n   or the source not having an ID, or the connection ID already in use).  Structure.disconnect(connectionID)  undoes the previous operation.\n   Returns true on success or false on failure (for example, if there were\n   no connection with that ID).  Structure.setConnectionData(connectionID,key,value)  can be called after\n   a connection was already formed to update its data.  myStructure.removeAllConnections()  does exactly what it sounds like;\n   the  Structure  will then have no connections in or out.   You can query the connections among structures with these functions:   source.getConnectionsOut()  returns a list of unique IDs for\n   connections (which are different than the IDs for structures\n   themselves).  To see what you can do with a connection ID, read on.\n   The IDs are always returned in alphabetical order.  target.getConnectionsIn()  functions analogously to the previous, but\n   for connections into a target, rather than out from a source.  node.getAllConnections()  returns the union of the previous two lists,\n   each entry listed only once (even if the node connects to itself), and\n   still in alphabetical order.  Structure.getConnectionSource(ID)  returns the  Structure  instance that\n   is the source for the connection with the given ID (or undefined if the\n   ID is not in use).  Structure.getConnectionTarget(ID)  and  Structure.getConnectionData(ID) \n   are similar to the previous.   Example usage:  function getConnectionsBetween ( A, B ) {\n    var result = [ ];\n    var connIDs = A.getConnectionsOut();\n    for ( var i = 0 ; i   connIDs.length ; i++ ) {\n        if ( target == Structure.getConnectionTarget( connIDs[i] ) )\n            result.push( Structure.getConnectionData( connIDs[i] ) );\n    }\n    return result;\n}", 
            "title": "Connections"
        }, 
        {
            "location": "/api-structures/#unique-ids", 
            "text": "The  Structure  class maintains a mapping from IDs (as strings) to instances\nof the class.  An instance gets its ID from the attribute with key \"id.\"\nAll IDs in a hierarchy can be tracked (that is, recorded into this\nclass-level mapping) with the  trackIDs()  function documented below.  Here are the relevant functions:   instance.id()  returns the instance's ID, if it has one, or undefined if\n   not  instance.trackIDs()  asks the class to update the class variable that\n   maps IDs to instances, recording the connection of all IDs for all nodes\n   in the hierarchy whose root is  instance .  This will overwrite earlier\n   data in that mapping if and only if you have not kept IDs unique.  instance.untrackIDs()  removes from the class-level mapping all IDs that\n   appear in the hierarchy whose root is  instance .  If you are done with\n   a  Structure  instance, you must call this function in it, so that its\n   memory is guaranteed to eventually be garbage collected.  Structure.instanceWithID(id)  takes a string ID and yields the instance\n   with that ID, if there is one, and that instance has recorded its ID in\n   the class-level variable for this purpose by means of a call to\n    trackIDs() , or null or undefined if there is none.", 
            "title": "Unique IDs"
        }, 
        {
            "location": "/api-structures/#events-and-event-handlers", 
            "text": "Any  Structure  instance fires up to twelve different types of events during\nits lifetime:   willBeInserted  willBeRemoved  willBeChanged  wasInserted  wasRemoved  wasChanged  connectionWillBeInserted  connectionWillBeRemoved  connectionWillBeChanged  connectionWasInserted  connectionWasRemoved  connectionWasChanged   To install an event handler for one of these, simply overwrite that key in\nthe  Structure  object itself, as in  myStructure.willBeRemoved =\nmyHandlerFunction .  Insertion events are fired immediately before/after the  Structure  is added\nas a child under a new parent.  Removal events are fired immediately\nbefore/after the  Structure  is removed from an existing parent.  Change\nevents are fired immediately before/after an attribute of the  Structure \ninstance changes.  The same holds true for changing connections, and the\nevents fire on both the source and target of the connection.  (In the case\nwhere the source is the target, this will result in the event firing twice.)  Example:      var A = new Structure();\n    var B = new Structure();\n    A.willBeInserted = function () { console.log( 'Now!' ); };\n    B.insertChild( A ); // prints 'Now!' to console just before inserting", 
            "title": "Events and event handlers"
        }, 
        {
            "location": "/api-input-structures/", 
            "text": "API Documentation for the \nInputStructure\n Class and its Subclasses\n\n\nSource Code\n\n\n\n\nThe \nInputStructure\n class\n\n\nUnit tests of the \nInputStructure\n class\n\n\n\n\nPurpose\n\n\nFor information on the generic notion of Structures, see\n\nthe API documentation for the base \nStructure\n class\n.\nThat explains not only the concepts common to all Structures, but also how\n\nInputStructure\ns fit into the bigger picture.\n\n\nIn this file, we cover the details specific to the \nInputStructure\n subclass\nas well as its subclasses.  We break this document into sections, one for\neach subclass of \nInputStructure\n, including \nInputStructure\n itself.\n\n\nThe \nInputStructure\n class\n\n\nThis class overrides none of the methods of its superclass, so you can refer\nto \nthe superclass API documentation\n for information\nabout many of the class's features.  It adds the following features.\n\n\nDirty/Clean Status\n\n\nIn the Input Tree, the \ndirty\n flag of an \nInputStructure\n signifies whether\nthat node in the tree needs to be reinterpreted (i.e., has changed since its\nlast interpretation, or something else that's relevant changed since its\nlast interpretation).  Because the interpretation of parent nodes is\ndependent on the interpretation of child nodes, if a node is marked dirty,\nits parent should be as well (and so on, up the ancestor chain).\n\n\nThus the \nInputStructure\n class provides a \nmarkDirty(yesOrNo)\n function to\nguarantee this property.  If you call it with a false argument (to mark the\nStructure clean) then it operates on only the Structure in which you called\nit.  But if you call it with a true argument, then it recursively continues\nup the ancestor chain, marking the whole chain dirty.\n\n\nThe same \nisDirty()\n function from the \nStructure\n base class remains\navailable, unchanged.\n\n\nFeedback\n\n\nTo make it easy to give feedback about \nInputStructure\n instances, we\nprovide an instance method called \nfeedback()\n.  You can call\n\nX.feedback(Y)\n in any \nInputStructure\n \nX\n, passing any JSON object \nY\n\ncontaining the feedback you wish to send, and it will add \nX.id()\n as the\n\nsubject\n field of \nY\n, then call the LDE's global feedback function to\ntransmit \nY\n to the client.\n\n\nThis transmission takes different forms depending on the client.  See the\n\nrelevant section in the LDE API documentation\n.", 
            "title": "Input Structures"
        }, 
        {
            "location": "/api-input-structures/#api-documentation-for-the-inputstructure-class-and-its-subclasses", 
            "text": "", 
            "title": "API Documentation for the InputStructure Class and its Subclasses"
        }, 
        {
            "location": "/api-input-structures/#source-code", 
            "text": "The  InputStructure  class  Unit tests of the  InputStructure  class", 
            "title": "Source Code"
        }, 
        {
            "location": "/api-input-structures/#purpose", 
            "text": "For information on the generic notion of Structures, see the API documentation for the base  Structure  class .\nThat explains not only the concepts common to all Structures, but also how InputStructure s fit into the bigger picture.  In this file, we cover the details specific to the  InputStructure  subclass\nas well as its subclasses.  We break this document into sections, one for\neach subclass of  InputStructure , including  InputStructure  itself.", 
            "title": "Purpose"
        }, 
        {
            "location": "/api-input-structures/#the-inputstructure-class", 
            "text": "This class overrides none of the methods of its superclass, so you can refer\nto  the superclass API documentation  for information\nabout many of the class's features.  It adds the following features.", 
            "title": "The InputStructure class"
        }, 
        {
            "location": "/api-input-structures/#dirtyclean-status", 
            "text": "In the Input Tree, the  dirty  flag of an  InputStructure  signifies whether\nthat node in the tree needs to be reinterpreted (i.e., has changed since its\nlast interpretation, or something else that's relevant changed since its\nlast interpretation).  Because the interpretation of parent nodes is\ndependent on the interpretation of child nodes, if a node is marked dirty,\nits parent should be as well (and so on, up the ancestor chain).  Thus the  InputStructure  class provides a  markDirty(yesOrNo)  function to\nguarantee this property.  If you call it with a false argument (to mark the\nStructure clean) then it operates on only the Structure in which you called\nit.  But if you call it with a true argument, then it recursively continues\nup the ancestor chain, marking the whole chain dirty.  The same  isDirty()  function from the  Structure  base class remains\navailable, unchanged.", 
            "title": "Dirty/Clean Status"
        }, 
        {
            "location": "/api-input-structures/#feedback", 
            "text": "To make it easy to give feedback about  InputStructure  instances, we\nprovide an instance method called  feedback() .  You can call X.feedback(Y)  in any  InputStructure   X , passing any JSON object  Y \ncontaining the feedback you wish to send, and it will add  X.id()  as the subject  field of  Y , then call the LDE's global feedback function to\ntransmit  Y  to the client.  This transmission takes different forms depending on the client.  See the relevant section in the LDE API documentation .", 
            "title": "Feedback"
        }
    ]
}